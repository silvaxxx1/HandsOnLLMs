{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03d35ef6",
   "metadata": {},
   "source": [
    "## Get the pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1314d3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import requests \n",
    "\n",
    "pdf_path = \"assets/DEEP LEARNING.pdf\" \n",
    "\n",
    "if not os.path.exists(pdf_path):\n",
    "    url = \"http://alvarestech.com/temp/deep/Deep%20Learning%20by%20Ian%20Goodfellow,%20Yoshua%20Bengio,%20Aaron%20Courville%20(z-lib.org).pdf\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(pdf_path, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(\"PDF downloaded successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to download the PDF. Status code: {response.status_code}\")\n",
    "    \n",
    "else:\n",
    "    print(\"PDF already exists.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbbdf5f",
   "metadata": {},
   "source": [
    "# Lets see the pdf file using fitz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97da10e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER 4.\n",
      "NUMERICAL COMPUTATION\n",
      "x\n",
      "f x\n",
      "( )\n",
      "Ideally, we would like\n",
      "to arrive at the global\n",
      "minimum, but this\n",
      "might not be possible.\n",
      "This local minimum\n",
      "performs nearly as well as\n",
      "the global one,\n",
      "so it is an acceptable\n",
      "halting point.\n",
      "This local minimum performs\n",
      "poorly and should be avoided.\n",
      "Figure 4.3: Optimization algorithms may fail to ﬁnd a global minimum when there are\n",
      "multiple local minima or plateaus present. In the context of deep learning, we generally\n",
      "accept such solutions even though they are not truly minimal, so long as they correspond\n",
      "to signiﬁcantly low values of the cost function.\n",
      "critical points are points where every element of the gradient is equal to zero.\n",
      "The directional derivative in direction\n",
      "(a unit vector) is the slope of the\n",
      "u\n",
      "function f in direction u. In other words, the directional derivative is the derivative\n",
      "of the function f(x + αu) with respect to α, evaluated at α = 0. Using the chain\n",
      "rule, we can see that\n",
      "∂\n",
      "∂αf\n",
      "α\n",
      "(\n",
      "+\n",
      "x\n",
      "u) evaluates to u∇xf\n",
      "α\n",
      "( )\n",
      "x when\n",
      "= 0.\n",
      "To minimize f, we would like to ﬁnd the direction in which f decreases the\n",
      "fastest. We can do this using the directional derivative:\n",
      "min\n",
      "u u\n",
      ",\n",
      "u=1 u∇xf( )\n",
      "x\n",
      "(4.3)\n",
      "=\n",
      "min\n",
      "u u\n",
      ",\n",
      "u=1|| ||\n",
      "u 2||∇xf( )\n",
      "x ||2 cos θ\n",
      "(4.4)\n",
      "where θ is the angle between u and the gradient. Substituting in || ||\n",
      "u 2 = 1 and\n",
      "ignoring factors that do not depend on u, this simpliﬁes to minu cos θ. This is\n",
      "minimized when u points in the opposite direction as the gradient. In other\n",
      "words, the gradient points directly uphill, and the negative gradient points directly\n",
      "downhill. We can decrease f by moving in the direction of the negative gradient.\n",
      "This is known as the\n",
      "or\n",
      ".\n",
      "method of steepest descent\n",
      "gradient descent\n",
      "Steepest descent proposes a new point\n",
      "x= x −∇\n",
      "\n",
      "xf( )\n",
      "x\n",
      "(4.5)\n",
      "85\n",
      "\n",
      "CHAPTER 4.\n",
      "NUMERICAL COMPUTATION\n",
      "where is the learning rate, a positive scalar determining the size of the step.\n",
      "We can choose in several diﬀerent ways. A popular approach is to set to a small\n",
      "constant. Sometimes, we can solve for the step size that makes the directional\n",
      "derivative vanish. Another approach is to evaluate f\n",
      "\n",
      "(x −∇xf( ))\n",
      "x\n",
      "for several\n",
      "values of and choose the one that results in the smallest objective function value.\n",
      "This last strategy is called a line search.\n",
      "Steepest descent converges when every element of the gradient is zero (or, in\n",
      "practice, very close to zero). In some cases, we may be able to avoid running this\n",
      "iterative algorithm, and just jump directly to the critical point by solving the\n",
      "equation ∇xf( ) = 0\n",
      "x\n",
      "for\n",
      ".\n",
      "x\n",
      "Although gradient descent is limited to optimization in continuous spaces, the\n",
      "general concept of repeatedly making a small move (that is approximately the best\n",
      "small move) towards better conﬁgurations can be generalized to discrete spaces.\n",
      "Ascending an objective function of discrete parameters is called hill climbing\n",
      "(\n",
      ",\n",
      ").\n",
      "Russel and Norvig 2003\n",
      "4.3.1\n",
      "Beyond the Gradient: Jacobian and Hessian Matrices\n",
      "Sometimes we need to ﬁnd all of the partial derivatives of a function whose input\n",
      "and output are both vectors. The matrix containing all such partial derivatives is\n",
      "known as a Jacobian matrix. Speciﬁcally, if we have a function f : Rm →Rn,\n",
      "then the Jacobian matrix J ∈Rn\n",
      "m\n",
      "×\n",
      "of\n",
      "is deﬁned such that\n",
      "f\n",
      "Ji,j =\n",
      "∂\n",
      "∂xjf( )\n",
      "x i.\n",
      "We are also sometimes interested in a derivative of a derivative. This is known\n",
      "as a second derivative. For example, for a function f : Rn →R, the derivative\n",
      "with respect to xi of the derivative of f with respect to xj is denoted as\n",
      "∂2\n",
      "∂xi∂xj f.\n",
      "In a single dimension, we can denote d2\n",
      "dx2 f by f (x). The second derivative tells\n",
      "us how the ﬁrst derivative will change as we vary the input. This is important\n",
      "because it tells us whether a gradient step will cause as much of an improvement\n",
      "as we would expect based on the gradient alone. We can think of the second\n",
      "derivative as measuring curvature. Suppose we have a quadratic function (many\n",
      "functions that arise in practice are not quadratic but can be approximated well\n",
      "as quadratic, at least locally). If such a function has a second derivative of zero,\n",
      "then there is no curvature. It is a perfectly ﬂat line, and its value can be predicted\n",
      "using only the gradient. If the gradient is\n",
      ", then we can make a step of size\n",
      "1\n",
      "\n",
      "along the negative gradient, and the cost function will decrease by . If the second\n",
      "derivative is negative, the function curves downward, so the cost function will\n",
      "actually decrease by more than . Finally, if the second derivative is positive, the\n",
      "function curves upward, so the cost function can decrease by less than . See\n",
      "86\n",
      "\n",
      "CHAPTER 4.\n",
      "NUMERICAL COMPUTATION\n",
      "x\n",
      "f x\n",
      "( )\n",
      "Negative curvature\n",
      "x\n",
      "f x\n",
      "( )\n",
      "No curvature\n",
      "x\n",
      "f x\n",
      "( )\n",
      "Positive curvature\n",
      "Figure 4.4: The second derivative determines the curvature of a function. Here we show\n",
      "quadratic functions with various curvature. The dashed line indicates the value of the cost\n",
      "function we would expect based on the gradient information alone as we make a gradient\n",
      "step downhill. In the case of negative curvature, the cost function actually decreases faster\n",
      "than the gradient predicts. In the case of no curvature, the gradient predicts the decrease\n",
      "correctly. In the case of positive curvature, the function decreases slower than expected\n",
      "and eventually begins to increase, so steps that are too large can actually increase the\n",
      "function inadvertently.\n",
      "ﬁgure\n",
      "to see how diﬀerent forms of curvature aﬀect the relationship between\n",
      "4.4\n",
      "the value of the cost function predicted by the gradient and the true value.\n",
      "When our function has multiple input dimensions, there are many second\n",
      "derivatives. These derivatives can be collected together into a matrix called the\n",
      "Hessian matrix. The Hessian matrix\n",
      "is deﬁned such that\n",
      "H\n",
      "x\n",
      "( )(\n",
      "f\n",
      ")\n",
      "H\n",
      "x\n",
      "( )(\n",
      "f\n",
      ")i,j =\n",
      "∂2\n",
      "∂xi∂xj\n",
      "f\n",
      ".\n",
      "( )\n",
      "x\n",
      "(4.6)\n",
      "Equivalently, the Hessian is the Jacobian of the gradient.\n",
      "Anywhere that the second partial derivatives are continuous, the diﬀerential\n",
      "operators are commutative, i.e. their order can be swapped:\n",
      "∂2\n",
      "∂xi∂xj\n",
      "f( ) =\n",
      "x\n",
      "∂2\n",
      "∂x j∂xi\n",
      "f\n",
      ".\n",
      "( )\n",
      "x\n",
      "(4.7)\n",
      "This implies that Hi,j = H j,i, so the Hessian matrix is symmetric at such points.\n",
      "Most of the functions we encounter in the context of deep learning have a symmetric\n",
      "Hessian almost everywhere. Because the Hessian matrix is real and symmetric,\n",
      "we can decompose it into a set of real eigenvalues and an orthogonal basis of\n",
      "87\n",
      "\n",
      "CHAPTER 4.\n",
      "NUMERICAL COMPUTATION\n",
      "eigenvectors. The second derivative in a speciﬁc direction represented by a unit\n",
      "vector d is given by dHd. When d is an eigenvector of H , the second derivative\n",
      "in that direction is given by the corresponding eigenvalue. For other directions of\n",
      "d, the directional second derivative is a weighted average of all of the eigenvalues,\n",
      "with weights between 0 and 1, and eigenvectors that have smaller angle with d\n",
      "receiving more weight. The maximum eigenvalue determines the maximum second\n",
      "derivative and the minimum eigenvalue determines the minimum second derivative.\n",
      "The (directional) second derivative tells us how well we can expect a gradient\n",
      "descent step to perform. We can make a second-order Taylor series approximation\n",
      "to the function\n",
      "around the current point\n",
      "f( )\n",
      "x\n",
      "x(0):\n",
      "f\n",
      "f\n",
      "( ) \n",
      "x ≈\n",
      "(x(0)) + (x\n",
      "x\n",
      "−\n",
      "(0))g + 1\n",
      "2(x\n",
      "x\n",
      "−\n",
      "(0))H x\n",
      "x\n",
      "(\n",
      "−\n",
      "(0)).\n",
      "(4.8)\n",
      "where g is the gradient and H is the Hessian at x(0). If we use a learning rate\n",
      "of , then the new point x will be given by x(0) −g. Substituting this into our\n",
      "approximation, we obtain\n",
      "f(x(0) −\n",
      "≈\n",
      "g) \n",
      "f(x(0)) −g g + 1\n",
      "22gHg.\n",
      "(4.9)\n",
      "There are three terms here: the original value of the function, the expected\n",
      "improvement due to the slope of the function, and the correction we must apply\n",
      "to account for the curvature of the function. When this last term is too large, the\n",
      "gradient descent step can actually move uphill. When gHg is zero or negative,\n",
      "the Taylor series approximation predicts that increasing forever will decrease f\n",
      "forever. In practice, the Taylor series is unlikely to remain accurate for large , so\n",
      "one must resort to more heuristic choices of in this case. When gHg is positive,\n",
      "solving for the optimal step size that decreases the Taylor series approximation of\n",
      "the function the most yields\n",
      "∗=\n",
      "gg\n",
      "gHg.\n",
      "(4.10)\n",
      "In the worst case, when g aligns with the eigenvector of H corresponding to the\n",
      "maximal eigenvalue λmax, then this optimal step size is given by\n",
      "1\n",
      "λ max. To the\n",
      "extent that the function we minimize can be approximated well by a quadratic\n",
      "function, the eigenvalues of the Hessian thus determine the scale of the learning\n",
      "rate.\n",
      "The second derivative can be used to determine whether a critical point is\n",
      "a local maximum, a local minimum, or saddle point. Recall that on a critical\n",
      "point, f(x) = 0. When the second derivative f(x) > 0, the ﬁrst derivative f (x)\n",
      "increases as we move to the right and decreases as we move to the left. This means\n",
      "88\n",
      "\n",
      "CHAPTER 4.\n",
      "NUMERICAL COMPUTATION\n",
      "f (x\n",
      "\n",
      "−) < 0 and f (x + ) > 0 for small enough . In other words, as we move\n",
      "right, the slope begins to point uphill to the right, and as we move left, the slope\n",
      "begins to point uphill to the left. Thus, when f (x) = 0 and f(x) > 0, we can\n",
      "conclude that x is a local minimum. Similarly, when f (x) = 0 and f (x) < 0, we\n",
      "can conclude that x is a local maximum. This is known as the second derivative\n",
      "test. Unfortunately, when f(x) = 0, the test is inconclusive. In this case x may\n",
      "be a saddle point, or a part of a ﬂat region.\n",
      "In multiple dimensions, we need to examine all of the second derivatives of the\n",
      "function. Using the eigendecomposition of the Hessian matrix, we can generalize\n",
      "the second derivative test to multiple dimensions.\n",
      "At a critical point, where\n",
      "∇xf(x) = 0, we can examine the eigenvalues of the Hessian to determine whether\n",
      "the critical point is a local maximum, local minimum, or saddle point. When the\n",
      "Hessian is positive deﬁnite (all its eigenvalues are positive), the point is a local\n",
      "minimum. This can be seen by observing that the directional second derivative\n",
      "in any direction must be positive, and making reference to the univariate second\n",
      "derivative test. Likewise, when the Hessian is negative deﬁnite (all its eigenvalues\n",
      "are negative), the point is a local maximum. In multiple dimensions, it is actually\n",
      "possible to ﬁnd positive evidence of saddle points in some cases. When at least\n",
      "one eigenvalue is positive and at least one eigenvalue is negative, we know that\n",
      "x is a local maximum on one cross section of f but a local minimum on another\n",
      "cross section. See ﬁgure\n",
      "for an example. Finally, the multidimensional second\n",
      "4.5\n",
      "derivative test can be inconclusive, just like the univariate version. The test is\n",
      "inconclusive whenever all of the non-zero eigenvalues have the same sign, but at\n",
      "least one eigenvalue is zero. This is because the univariate second derivative test is\n",
      "inconclusive in the cross section corresponding to the zero eigenvalue.\n",
      "In multiple dimensions, there is a diﬀerent second derivative for each direction\n",
      "at a single point. The condition number of the Hessian at this point measures\n",
      "how much the second derivatives diﬀer from each other. When the Hessian has a\n",
      "poor condition number, gradient descent performs poorly. This is because in one\n",
      "direction, the derivative increases rapidly, while in another direction, it increases\n",
      "slowly. Gradient descent is unaware of this change in the derivative so it does not\n",
      "know that it needs to explore preferentially in the direction where the derivative\n",
      "remains negative for longer. It also makes it diﬃcult to choose a good step size.\n",
      "The step size must be small enough to avoid overshooting the minimum and going\n",
      "uphill in directions with strong positive curvature. This usually means that the\n",
      "step size is too small to make signiﬁcant progress in other directions with less\n",
      "curvature. See ﬁgure\n",
      "for an example.\n",
      "4.6\n",
      "This issue can be resolved by using information from the Hessian matrix to guide\n",
      "89\n",
      "\n",
      "CHAPTER 4.\n",
      "NUMERICAL COMPUTATION\n",
      "\n",
      "󰤓\n",
      "\n",
      "\n",
      "\n",
      "󰤓\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "󰤓\n",
      "\n",
      "\n",
      "Figure 4.5: A saddle point containing both positive and negative curvature. The function\n",
      "in this example is f (x) = x2\n",
      "1 −x2\n",
      "2. Along the axis corresponding to x1, the function\n",
      "curves upward. This axis is an eigenvector of the Hessian and has a positive eigenvalue.\n",
      "Along the axis corresponding to x2, the function curves downward. This direction is an\n",
      "eigenvector of the Hessian with negative eigenvalue. The name “saddle point” derives from\n",
      "the saddle-like shape of this function. This is the quintessential example of a function\n",
      "with a saddle point. In more than one dimension, it is not necessary to have an eigenvalue\n",
      "of 0 in order to get a saddle point: it is only necessary to have both positive and negative\n",
      "eigenvalues. We can think of a saddle point with both signs of eigenvalues as being a local\n",
      "maximum within one cross section and a local minimum within another cross section.\n",
      "90\n",
      "\n",
      "CHAPTER 4.\n",
      "NUMERICAL COMPUTATION\n",
      "−\n",
      "−\n",
      "−\n",
      "30\n",
      "20\n",
      "10\n",
      "0\n",
      "10\n",
      "20\n",
      "x1\n",
      "−30\n",
      "−20\n",
      "−10\n",
      "0\n",
      "10\n",
      "20\n",
      "x2\n",
      "Figure 4.6: Gradient descent fails to exploit the curvature information contained in the\n",
      "Hessian matrix. Here we use gradient descent to minimize a quadratic functionf(x) whose\n",
      "Hessian matrix has condition number 5. This means that the direction of most curvature\n",
      "has ﬁve times more curvature than the direction of least curvature. In this case, the most\n",
      "curvature is in the direction [1, 1]and the least curvature is in the direction [1, −1]. The\n",
      "red lines indicate the path followed by gradient descent. This very elongated quadratic\n",
      "function resembles a long canyon. Gradient descent wastes time repeatedly descending\n",
      "canyon walls, because they are the steepest feature. Because the step size is somewhat\n",
      "too large, it has a tendency to overshoot the bottom of the function and thus needs to\n",
      "descend the opposite canyon wall on the next iteration. The large positive eigenvalue\n",
      "of the Hessian corresponding to the eigenvector pointed in this direction indicates that\n",
      "this directional derivative is rapidly increasing, so an optimization algorithm based on\n",
      "the Hessian could predict that the steepest direction is not actually a promising search\n",
      "direction in this context.\n",
      "91\n",
      "\n",
      "CHAPTER 4.\n",
      "NUMERICAL COMPUTATION\n",
      "the search. The simplest method for doing so is known as Newton’s method.\n",
      "Newton’s method is based on using a second-order Taylor series expansion to\n",
      "approximate\n",
      "near some point\n",
      "f( )\n",
      "x\n",
      "x(0):\n",
      "f\n",
      "f\n",
      "( ) \n",
      "x ≈\n",
      "(x(0))+(x\n",
      "x\n",
      "−\n",
      "(0))∇xf(x(0))+ 1\n",
      "2(x\n",
      "x\n",
      "−\n",
      "(0))H\n",
      "x\n",
      "( )(\n",
      "f\n",
      "(0) )(x\n",
      "x\n",
      "−\n",
      "(0)). (4.11)\n",
      "If we then solve for the critical point of this function, we obtain:\n",
      "x∗= x(0) −H\n",
      "x\n",
      "( )(\n",
      "f\n",
      "(0))−1∇xf(x(0)).\n",
      "(4.12)\n",
      "When f is a positive deﬁnite quadratic function, Newton’s method consists of\n",
      "applying equation\n",
      "once to jump to the minimum of the function directly.\n",
      "4.12\n",
      "When f is not truly quadratic but can be locally approximated as a positive\n",
      "deﬁnite quadratic, Newton’s method consists of applying equation\n",
      "multiple\n",
      "4.12\n",
      "times. Iteratively updating the approximation and jumping to the minimum of\n",
      "the approximation can reach the critical point much faster than gradient descent\n",
      "would. This is a useful property near a local minimum, but it can be a harmful\n",
      "property near a saddle point. As discussed in section\n",
      ", Newton’s method is\n",
      "8.2.3\n",
      "only appropriate when the nearby critical point is a minimum (all the eigenvalues\n",
      "of the Hessian are positive), whereas gradient descent is not attracted to saddle\n",
      "points unless the gradient points toward them.\n",
      "Optimization algorithms that use only the gradient, such as gradient descent,\n",
      "are called ﬁrst-order optimization algorithms. Optimization algorithms that\n",
      "also use the Hessian matrix, such as Newton’s method, are called second-order\n",
      "optimization algorithms (Nocedal and Wright 2006\n",
      ",\n",
      ").\n",
      "The optimization algorithms employed in most contexts in this book are\n",
      "applicable to a wide variety of functions, but come with almost no guarantees.\n",
      "Deep learning algorithms tend to lack guarantees because the family of functions\n",
      "used in deep learning is quite complicated. In many other ﬁelds, the dominant\n",
      "approach to optimization is to design optimization algorithms for a limited family\n",
      "of functions.\n",
      "In the context of deep learning, we sometimes gain some guarantees by restrict-\n",
      "ing ourselves to functions that are either Lipschitz continuous or have Lipschitz\n",
      "continuous derivatives. A Lipschitz continuous function is a function f whose rate\n",
      "of change is bounded by a Lipschitz constant L:\n",
      "∀\n",
      "∀\n",
      "|\n",
      "−\n",
      "| ≤L||\n",
      "−\n",
      "||\n",
      "x, y, f( )\n",
      "x\n",
      "f( )\n",
      "y\n",
      "x\n",
      "y 2.\n",
      "(4.13)\n",
      "This property is useful because it allows us to quantify our assumption that a\n",
      "small change in the input made by an algorithm such as gradient descent will have\n",
      "92\n",
      "\n",
      "CHAPTER 4.\n",
      "NUMERICAL COMPUTATION\n",
      "a small change in the output. Lipschitz continuity is also a fairly weak constraint,\n",
      "and many optimization problems in deep learning can be made Lipschitz continuous\n",
      "with relatively minor modiﬁcations.\n",
      "Perhaps the most successful ﬁeld of specialized optimization is convex op-\n",
      "timization. Convex optimization algorithms are able to provide many more\n",
      "guarantees by making stronger restrictions. Convex optimization algorithms are\n",
      "applicable only to convex functions—functions for which the Hessian is positive\n",
      "semideﬁnite everywhere. Such functions are well-behaved because they lack saddle\n",
      "points and all of their local minima are necessarily global minima. However, most\n",
      "problems in deep learning are diﬃcult to express in terms of convex optimization.\n",
      "Convex optimization is used only as a subroutine of some deep learning algorithms.\n",
      "Ideas from the analysis of convex optimization algorithms can be useful for proving\n",
      "the convergence of deep learning algorithms. However, in general, the importance\n",
      "of convex optimization is greatly diminished in the context of deep learning. For\n",
      "more information about convex optimization, see Boyd and Vandenberghe 2004\n",
      "(\n",
      ")\n",
      "or Rockafellar 1997\n",
      "(\n",
      ").\n",
      "4.4\n",
      "Constrained Optimization\n",
      "Sometimes we wish not only to maximize or minimize a function f(x) over all\n",
      "possible values of x.\n",
      "Instead we may wish to ﬁnd the maximal or minimal\n",
      "value of f(x) for values of x in some set S.\n",
      "This is known as constrained\n",
      "optimization. Points x that lie within the set S are called feasible points in\n",
      "constrained optimization terminology.\n",
      "We often wish to ﬁnd a solution that is small in some sense. A common\n",
      "approach in such situations is to impose a norm constraint, such as\n",
      ".\n",
      "|| || ≤\n",
      "x\n",
      "1\n",
      "One simple approach to constrained optimization is simply to modify gradient\n",
      "descent taking the constraint into account. If we use a small constant step size ,\n",
      "we can make gradient descent steps, then project the result back into S. If we use\n",
      "a line search, we can search only over step sizes that yield new x points that are\n",
      "feasible, or we can project each point on the line back into the constraint region.\n",
      "When possible, this method can be made more eﬃcient by projecting the gradient\n",
      "into the tangent space of the feasible region before taking the step or beginning\n",
      "the line search (\n",
      ",\n",
      ").\n",
      "Rosen 1960\n",
      "A more sophisticated approach is to design a diﬀerent, unconstrained opti-\n",
      "mization problem whose solution can be converted into a solution to the original,\n",
      "constrained optimization problem. For example, if we want to minimize f(x) for\n",
      "93\n",
      "\n",
      "CHAPTER 4.\n",
      "NUMERICAL COMPUTATION\n",
      "x ∈R2 with x constrained to have exactly unit L2 norm, we can instead minimize\n",
      "g(θ) = f ([cos\n",
      "sin\n",
      "θ,\n",
      "θ] ) with respect to θ, then return [cos\n",
      "sin\n",
      "θ,\n",
      "θ] as the solution\n",
      "to the original problem. This approach requires creativity; the transformation\n",
      "between optimization problems must be designed speciﬁcally for each case we\n",
      "encounter.\n",
      "The Karush–Kuhn–Tucker (KKT) approach1 provides a very general so-\n",
      "lution to constrained optimization. With the KKT approach, we introduce a\n",
      "new function called the generalized Lagrangian or generalized Lagrange\n",
      "function.\n",
      "To deﬁne the Lagrangian, we ﬁrst need to describe S in terms of equations\n",
      "and inequalities. We want a description of S in terms of m functions g( )i and n\n",
      "functions h( )\n",
      "j so that S = {\n",
      "| ∀\n",
      "x\n",
      "i, g( )i (x) = 0 and ∀j, h( )\n",
      "j (x) ≤0}. The equations\n",
      "involving g( )i are called the equality constraints and the inequalities involving\n",
      "h( )\n",
      "j are called\n",
      ".\n",
      "inequality constraints\n",
      "We introduce new variables λi andα j for each constraint, these are called the\n",
      "KKT multipliers. The generalized Lagrangian is then deﬁned as\n",
      "L\n",
      ",\n",
      ",\n",
      "f\n",
      "(x λ α) = ( ) +\n",
      "x\n",
      "\n",
      "i\n",
      "λig( )i ( ) +\n",
      "x\n",
      "\n",
      "j\n",
      "αjh( )\n",
      "j ( )\n",
      "x .\n",
      "(4.14)\n",
      "We can now solve a constrained minimization problem using unconstrained\n",
      "optimization of the generalized Lagrangian. Observe that, so long as at least one\n",
      "feasible point exists and\n",
      "is not permitted to have value\n",
      ", then\n",
      "f( )\n",
      "x\n",
      "∞\n",
      "min\n",
      "x max\n",
      "λ\n",
      "max\n",
      "α α\n",
      ",\n",
      "≥0 L\n",
      ",\n",
      ",\n",
      ".\n",
      "(x λ α)\n",
      "(4.15)\n",
      "has the same optimal objective function value and set of optimal points\n",
      "as\n",
      "x\n",
      "min\n",
      "x∈S f\n",
      ".\n",
      "( )\n",
      "x\n",
      "(4.16)\n",
      "This follows because any time the constraints are satisﬁed,\n",
      "max\n",
      "λ\n",
      "max\n",
      "α α\n",
      ",\n",
      "≥0L\n",
      ",\n",
      ",\n",
      "f\n",
      ",\n",
      "(x λ α) = ( )\n",
      "x\n",
      "(4.17)\n",
      "while any time a constraint is violated,\n",
      "max\n",
      "λ\n",
      "max\n",
      "α α\n",
      ",\n",
      "≥0 L\n",
      ",\n",
      ",\n",
      ".\n",
      "(x λ α) = ∞\n",
      "(4.18)\n",
      "1The KKT approach generalizes the method of Lagrange multipliers which allows equality\n",
      "constraints but not inequality constraints.\n",
      "94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "doc = fitz.open(pdf_path) \n",
    "\n",
    "for page in doc[100:110]:\n",
    "    text = page.get_text()\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a695edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN TEXT \n",
    "\n",
    "def text_formatter(text: str) -> str:\n",
    "    return text.replace(\"\\n\", \" \").replace(\"\\\\n\", \" \").strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18c89f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_and_read_pdf(pdf_path):\n",
    "    import fitz  # PyMuPDF\n",
    "    doc = fitz.open(pdf_path)\n",
    "    pages_and_texts = []\n",
    "\n",
    "    for page_number, page in enumerate(doc, start=1):\n",
    "        text = page.get_text()\n",
    "        \n",
    "        if not text:\n",
    "            continue  # skip pages with no extractable text\n",
    "\n",
    "        text = text_formatter(text)  # your formatting function\n",
    "\n",
    "        pages_and_texts.append({\n",
    "            \"page_number\": page_number - 17,\n",
    "            \"page_char_count\": len(text),\n",
    "            \"page_word_count\": len(text.split()),\n",
    "            \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "            \"page_token_count\": len(text) / 4,\n",
    "            \"text\": text\n",
    "        })\n",
    "\n",
    "    return pages_and_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b42612e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': -15,\n",
       "  'page_char_count': 58,\n",
       "  'page_word_count': 8,\n",
       "  'page_sentence_count_raw': 1,\n",
       "  'page_token_count': 14.5,\n",
       "  'text': 'Deep Learning Ian Goodfellow Yoshua Bengio Aaron Courville'},\n",
       " {'page_number': -14,\n",
       "  'page_char_count': 1319,\n",
       "  'page_word_count': 425,\n",
       "  'page_sentence_count_raw': 315,\n",
       "  'page_token_count': 329.75,\n",
       "  'text': 'Contents Website vii Acknowledgments viii Notation xi 1 Introduction 1 1.1 Who Should Read This Book? . . . . . . . . . . . . . . . . . . . . 8 1.2 Historical Trends in Deep Learning . . . . . . . . . . . . . . . . . 11 I Applied Math and Machine Learning Basics 29 2 Linear Algebra 31 2.1 Scalars, Vectors, Matrices and Tensors . . . . . . . . . . . . . . . 31 2.2 Multiplying Matrices and Vectors . . . . . . . . . . . . . . . . . . 34 2.3 Identity and Inverse Matrices . . . . . . . . . . . . . . . . . . . . 36 2.4 Linear Dependence and Span . . . . . . . . . . . . . . . . . . . . 37 2.5 Norms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 2.6 Special Kinds of Matrices and Vectors . . . . . . . . . . . . . . . 40 2.7 Eigendecomposition . . . . . . . . . . . . . . . . . . . . . . . . . . 42 2.8 Singular Value Decomposition . . . . . . . . . . . . . . . . . . . . 44 2.9 The Moore-Penrose Pseudoinverse . . . . . . . . . . . . . . . . . . 45 2.10 The Trace Operator . . . . . . . . . . . . . . . . . . . . . . . . . 46 2.11 The Determinant . . . . . . . . . . . . . . . . . . . . . . . . . . . 47 2.12 Example: Principal Components Analysis . . . . . . . . . . . . . 48 3 Probability and Information Theory 53 3.1 Why Probability? . . . . . . . . . . . . . . . . . . . . . . . . . . . 54 i'},\n",
       " {'page_number': -13,\n",
       "  'page_char_count': 2504,\n",
       "  'page_word_count': 799,\n",
       "  'page_sentence_count_raw': 619,\n",
       "  'page_token_count': 626.0,\n",
       "  'text': 'CONTENTS 3.2 Random Variables . . . . . . . . . . . . . . . . . . . . . . . . . . 56 3.3 Probability Distributions . . . . . . . . . . . . . . . . . . . . . . . 56 3.4 Marginal Probability . . . . . . . . . . . . . . . . . . . . . . . . . 58 3.5 Conditional Probability . . . . . . . . . . . . . . . . . . . . . . . 59 3.6 The Chain Rule of Conditional Probabilities . . . . . . . . . . . . 59 3.7 Independence and Conditional Independence . . . . . . . . . . . . 60 3.8 Expectation, Variance and Covariance . . . . . . . . . . . . . . . 60 3.9 Common Probability Distributions . . . . . . . . . . . . . . . . . 62 3.10 Useful Properties of Common Functions . . . . . . . . . . . . . . 67 3.11 Bayes’ Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70 3.12 Technical Details of Continuous Variables . . . . . . . . . . . . . 71 3.13 Information Theory . . . . . . . . . . . . . . . . . . . . . . . . . . 73 3.14 Structured Probabilistic Models . . . . . . . . . . . . . . . . . . . 75 4 Numerical Computation 80 4.1 Overﬂow and Underﬂow . . . . . . . . . . . . . . . . . . . . . . . 80 4.2 Poor Conditioning . . . . . . . . . . . . . . . . . . . . . . . . . . 82 4.3 Gradient-Based Optimization . . . . . . . . . . . . . . . . . . . . 82 4.4 Constrained Optimization . . . . . . . . . . . . . . . . . . . . . . 93 4.5 Example: Linear Least Squares . . . . . . . . . . . . . . . . . . . 96 5 Machine Learning Basics 98 5.1 Learning Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . 99 5.2 Capacity, Overﬁtting and Underﬁtting . . . . . . . . . . . . . . . 110 5.3 Hyperparameters and Validation Sets . . . . . . . . . . . . . . . . 120 5.4 Estimators, Bias and Variance . . . . . . . . . . . . . . . . . . . . 122 5.5 Maximum Likelihood Estimation . . . . . . . . . . . . . . . . . . 131 5.6 Bayesian Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . 135 5.7 Supervised Learning Algorithms . . . . . . . . . . . . . . . . . . . 140 5.8 Unsupervised Learning Algorithms . . . . . . . . . . . . . . . . . 146 5.9 Stochastic Gradient Descent . . . . . . . . . . . . . . . . . . . . . 151 5.10 Building a Machine Learning Algorithm . . . . . . . . . . . . . . 153 5.11 Challenges Motivating Deep Learning . . . . . . . . . . . . . . . . 155 II Deep Networks: Modern Practices 166 6 Deep Feedforward Networks 168 6.1 Example: Learning XOR . . . . . . . . . . . . . . . . . . . . . . . 171 6.2 Gradient-Based Learning . . . . . . . . . . . . . . . . . . . . . . . 177 ii'},\n",
       " {'page_number': -12,\n",
       "  'page_char_count': 2731,\n",
       "  'page_word_count': 870,\n",
       "  'page_sentence_count_raw': 670,\n",
       "  'page_token_count': 682.75,\n",
       "  'text': 'CONTENTS 6.3 Hidden Units . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191 6.4 Architecture Design . . . . . . . . . . . . . . . . . . . . . . . . . . 197 6.5 Back-Propagation and Other Diﬀerentiation Algorithms . . . . . 204 6.6 Historical Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224 7 Regularization for Deep Learning 228 7.1 Parameter Norm Penalties . . . . . . . . . . . . . . . . . . . . . . 230 7.2 Norm Penalties as Constrained Optimization . . . . . . . . . . . . 237 7.3 Regularization and Under-Constrained Problems . . . . . . . . . 239 7.4 Dataset Augmentation . . . . . . . . . . . . . . . . . . . . . . . . 240 7.5 Noise Robustness . . . . . . . . . . . . . . . . . . . . . . . . . . . 242 7.6 Semi-Supervised Learning . . . . . . . . . . . . . . . . . . . . . . 243 7.7 Multi-Task Learning . . . . . . . . . . . . . . . . . . . . . . . . . 244 7.8 Early Stopping . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246 7.9 Parameter Tying and Parameter Sharing . . . . . . . . . . . . . . 253 7.10 Sparse Representations . . . . . . . . . . . . . . . . . . . . . . . . 254 7.11 Bagging and Other Ensemble Methods . . . . . . . . . . . . . . . 256 7.12 Dropout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258 7.13 Adversarial Training . . . . . . . . . . . . . . . . . . . . . . . . . 268 7.14 Tangent Distance, Tangent Prop, and Manifold Tangent Classiﬁer 270 8 Optimization for Training Deep Models 274 8.1 How Learning Diﬀers from Pure Optimization . . . . . . . . . . . 275 8.2 Challenges in Neural Network Optimization . . . . . . . . . . . . 282 8.3 Basic Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . 294 8.4 Parameter Initialization Strategies . . . . . . . . . . . . . . . . . 301 8.5 Algorithms with Adaptive Learning Rates . . . . . . . . . . . . . 306 8.6 Approximate Second-Order Methods . . . . . . . . . . . . . . . . 310 8.7 Optimization Strategies and Meta-Algorithms . . . . . . . . . . . 317 9 Convolutional Networks 330 9.1 The Convolution Operation . . . . . . . . . . . . . . . . . . . . . 331 9.2 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 335 9.3 Pooling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 339 9.4 Convolution and Pooling as an Inﬁnitely Strong Prior . . . . . . . 345 9.5 Variants of the Basic Convolution Function . . . . . . . . . . . . 347 9.6 Structured Outputs . . . . . . . . . . . . . . . . . . . . . . . . . . 358 9.7 Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360 9.8 Eﬃcient Convolution Algorithms . . . . . . . . . . . . . . . . . . 362 9.9 Random or Unsupervised Features . . . . . . . . . . . . . . . . . 363 iii'},\n",
       " {'page_number': -11,\n",
       "  'page_char_count': 2411,\n",
       "  'page_word_count': 730,\n",
       "  'page_sentence_count_raw': 539,\n",
       "  'page_token_count': 602.75,\n",
       "  'text': 'CONTENTS 9.10 The Neuroscientiﬁc Basis for Convolutional Networks . . . . . . . 364 9.11 Convolutional Networks and the History of Deep Learning . . . . 371 10 Sequence Modeling: Recurrent and Recursive Nets 373 10.1 Unfolding Computational Graphs . . . . . . . . . . . . . . . . . . 375 10.2 Recurrent Neural Networks . . . . . . . . . . . . . . . . . . . . . 378 10.3 Bidirectional RNNs . . . . . . . . . . . . . . . . . . . . . . . . . . 394 10.4 Encoder-Decoder Sequence-to-Sequence Architectures . . . . . . . 396 10.5 Deep Recurrent Networks . . . . . . . . . . . . . . . . . . . . . . 398 10.6 Recursive Neural Networks . . . . . . . . . . . . . . . . . . . . . . 400 10.7 The Challenge of Long-Term Dependencies . . . . . . . . . . . . . 401 10.8 Echo State Networks . . . . . . . . . . . . . . . . . . . . . . . . . 404 10.9 Leaky Units and Other Strategies for Multiple Time Scales . . . . 406 10.10 The Long Short-Term Memory and Other Gated RNNs . . . . . . 408 10.11 Optimization for Long-Term Dependencies . . . . . . . . . . . . . 413 10.12 Explicit Memory . . . . . . . . . . . . . . . . . . . . . . . . . . . 416 11 Practical Methodology 421 11.1 Performance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . 422 11.2 Default Baseline Models . . . . . . . . . . . . . . . . . . . . . . . 425 11.3 Determining Whether to Gather More Data . . . . . . . . . . . . 426 11.4 Selecting Hyperparameters . . . . . . . . . . . . . . . . . . . . . . 427 11.5 Debugging Strategies . . . . . . . . . . . . . . . . . . . . . . . . . 436 11.6 Example: Multi-Digit Number Recognition . . . . . . . . . . . . . 440 12 Applications 443 12.1 Large-Scale Deep Learning . . . . . . . . . . . . . . . . . . . . . . 443 12.2 Computer Vision . . . . . . . . . . . . . . . . . . . . . . . . . . . 452 12.3 Speech Recognition . . . . . . . . . . . . . . . . . . . . . . . . . . 458 12.4 Natural Language Processing . . . . . . . . . . . . . . . . . . . . 461 12.5 Other Applications . . . . . . . . . . . . . . . . . . . . . . . . . . 478 III Deep Learning Research 486 13 Linear Factor Models 489 13.1 Probabilistic PCA and Factor Analysis . . . . . . . . . . . . . . . 490 13.2 Independent Component Analysis (ICA) . . . . . . . . . . . . . . 491 13.3 Slow Feature Analysis . . . . . . . . . . . . . . . . . . . . . . . . 493 13.4 Sparse Coding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 496 iv'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_texts = open_and_read_pdf(pdf_path = pdf_path) \n",
    "pages_and_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "52e3c996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 317,\n",
       "  'page_char_count': 2777,\n",
       "  'page_word_count': 497,\n",
       "  'page_sentence_count_raw': 31,\n",
       "  'page_token_count': 694.25,\n",
       "  'text': 'CHAPTER 8. OPTIMIZATION FOR TRAINING DEEP MODELS example, suppose we have a deep neural network that has only one unit per layer and does not use an activation function at each hidden layer: ˆy = xw1w2w3 . . . wl. Here, wi provides the weight used by layer i. The output of layer i is hi = hi−1wi. The output ˆy is a linear function of the input x, but a nonlinear function of the weights wi. Suppose our cost function has put a gradient of on 1 ˆy, so we wish to decrease ˆy slightly. The back-propagation algorithm can then compute a gradient g = ∇wˆy. Consider what happens when we make an update w w g ← −\\ue00f. The ﬁrst-order Taylor series approximation of ˆy predicts that the value of ˆy will decrease by \\ue00fg\\ue03eg. If we wanted to decrease ˆy by .1, this ﬁrst-order information available in the gradient suggests we could set the learning rate \\ue00fto .1 g \\ue03eg . However, the actual update will include second-order and third-order eﬀects, on up to eﬀects of order l. The new value of ˆy is given by x w ( 1 −\\ue00fg1)(w2 −\\ue00fg 2) ( . . . wl −\\ue00fgl). (8.34) An example of one second-order term arising from this update is \\ue00f2g1 g2 \\ue051l i=3 wi. This term might be negligible if \\ue051l i=3wi is small, or might be exponentially large if the weights on layers through 3 l are greater than . This makes it very hard 1 to choose an appropriate learning rate, because the eﬀects of an update to the parameters for one layer depends so strongly on all of the other layers. Second-order optimization algorithms address this issue by computing an update that takes these second-order interactions into account, but we can see that in very deep networks, even higher-order interactions can be signiﬁcant. Even second-order optimization algorithms are expensive and usually require numerous approximations that prevent them from truly accounting for all signiﬁcant second-order interactions. Building an n-th order optimization algorithm for n > 2 thus seems hopeless. What can we do instead? Batch normalization provides an elegant way of reparametrizing almost any deep network. The reparametrization signiﬁcantly reduces the problem of coordinating updates across many layers. Batch normalization can be applied to any input or hidden layer in a network. Let H be a minibatch of activations of the layer to normalize, arranged as a design matrix, with the activations for each example appearing in a row of the matrix. To normalize , we replace it with H H\\ue030= H µ − σ , (8.35) where µ is a vector containing the mean of each unit and σ is a vector containing the standard deviation of each unit. The arithmetic here is based on broadcasting the vector µ and the vector σ to be applied to every row of the matrix H . Within each row, the arithmetic is element-wise, so Hi,j is normalized by subtracting µj 318'},\n",
       " {'page_number': 183,\n",
       "  'page_char_count': 2530,\n",
       "  'page_word_count': 429,\n",
       "  'page_sentence_count_raw': 20,\n",
       "  'page_token_count': 632.5,\n",
       "  'text': 'CHAPTER 6. DEEP FEEDFORWARD NETWORKS (1 −2y)z, may be simpliﬁed to | |z . As | |z becomes large while z has the wrong sign, the softplus function asymptotes toward simply returning its argument | |z . The derivative with respect to z asymptotes to sign(z), so, in the limit of extremely incorrect z, the softplus function does not shrink the gradient at all. This property is very useful because it means that gradient-based learning can act to quickly correct a mistaken . z When we use other loss functions, such as mean squared error, the loss can saturate anytime σ(z) saturates. The sigmoid activation function saturates to 0 when z becomes very negative and saturates to when 1 z becomes very positive. The gradient can shrink too small to be useful for learning whenever this happens, whether the model has the correct answer or the incorrect answer. For this reason, maximum likelihood is almost always the preferred approach to training sigmoid output units. Analytically, the logarithm of the sigmoid is always deﬁned and ﬁnite, because the sigmoid returns values restricted to the open interval (0, 1), rather than using the entire closed interval of valid probabilities [0,1]. In software implementations, to avoid numerical problems, it is best to write the negative log-likelihood as a function of z, rather than as a function of ˆy = σ(z ). If the sigmoid function underﬂows to zero, then taking the logarithm of ˆy yields negative inﬁnity. 6.2.2.3 Softmax Units for Multinoulli Output Distributions Any time we wish to represent a probability distribution over a discrete variable with n possible values, we may use the softmax function. This can be seen as a generalization of the sigmoid function which was used to represent a probability distribution over a binary variable. Softmax functions are most often used as the output of a classiﬁer, to represent the probability distribution over n diﬀerent classes. More rarely, softmax functions can be used inside the model itself, if we wish the model to choose between one of n diﬀerent options for some internal variable. In the case of binary variables, we wished to produce a single number ˆy P y . = ( = 1  ) | x (6.27) Because this number needed to lie between and , and because we wanted the 0 1 logarithm of the number to be well-behaved for gradient-based optimization of the log-likelihood, we chose to instead predict a number z = log ˜P(y = 1 | x). Exponentiating and normalizing gave us a Bernoulli distribution controlled by the sigmoid function. 184'},\n",
       " {'page_number': 332,\n",
       "  'page_char_count': 2382,\n",
       "  'page_word_count': 395,\n",
       "  'page_sentence_count_raw': 18,\n",
       "  'page_token_count': 595.5,\n",
       "  'text': 'CHAPTER 9. CONVOLUTIONAL NETWORKS is useful for writing proofs, it is not usually an important property of a neural network implementation. Instead, many neural network libraries implement a related function called the cross-correlation, which is the same as convolution but without ﬂipping the kernel: S i, j I K i, j ( ) = ( ∗ )( ) = \\ue058 m \\ue058 n I i m, j n K m, n . ( + + ) ( ) (9.6) Many machine learning libraries implement cross-correlation but call it convolution. In this text we will follow this convention of calling both operations convolution, and specify whether we mean to ﬂip the kernel or not in contexts where kernel ﬂipping is relevant. In the context of machine learning, the learning algorithm will learn the appropriate values of the kernel in the appropriate place, so an algorithm based on convolution with kernel ﬂipping will learn a kernel that is ﬂipped relative to the kernel learned by an algorithm without the ﬂipping. It is also rare for convolution to be used alone in machine learning; instead convolution is used simultaneously with other functions, and the combination of these functions does not commute regardless of whether the convolution operation ﬂips its kernel or not. See ﬁgure for an example of convolution (without kernel ﬂipping) applied 9.1 to a 2-D tensor. Discrete convolution can be viewed as multiplication by a matrix. However, the matrix has several entries constrained to be equal to other entries. For example, for univariate discrete convolution, each row of the matrix is constrained to be equal to the row above shifted by one element. This is known as a Toeplitz matrix. In two dimensions, a doubly block circulant matrix corresponds to convolution. In addition to these constraints that several elements be equal to each other, convolution usually corresponds to a very sparse matrix (a matrix whose entries are mostly equal to zero). This is because the kernel is usually much smaller than the input image. Any neural network algorithm that works with matrix multiplication and does not depend on speciﬁc properties of the matrix structure should work with convolution, without requiring any further changes to the neural network. Typical convolutional neural networks do make use of further specializations in order to deal with large inputs eﬃciently, but these are not strictly necessary from a theoretical perspective. 333'}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "random.sample(pages_and_texts, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9a405f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-15</td>\n",
       "      <td>58</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>14.50</td>\n",
       "      <td>Deep Learning Ian Goodfellow Yoshua Bengio Aar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-14</td>\n",
       "      <td>1319</td>\n",
       "      <td>425</td>\n",
       "      <td>315</td>\n",
       "      <td>329.75</td>\n",
       "      <td>Contents Website vii Acknowledgments viii Nota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-13</td>\n",
       "      <td>2504</td>\n",
       "      <td>799</td>\n",
       "      <td>619</td>\n",
       "      <td>626.00</td>\n",
       "      <td>CONTENTS 3.2 Random Variables . . . . . . . . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-12</td>\n",
       "      <td>2731</td>\n",
       "      <td>870</td>\n",
       "      <td>670</td>\n",
       "      <td>682.75</td>\n",
       "      <td>CONTENTS 6.3 Hidden Units . . . . . . . . . . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-11</td>\n",
       "      <td>2411</td>\n",
       "      <td>730</td>\n",
       "      <td>539</td>\n",
       "      <td>602.75</td>\n",
       "      <td>CONTENTS 9.10 The Neuroscientiﬁc Basis for Con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "0          -15               58                8                        1   \n",
       "1          -14             1319              425                      315   \n",
       "2          -13             2504              799                      619   \n",
       "3          -12             2731              870                      670   \n",
       "4          -11             2411              730                      539   \n",
       "\n",
       "   page_token_count                                               text  \n",
       "0             14.50  Deep Learning Ian Goodfellow Yoshua Bengio Aar...  \n",
       "1            329.75  Contents Website vii Acknowledgments viii Nota...  \n",
       "2            626.00  CONTENTS 3.2 Random Variables . . . . . . . . ...  \n",
       "3            682.75  CONTENTS 6.3 Hidden Units . . . . . . . . . . ...  \n",
       "4            602.75  CONTENTS 9.10 The Neuroscientiﬁc Basis for Con...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame(pages_and_texts) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0309d5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800.00</td>\n",
       "      <td>800.00</td>\n",
       "      <td>800.00</td>\n",
       "      <td>800.00</td>\n",
       "      <td>800.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>384.50</td>\n",
       "      <td>2223.28</td>\n",
       "      <td>378.88</td>\n",
       "      <td>26.79</td>\n",
       "      <td>555.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>231.08</td>\n",
       "      <td>612.58</td>\n",
       "      <td>103.48</td>\n",
       "      <td>46.86</td>\n",
       "      <td>153.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-15.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>184.75</td>\n",
       "      <td>1884.75</td>\n",
       "      <td>335.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>471.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>384.50</td>\n",
       "      <td>2356.50</td>\n",
       "      <td>398.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>589.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>584.25</td>\n",
       "      <td>2668.75</td>\n",
       "      <td>450.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>667.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>784.00</td>\n",
       "      <td>3168.00</td>\n",
       "      <td>870.00</td>\n",
       "      <td>670.00</td>\n",
       "      <td>792.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count       800.00           800.00           800.00                   800.00   \n",
       "mean        384.50          2223.28           378.88                    26.79   \n",
       "std         231.08           612.58           103.48                    46.86   \n",
       "min         -15.00            35.00             6.00                     1.00   \n",
       "25%         184.75          1884.75           335.00                    16.00   \n",
       "50%         384.50          2356.50           398.00                    20.00   \n",
       "75%         584.25          2668.75           450.00                    24.00   \n",
       "max         784.00          3168.00           870.00                   670.00   \n",
       "\n",
       "       page_token_count  \n",
       "count            800.00  \n",
       "mean             555.82  \n",
       "std              153.15  \n",
       "min                8.75  \n",
       "25%              471.19  \n",
       "50%              589.12  \n",
       "75%              667.19  \n",
       "max              792.00  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().round(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeb100d",
   "metadata": {},
   "source": [
    "## Splitting using spacy is more efficient than using text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a5abe3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[As an example we will we use this., and this is another sentence.]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "lang = English()\n",
    "\n",
    "lang.add_pipe(\"sentencizer\")\n",
    "doc = lang(\"As an example we will we use this. and this is another sentence.\")\n",
    "\n",
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "41237059",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:01<00:00, 483.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentences\"] = list(lang(item[\"text\"]).sents)\n",
    "    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]] \n",
    "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7fd2cffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 373,\n",
       "  'page_char_count': 2663,\n",
       "  'page_word_count': 448,\n",
       "  'page_sentence_count_raw': 26,\n",
       "  'page_token_count': 665.75,\n",
       "  'text': 'CHAPTER 10. SEQUENCE MODELING: RECURRENT AND RECURSIVE NETS word or the second word of the sentence. Suppose that we trained a feedforward network that processes sentences of ﬁxed length. A traditional fully connected feedforward network would have separate parameters for each input feature, so it would need to learn all of the rules of the language separately at each position in the sentence. By comparison, a recurrent neural network shares the same weights across several time steps. A related idea is the use of convolution across a 1-D temporal sequence. This convolutional approach is the basis for time-delay neural networks (Lang and Hinton 1988 Waibel 1989 Lang 1990 , ; et al., ; et al., ). The convolution operation allows a network to share parameters across time, but is shallow. The output of convolution is a sequence where each member of the output is a function of a small number of neighboring members of the input. The idea of parameter sharing manifests in the application of the same convolution kernel at each time step. Recurrent networks share parameters in a diﬀerent way. Each member of the output is a function of the previous members of the output. Each member of the output is produced using the same update rule applied to the previous outputs. This recurrent formulation results in the sharing of parameters through a very deep computational graph. For the simplicity of exposition, we refer to RNNs as operating on a sequence that contains vectors x( )t with the time step index t ranging from to 1 τ. In practice, recurrent networks usually operate on minibatches of such sequences, with a diﬀerent sequence length τ for each member of the minibatch. We have omitted the minibatch indices to simplify notation. Moreover, the time step index need not literally refer to the passage of time in the real world. Sometimes it refers only to the position in the sequence. RNNs may also be applied in two dimensions across spatial data such as images, and even when applied to data involving time, the network may have connections that go backwards in time, provided that the entire sequence is observed before it is provided to the network. This chapter extends the idea of a computational graph to include cycles. These cycles represent the inﬂuence of the present value of a variable on its own value at a future time step. Such computational graphs allow us to deﬁne recurrent neural networks. We then describe many diﬀerent ways to construct, train, and use recurrent neural networks. For more information on recurrent neural networks than is available in this chapter, we refer the reader to the textbook of Graves 2012 ( ). 374',\n",
       "  'sentences': ['CHAPTER 10.',\n",
       "   'SEQUENCE MODELING: RECURRENT AND RECURSIVE NETS word or the second word of the sentence.',\n",
       "   'Suppose that we trained a feedforward network that processes sentences of ﬁxed length.',\n",
       "   'A traditional fully connected feedforward network would have separate parameters for each input feature, so it would need to learn all of the rules of the language separately at each position in the sentence.',\n",
       "   'By comparison, a recurrent neural network shares the same weights across several time steps.',\n",
       "   'A related idea is the use of convolution across a 1-D temporal sequence.',\n",
       "   'This convolutional approach is the basis for time-delay neural networks (Lang and Hinton 1988 Waibel 1989 Lang 1990 , ; et al., ;',\n",
       "   'et al., ).',\n",
       "   'The convolution operation allows a network to share parameters across time, but is shallow.',\n",
       "   'The output of convolution is a sequence where each member of the output is a function of a small number of neighboring members of the input.',\n",
       "   'The idea of parameter sharing manifests in the application of the same convolution kernel at each time step.',\n",
       "   'Recurrent networks share parameters in a diﬀerent way.',\n",
       "   'Each member of the output is a function of the previous members of the output.',\n",
       "   'Each member of the output is produced using the same update rule applied to the previous outputs.',\n",
       "   'This recurrent formulation results in the sharing of parameters through a very deep computational graph.',\n",
       "   'For the simplicity of exposition, we refer to RNNs as operating on a sequence that contains vectors x( )t with the time step index t ranging from to 1 τ.',\n",
       "   'In practice, recurrent networks usually operate on minibatches of such sequences, with a diﬀerent sequence length τ for each member of the minibatch.',\n",
       "   'We have omitted the minibatch indices to simplify notation.',\n",
       "   'Moreover, the time step index need not literally refer to the passage of time in the real world.',\n",
       "   'Sometimes it refers only to the position in the sequence.',\n",
       "   'RNNs may also be applied in two dimensions across spatial data such as images, and even when applied to data involving time, the network may have connections that go backwards in time, provided that the entire sequence is observed before it is provided to the network.',\n",
       "   'This chapter extends the idea of a computational graph to include cycles.',\n",
       "   'These cycles represent the inﬂuence of the present value of a variable on its own value at a future time step.',\n",
       "   'Such computational graphs allow us to deﬁne recurrent neural networks.',\n",
       "   'We then describe many diﬀerent ways to construct, train, and use recurrent neural networks.',\n",
       "   'For more information on recurrent neural networks than is available in this chapter, we refer the reader to the textbook of Graves 2012 ( ).',\n",
       "   '374'],\n",
       "  'page_sentence_count_spacy': 27},\n",
       " {'page_number': 335,\n",
       "  'page_char_count': 541,\n",
       "  'page_word_count': 113,\n",
       "  'page_sentence_count_raw': 5,\n",
       "  'page_token_count': 135.25,\n",
       "  'text': 'CHAPTER 9. CONVOLUTIONAL NETWORKS x1 x1 x2 x2 x3 x3 s2 s2 s1 s1 s3 s3 x4 x4 s4 s4 x5 x5 s5 s5 x1 x1 x2 x2 x3 x3 s2 s2 s1 s1 s3 s3 x4 x4 s4 s4 x5 x5 s5 s5 Figure 9.2: Sparse connectivity, viewed from below: We highlight one input unit, x3, and also highlight the output units in s that are aﬀected by this unit. (Top)When s is formed by convolution with a kernel of width , only three outputs are aﬀected by 3 x. (Bottom)When is formed by matrix multiplication, connectivity is no longer sparse, so s all of the outputs are aﬀected by x3. 336',\n",
       "  'sentences': ['CHAPTER 9.',\n",
       "   'CONVOLUTIONAL NETWORKS x1 x1 x2 x2 x3 x3 s2 s2 s1 s1 s3 s3 x4 x4 s4 s4 x5 x5 s5 s5 x1 x1 x2 x2 x3 x3 s2 s2 s1 s1 s3 s3 x4 x4 s4 s4 x5 x5 s5 s5 Figure 9.2: Sparse connectivity, viewed from below: We highlight one input unit, x3, and also highlight the output units in s that are aﬀected by this unit. (',\n",
       "   'Top)When s is formed by convolution with a kernel of width , only three outputs are aﬀected by 3 x. (Bottom)When is formed by matrix multiplication, connectivity is no longer sparse, so s all of the outputs are aﬀected by x3.',\n",
       "   '336'],\n",
       "  'page_sentence_count_spacy': 4},\n",
       " {'page_number': 519,\n",
       "  'page_char_count': 1625,\n",
       "  'page_word_count': 265,\n",
       "  'page_sentence_count_raw': 13,\n",
       "  'page_token_count': 406.25,\n",
       "  'text': 'CHAPTER 14. AUTOENCODERS Figure 14.9: If the tangent planes (see ﬁgure ) at each location are known, then they 14.6 can be tiled to form a global coordinate system or a density function. Each local patch can be thought of as a local Euclidean coordinate system or as a locally ﬂat Gaussian, or “pancake,” with a very small variance in the directions orthogonal to the pancake and a very large variance in the directions deﬁning the coordinate system on the pancake. A mixture of these Gaussians provides an estimated density function, as in the manifold Parzen window algorithm ( , ) or its non-local neural-net based Vincent and Bengio 2003 variant ( , ). Bengio et al. 2006c these variations, with no chance to generalize to unseen variations. Indeed, these methods can only generalize the shape of the manifold by interpolating between neighboring examples. Unfortunately, the manifolds involved in AI problems can have very complicated structure that can be diﬃcult to capture from only local interpolation. Consider for example the manifold resulting from translation shown in ﬁgure . If we watch just one coordinate within the input vector, 14.6 xi, as the image is translated, we will observe that one coordinate encounters a peak or a trough in its value once for every peak or trough in brightness in the image. In other words, the complexity of the patterns of brightness in an underlying image template drives the complexity of the manifolds that are generated by performing simple image transformations. This motivates the use of distributed representations and deep learning for capturing manifold structure. 520',\n",
       "  'sentences': ['CHAPTER 14.',\n",
       "   'AUTOENCODERS Figure 14.9: If the tangent planes (see ﬁgure ) at each location are known, then they 14.6 can be tiled to form a global coordinate system or a density function.',\n",
       "   'Each local patch can be thought of as a local Euclidean coordinate system or as a locally ﬂat Gaussian, or “pancake,” with a very small variance in the directions orthogonal to the pancake and a very large variance in the directions deﬁning the coordinate system on the pancake.',\n",
       "   'A mixture of these Gaussians provides an estimated density function, as in the manifold Parzen window algorithm ( , ) or its non-local neural-net based Vincent and Bengio 2003 variant ( , ).',\n",
       "   'Bengio et al.',\n",
       "   '2006c these variations, with no chance to generalize to unseen variations.',\n",
       "   'Indeed, these methods can only generalize the shape of the manifold by interpolating between neighboring examples.',\n",
       "   'Unfortunately, the manifolds involved in AI problems can have very complicated structure that can be diﬃcult to capture from only local interpolation.',\n",
       "   'Consider for example the manifold resulting from translation shown in ﬁgure .',\n",
       "   'If we watch just one coordinate within the input vector, 14.6 xi, as the image is translated, we will observe that one coordinate encounters a peak or a trough in its value once for every peak or trough in brightness in the image.',\n",
       "   'In other words, the complexity of the patterns of brightness in an underlying image template drives the complexity of the manifolds that are generated by performing simple image transformations.',\n",
       "   'This motivates the use of distributed representations and deep learning for capturing manifold structure.',\n",
       "   '520'],\n",
       "  'page_sentence_count_spacy': 13}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_texts, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "86badc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800.00</td>\n",
       "      <td>800.00</td>\n",
       "      <td>800.00</td>\n",
       "      <td>800.00</td>\n",
       "      <td>800.00</td>\n",
       "      <td>800.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>384.50</td>\n",
       "      <td>2223.28</td>\n",
       "      <td>378.88</td>\n",
       "      <td>26.79</td>\n",
       "      <td>555.82</td>\n",
       "      <td>20.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>231.08</td>\n",
       "      <td>612.58</td>\n",
       "      <td>103.48</td>\n",
       "      <td>46.86</td>\n",
       "      <td>153.15</td>\n",
       "      <td>9.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-15.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.75</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>184.75</td>\n",
       "      <td>1884.75</td>\n",
       "      <td>335.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>471.19</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>384.50</td>\n",
       "      <td>2356.50</td>\n",
       "      <td>398.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>589.12</td>\n",
       "      <td>19.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>584.25</td>\n",
       "      <td>2668.75</td>\n",
       "      <td>450.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>667.19</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>784.00</td>\n",
       "      <td>3168.00</td>\n",
       "      <td>870.00</td>\n",
       "      <td>670.00</td>\n",
       "      <td>792.00</td>\n",
       "      <td>55.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count       800.00           800.00           800.00                   800.00   \n",
       "mean        384.50          2223.28           378.88                    26.79   \n",
       "std         231.08           612.58           103.48                    46.86   \n",
       "min         -15.00            35.00             6.00                     1.00   \n",
       "25%         184.75          1884.75           335.00                    16.00   \n",
       "50%         384.50          2356.50           398.00                    20.00   \n",
       "75%         584.25          2668.75           450.00                    24.00   \n",
       "max         784.00          3168.00           870.00                   670.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  \n",
       "count            800.00                     800.00  \n",
       "mean             555.82                      20.01  \n",
       "std              153.15                       9.34  \n",
       "min                8.75                       1.00  \n",
       "25%              471.19                      15.00  \n",
       "50%              589.12                      19.00  \n",
       "75%              667.19                      23.00  \n",
       "max              792.00                      55.00  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts) \n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1b202b",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "739109fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 351244.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define split size to turn groups of sentences into chunks\n",
    "num_sentence_chunk_size = 10 \n",
    "\n",
    "# Create a function that recursively splits a list into desired sizes\n",
    "def split_list(input_list: list, \n",
    "               slice_size: int) -> list[list[str]]:\n",
    "    \"\"\"\n",
    "    Splits the input_list into sublists of size slice_size (or as close as possible).\n",
    "\n",
    "    For example, a list of 17 sentences would be split into two lists of [[10], [7]]\n",
    "    \"\"\"\n",
    "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "\n",
    "# Loop through pages and texts and split sentences into chunks\n",
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
    "                                         slice_size=num_sentence_chunk_size)\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "54d2dd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 702,\n",
       "  'page_char_count': 2461,\n",
       "  'page_word_count': 409,\n",
       "  'page_sentence_count_raw': 25,\n",
       "  'page_token_count': 615.25,\n",
       "  'text': 'CHAPTER 20. DEEP GENERATIVE MODELS Gaussian distribution. Dropout seems to be important in the discriminator network. In particular, units should be stochastically dropped while computing the gradient for the generator network to follow. Following the gradient of the deterministic version of the discriminator with its weights divided by two does not seem to be as eﬀective. Likewise, never using dropout seems to yield poor results. While the GAN framework is designed for diﬀerentiable generator networks, similar principles can be used to train other kinds of models. For example, self- supervised boosting can be used to train an RBM generator to fool a logistic regression discriminator (Welling 2002 et al., ). 20.10.5 Generative Moment Matching Networks Generative moment matching networks ( , ; , Li et al. 2015 Dziugaite et al. 2015) are another form of generative model based on diﬀerentiable generator networks. Unlike VAEs and GANs, they do not need to pair the generator network with any other network—neither an inference network as used with VAEs nor a discriminator network as used with GANs. These networks are trained with a technique called moment matching. The basic idea behind moment matching is to train the generator in such a way that many of the statistics of samples generated by the model are as similar as possible to those of the statistics of the examples in the training set. In this context, a moment is an expectation of diﬀerent powers of a random variable. For example, the ﬁrst moment is the mean, the second moment is the mean of the squared values, and so on. In multiple dimensions, each element of the random vector may be raised to diﬀerent powers, so that a moment may be any quantity of the form ExΠixni i (20.82) where n = [n1, n2, . . . , nd]\\ue03eis a vector of non-negative integers. Upon ﬁrst examination, this approach seems to be computationally infeasible. For example, if we want to match all the moments of the form xix j, then we need to minimize the diﬀerence between a number of values that is quadratic in the dimension of x. Moreover, even matching all of the ﬁrst and second moments would only be suﬃcient to ﬁt a multivariate Gaussian distribution, which captures only linear relationships between values. Our ambitions for neural networks are to capture complex nonlinear relationships, which would require far more moments. GANs avoid this problem of exhaustively enumerating all moments by using a 703',\n",
       "  'sentences': ['CHAPTER 20.',\n",
       "   'DEEP GENERATIVE MODELS Gaussian distribution.',\n",
       "   'Dropout seems to be important in the discriminator network.',\n",
       "   'In particular, units should be stochastically dropped while computing the gradient for the generator network to follow.',\n",
       "   'Following the gradient of the deterministic version of the discriminator with its weights divided by two does not seem to be as eﬀective.',\n",
       "   'Likewise, never using dropout seems to yield poor results.',\n",
       "   'While the GAN framework is designed for diﬀerentiable generator networks, similar principles can be used to train other kinds of models.',\n",
       "   'For example, self- supervised boosting can be used to train an RBM generator to fool a logistic regression discriminator (Welling 2002 et al., ).',\n",
       "   '20.10.5 Generative Moment Matching Networks Generative moment matching networks ( , ; , Li et al.',\n",
       "   '2015 Dziugaite et al.',\n",
       "   '2015) are another form of generative model based on diﬀerentiable generator networks.',\n",
       "   'Unlike VAEs and GANs, they do not need to pair the generator network with any other network—neither an inference network as used with VAEs nor a discriminator network as used with GANs.',\n",
       "   'These networks are trained with a technique called moment matching.',\n",
       "   'The basic idea behind moment matching is to train the generator in such a way that many of the statistics of samples generated by the model are as similar as possible to those of the statistics of the examples in the training set.',\n",
       "   'In this context, a moment is an expectation of diﬀerent powers of a random variable.',\n",
       "   'For example, the ﬁrst moment is the mean, the second moment is the mean of the squared values, and so on.',\n",
       "   'In multiple dimensions, each element of the random vector may be raised to diﬀerent powers, so that a moment may be any quantity of the form ExΠixni i (20.82) where n = [n1, n2, . . . ,',\n",
       "   'nd]\\ue03eis a vector of non-negative integers.',\n",
       "   'Upon ﬁrst examination, this approach seems to be computationally infeasible.',\n",
       "   'For example, if we want to match all the moments of the form xix j, then we need to minimize the diﬀerence between a number of values that is quadratic in the dimension of x. Moreover, even matching all of the ﬁrst and second moments would only be suﬃcient to ﬁt a multivariate Gaussian distribution, which captures only linear relationships between values.',\n",
       "   'Our ambitions for neural networks are to capture complex nonlinear relationships, which would require far more moments.',\n",
       "   'GANs avoid this problem of exhaustively enumerating all moments by using a 703'],\n",
       "  'page_sentence_count_spacy': 22,\n",
       "  'sentence_chunks': [['CHAPTER 20.',\n",
       "    'DEEP GENERATIVE MODELS Gaussian distribution.',\n",
       "    'Dropout seems to be important in the discriminator network.',\n",
       "    'In particular, units should be stochastically dropped while computing the gradient for the generator network to follow.',\n",
       "    'Following the gradient of the deterministic version of the discriminator with its weights divided by two does not seem to be as eﬀective.',\n",
       "    'Likewise, never using dropout seems to yield poor results.',\n",
       "    'While the GAN framework is designed for diﬀerentiable generator networks, similar principles can be used to train other kinds of models.',\n",
       "    'For example, self- supervised boosting can be used to train an RBM generator to fool a logistic regression discriminator (Welling 2002 et al., ).',\n",
       "    '20.10.5 Generative Moment Matching Networks Generative moment matching networks ( , ; , Li et al.',\n",
       "    '2015 Dziugaite et al.'],\n",
       "   ['2015) are another form of generative model based on diﬀerentiable generator networks.',\n",
       "    'Unlike VAEs and GANs, they do not need to pair the generator network with any other network—neither an inference network as used with VAEs nor a discriminator network as used with GANs.',\n",
       "    'These networks are trained with a technique called moment matching.',\n",
       "    'The basic idea behind moment matching is to train the generator in such a way that many of the statistics of samples generated by the model are as similar as possible to those of the statistics of the examples in the training set.',\n",
       "    'In this context, a moment is an expectation of diﬀerent powers of a random variable.',\n",
       "    'For example, the ﬁrst moment is the mean, the second moment is the mean of the squared values, and so on.',\n",
       "    'In multiple dimensions, each element of the random vector may be raised to diﬀerent powers, so that a moment may be any quantity of the form ExΠixni i (20.82) where n = [n1, n2, . . . ,',\n",
       "    'nd]\\ue03eis a vector of non-negative integers.',\n",
       "    'Upon ﬁrst examination, this approach seems to be computationally infeasible.',\n",
       "    'For example, if we want to match all the moments of the form xix j, then we need to minimize the diﬀerence between a number of values that is quadratic in the dimension of x. Moreover, even matching all of the ﬁrst and second moments would only be suﬃcient to ﬁt a multivariate Gaussian distribution, which captures only linear relationships between values.'],\n",
       "   ['Our ambitions for neural networks are to capture complex nonlinear relationships, which would require far more moments.',\n",
       "    'GANs avoid this problem of exhaustively enumerating all moments by using a 703']],\n",
       "  'num_chunks': 3}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "717b4532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800.00</td>\n",
       "      <td>800.00</td>\n",
       "      <td>800.00</td>\n",
       "      <td>800.00</td>\n",
       "      <td>800.00</td>\n",
       "      <td>800.00</td>\n",
       "      <td>800.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>384.50</td>\n",
       "      <td>2223.28</td>\n",
       "      <td>378.88</td>\n",
       "      <td>26.79</td>\n",
       "      <td>555.82</td>\n",
       "      <td>20.01</td>\n",
       "      <td>2.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>231.08</td>\n",
       "      <td>612.58</td>\n",
       "      <td>103.48</td>\n",
       "      <td>46.86</td>\n",
       "      <td>153.15</td>\n",
       "      <td>9.34</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-15.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>184.75</td>\n",
       "      <td>1884.75</td>\n",
       "      <td>335.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>471.19</td>\n",
       "      <td>15.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>384.50</td>\n",
       "      <td>2356.50</td>\n",
       "      <td>398.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>589.12</td>\n",
       "      <td>19.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>584.25</td>\n",
       "      <td>2668.75</td>\n",
       "      <td>450.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>667.19</td>\n",
       "      <td>23.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>784.00</td>\n",
       "      <td>3168.00</td>\n",
       "      <td>870.00</td>\n",
       "      <td>670.00</td>\n",
       "      <td>792.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count       800.00           800.00           800.00                   800.00   \n",
       "mean        384.50          2223.28           378.88                    26.79   \n",
       "std         231.08           612.58           103.48                    46.86   \n",
       "min         -15.00            35.00             6.00                     1.00   \n",
       "25%         184.75          1884.75           335.00                    16.00   \n",
       "50%         384.50          2356.50           398.00                    20.00   \n",
       "75%         584.25          2668.75           450.00                    24.00   \n",
       "max         784.00          3168.00           870.00                   670.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  num_chunks  \n",
       "count            800.00                     800.00      800.00  \n",
       "mean             555.82                      20.01        2.46  \n",
       "std              153.15                       9.34        0.98  \n",
       "min                8.75                       1.00        1.00  \n",
       "25%              471.19                      15.00        2.00  \n",
       "50%              589.12                      19.00        2.00  \n",
       "75%              667.19                      23.00        3.00  \n",
       "max              792.00                      55.00        6.00  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts) \n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "17267bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 14960.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1970"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Split each chunk into its own item\n",
    "pages_and_chunks = []\n",
    "for item in tqdm(pages_and_texts):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = {}\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "        \n",
    "        # Join the sentences together into a paragraph-like structure, aka a chunk (so they are a single string)\n",
    "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "        joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # \".A\" -> \". A\" for any full-stop/capital letter combo \n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "\n",
    "        # Get stats about the chunk\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4 # 1 token = ~4 characters\n",
    "        \n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "# How many chunks do we have?\n",
    "len(pages_and_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bd48d42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 415,\n",
       "  'sentence_chunk': '10.12 Explicit Memory Intelligence requires knowledge and acquiring knowledge can be done via learning, which has motivated the development of large-scale deep architectures. However, there are diﬀerent kinds of knowledge. Some knowledge can be implicit, sub- conscious, and diﬃcult to verbalize—such as how to walk, or how a dog looks diﬀerent from a cat. Other knowledge can be explicit, declarative, and relatively straightforward to put into words—every day commonsense knowledge, like “a cat is a kind of animal,” or very speciﬁc facts that you need to know to accomplish your current goals, like “the meeting with the sales team is at 3:00 PM in room 141.”Neural networks excel at storing implicit knowledge. However, they struggle to memorize facts. Stochastic gradient descent requires many presentations of the 416',\n",
       "  'chunk_char_count': 823,\n",
       "  'chunk_word_count': 127,\n",
       "  'chunk_token_count': 205.75}]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_chunks, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a181000a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1970.00</td>\n",
       "      <td>1970.00</td>\n",
       "      <td>1970.00</td>\n",
       "      <td>1970.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>413.64</td>\n",
       "      <td>900.64</td>\n",
       "      <td>152.47</td>\n",
       "      <td>225.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>240.78</td>\n",
       "      <td>464.17</td>\n",
       "      <td>81.54</td>\n",
       "      <td>116.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-15.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>204.00</td>\n",
       "      <td>503.75</td>\n",
       "      <td>76.00</td>\n",
       "      <td>125.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>422.00</td>\n",
       "      <td>979.00</td>\n",
       "      <td>168.00</td>\n",
       "      <td>244.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>634.75</td>\n",
       "      <td>1248.75</td>\n",
       "      <td>213.00</td>\n",
       "      <td>312.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>784.00</td>\n",
       "      <td>2437.00</td>\n",
       "      <td>423.00</td>\n",
       "      <td>609.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count      1970.00           1970.00           1970.00            1970.00\n",
       "mean        413.64            900.64            152.47             225.16\n",
       "std         240.78            464.17             81.54             116.04\n",
       "min         -15.00              2.00              1.00               0.50\n",
       "25%         204.00            503.75             76.00             125.94\n",
       "50%         422.00            979.00            168.00             244.75\n",
       "75%         634.75           1248.75            213.00             312.19\n",
       "max         784.00           2437.00            423.00             609.25"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get stats about our chunks\n",
    "df = pd.DataFrame(pages_and_chunks)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3fd17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The Sentences Transformers library provides an easy and open-source way to create embeddings.\n",
      "Embedding: [-2.07982697e-02  3.03164832e-02 -2.01217849e-02  6.86484650e-02\n",
      " -2.55256221e-02 -8.47686455e-03 -2.07225574e-04 -6.32377118e-02\n",
      "  2.81606894e-02 -3.33353989e-02  3.02633960e-02  5.30721806e-02\n",
      " -5.03527038e-02  2.62288321e-02  3.33313718e-02 -4.51577231e-02\n",
      "  3.63044813e-02 -1.37122418e-03 -1.20171458e-02  1.14947259e-02\n",
      "  5.04510924e-02  4.70856987e-02  2.11913940e-02  5.14606535e-02\n",
      " -2.03746483e-02 -3.58889401e-02 -6.67763175e-04 -2.94393823e-02\n",
      "  4.95859198e-02 -1.05639677e-02 -1.52014112e-02 -1.31758570e-03\n",
      "  4.48197424e-02  1.56023465e-02  8.60379430e-07 -1.21392624e-03\n",
      " -2.37978697e-02 -9.09368275e-04  7.34484056e-03 -2.53933994e-03\n",
      "  5.23370504e-02 -4.68043424e-02  1.66214760e-02  4.71579395e-02\n",
      " -4.15599644e-02  9.01976076e-04  3.60277519e-02  3.42214219e-02\n",
      "  9.68227163e-02  5.94829023e-02 -1.64984372e-02 -3.51249315e-02\n",
      "  5.92516130e-03 -7.07903586e-04 -2.41031442e-02  3.49740870e-02\n",
      " -2.94746887e-02  6.04262855e-03 -9.80652310e-03  2.83218101e-02\n",
      " -1.85375679e-02  3.63212861e-02  1.30292149e-02 -3.71233001e-02\n",
      "  5.27256243e-02 -1.19707026e-02 -7.18083233e-02  1.24431746e-02\n",
      " -6.70563010e-03  7.42154419e-02  1.16356099e-02 -1.74534023e-02\n",
      " -1.82405282e-02 -1.88931134e-02  2.82415152e-02  1.32829510e-02\n",
      " -3.51909734e-02  8.87303147e-04  5.79572394e-02  3.22094113e-02\n",
      " -3.48579930e-03  4.13768739e-02  1.44358072e-02 -3.28044333e-02\n",
      " -9.79085453e-03 -3.16492803e-02  4.23870534e-02 -4.70846333e-02\n",
      " -2.08936650e-02 -1.91249400e-02 -1.22627662e-02  1.01606082e-02\n",
      "  3.91921513e-02 -2.61896141e-02  1.09027857e-02  1.35722943e-02\n",
      " -5.79267405e-02 -3.21500264e-02 -5.75725595e-03 -2.43515857e-02\n",
      "  5.23416735e-02  5.46121923e-03 -2.30996069e-02  2.57174857e-03\n",
      " -6.63347095e-02  3.54125462e-02 -1.03907324e-02  2.25410350e-02\n",
      " -1.84573866e-02 -2.42007170e-02 -4.78365757e-02 -4.79222648e-03\n",
      " -5.34138344e-02  3.01790610e-02 -1.56131107e-02 -5.51476665e-02\n",
      " -3.91874090e-02  5.92152663e-02 -3.47646885e-02  9.68123414e-03\n",
      "  2.13415958e-02  2.30417158e-02  1.91712864e-02  2.77378634e-02\n",
      " -7.73504097e-03  1.04445815e-02 -2.67719701e-02 -2.40199845e-02\n",
      " -1.92290191e-02  3.91504029e-03 -2.54714545e-02  3.61943170e-02\n",
      "  5.12867272e-02 -8.41695443e-03 -3.13829891e-02  1.47483395e-02\n",
      "  2.13940237e-02 -3.84900905e-02  2.01945025e-02  1.20766172e-02\n",
      " -3.12067149e-03  7.84034468e-03  3.30334972e-03 -4.94357683e-02\n",
      "  5.83886690e-02  3.26137990e-03  4.84483130e-03 -4.50682305e-02\n",
      "  2.45682914e-02  3.55427973e-02 -5.32506183e-02  9.21152830e-02\n",
      "  2.04394981e-02 -3.36951911e-02 -6.19803667e-02 -2.11039372e-02\n",
      "  7.82358795e-02  5.11908121e-02  5.93170337e-02 -1.25138249e-04\n",
      "  4.96350192e-02 -1.55722611e-02 -3.35678132e-03  1.82016175e-02\n",
      " -2.73444112e-02 -1.08772302e-02  1.41476206e-02  1.09877614e-02\n",
      "  4.32554120e-03  8.23311061e-02 -9.85351857e-04  7.58791268e-02\n",
      "  9.44995414e-03  2.37687770e-02  1.61927696e-02  6.24993593e-02\n",
      "  4.75922152e-02 -3.92625527e-03  9.07524452e-02  4.49874513e-02\n",
      " -3.47131379e-02  2.14077290e-02 -3.35604399e-02  4.93849255e-02\n",
      "  1.08669596e-02  2.63447315e-02 -3.26090083e-02  8.00303668e-02\n",
      "  9.29764099e-03  7.16581754e-03 -2.79172305e-02 -3.06821167e-02\n",
      "  4.01061308e-03 -4.93906848e-02 -3.13766720e-03  4.00537960e-02\n",
      " -3.97855081e-02  5.48014119e-02  1.36232920e-05 -8.38373005e-02\n",
      " -1.21547757e-02  3.40949483e-02  3.22403293e-03  6.11845851e-02\n",
      "  5.60067147e-02  9.62868426e-03  2.54616365e-02 -4.64168824e-02\n",
      " -3.98901179e-02  7.68131986e-02  2.28409003e-02 -2.26568524e-02\n",
      " -1.91193614e-02 -6.53029084e-02  4.56781089e-02 -4.43657534e-03\n",
      "  1.49631901e-02 -2.15077940e-02  2.74249981e-03  1.90358274e-02\n",
      "  5.91888502e-02 -2.47569326e-02  3.66144404e-02  5.63083962e-02\n",
      " -8.86448752e-03 -1.74324475e-02 -1.03288016e-03  2.47666314e-02\n",
      "  1.30763054e-02  5.04632853e-02 -5.28496411e-03  5.92397638e-02\n",
      "  6.29906207e-02 -4.36783433e-02 -4.97830249e-02  5.56296855e-02\n",
      " -2.44853850e-02 -8.26754868e-02  2.04910524e-02 -1.06446289e-01\n",
      "  6.64840313e-03  2.97304858e-02 -2.36440394e-02 -8.84616654e-03\n",
      "  2.45556212e-03 -3.35234217e-02  7.52212405e-02 -5.89880198e-02\n",
      " -3.67808491e-02  3.41542847e-02  5.41130826e-02 -1.74904745e-02\n",
      "  1.33920852e-02  4.71682437e-02  1.46116382e-02 -2.12310851e-02\n",
      " -6.55338690e-02  1.23857660e-02  2.76074912e-02 -8.02162010e-03\n",
      " -4.59636636e-02 -8.22441280e-03  9.16955061e-03 -1.56399272e-02\n",
      "  7.54621858e-03  1.58311694e-03 -3.03958263e-02 -5.10671102e-02\n",
      "  1.96313895e-02  1.26263080e-02 -1.51736313e-03  2.02891696e-02\n",
      "  1.37817422e-02  1.49110639e-02  2.50766799e-02 -3.62870470e-02\n",
      "  1.08085470e-02  2.74132611e-03  1.81510597e-02  5.39872162e-02\n",
      " -4.74542119e-02 -4.28730771e-02 -2.89914198e-02  2.13235393e-02\n",
      " -3.85161303e-02  6.31922707e-02 -5.77975921e-02  3.77887371e-03\n",
      " -2.54394077e-02 -1.77221402e-04  9.08246171e-03  1.59095451e-02\n",
      "  4.11799699e-02 -3.94367501e-02 -9.64435469e-03  1.30791226e-02\n",
      "  6.87962249e-02  4.32192720e-02  7.53988861e-04  6.77741393e-02\n",
      "  4.93705869e-02 -3.47822974e-03 -1.06055206e-02  6.72493502e-03\n",
      " -1.39062526e-02  4.88276556e-02 -1.05735194e-02  3.50223086e-03\n",
      "  2.90228007e-03  2.40044240e-02  1.20271696e-02 -2.09797733e-02\n",
      " -2.39111856e-02  3.26579362e-02 -1.01329759e-03 -5.92753664e-03\n",
      " -7.40531320e-03  3.63146723e-03 -2.26698499e-02 -2.21241470e-02\n",
      "  3.86996605e-02  1.72321927e-02  3.85920033e-02 -5.04711568e-02\n",
      " -3.42145115e-02 -4.00443934e-02 -3.57910767e-02 -4.62561324e-02\n",
      "  6.70232177e-02 -4.61649662e-03 -3.29675269e-03  2.08444465e-02\n",
      " -5.14258211e-03 -5.00849895e-02  2.22503915e-02  4.66933772e-02\n",
      "  1.36208758e-02  1.77530069e-02  4.28080093e-03 -2.79332325e-02\n",
      " -1.93421096e-02 -3.87859829e-02 -3.09554469e-02 -6.64134398e-02\n",
      " -1.13433953e-02  1.64267533e-02  1.77629739e-02 -2.28224183e-03\n",
      " -3.30087505e-02 -1.36263284e-03 -2.17934493e-02 -2.67508309e-02\n",
      " -1.26375612e-02  1.61869323e-03 -4.95672598e-02  7.85446092e-02\n",
      "  4.10962887e-02  9.65921115e-03 -1.14643481e-02  1.68858981e-03\n",
      "  5.37662953e-02  2.05532974e-03 -4.11199965e-02  1.46330167e-02\n",
      " -3.75564173e-02 -3.35689783e-02  5.19254804e-03 -6.33088797e-02\n",
      "  3.32963243e-02  8.76118429e-03  1.33859867e-03 -3.95742478e-03\n",
      " -1.61677748e-02  8.26746598e-02  4.75945137e-02 -3.43055725e-02\n",
      "  2.50880960e-02 -3.50977443e-02  3.68657485e-02  4.12650127e-03\n",
      "  4.16017845e-02 -1.35181695e-01 -4.76338193e-02 -1.20025752e-02\n",
      " -3.48891653e-02  3.25455032e-02 -2.93580024e-03 -4.85053752e-03\n",
      " -1.04223713e-01  2.78610419e-02  1.41570149e-02  3.94395217e-02\n",
      " -3.88806835e-02 -1.42463734e-02 -5.19983917e-02  8.92731640e-03\n",
      " -1.99771058e-02 -2.51725148e-02 -3.41299735e-02  1.93041563e-02\n",
      " -5.20207956e-02 -6.72000423e-02 -9.46364645e-03 -1.25585229e-03\n",
      " -5.66048585e-02  2.62098424e-02  9.91584174e-03  4.38286550e-02\n",
      "  2.26643379e-03 -3.11895553e-02 -6.25467747e-02 -3.87793221e-02\n",
      " -6.83939159e-02  4.93721664e-02  5.85507713e-02 -4.08729427e-02\n",
      " -1.98638085e-02 -2.12634560e-02  4.98037562e-02 -4.51748557e-02\n",
      " -2.37141773e-02  2.32674759e-02  1.00594789e-01  9.87118296e-03\n",
      " -1.38015077e-02 -5.21041602e-02  9.08206403e-03  1.72427595e-02\n",
      "  5.91431372e-02  2.62336880e-02 -7.04640616e-03 -1.50032090e-02\n",
      " -3.76658537e-03  6.28258800e-03 -5.23981117e-02 -4.96638566e-02\n",
      "  3.06611080e-02 -3.33646522e-03  2.34911181e-02 -8.58829916e-02\n",
      " -4.62449081e-02  5.59700914e-02  3.09063587e-04  2.01728866e-02\n",
      " -2.98053538e-03  1.76646058e-02  1.54669620e-02 -7.41718039e-02\n",
      "  7.34992698e-03 -1.05015635e-02  2.45247297e-02  1.36879468e-02\n",
      " -1.17803654e-02  4.51544970e-02  3.29039358e-02 -3.50389048e-03\n",
      " -2.71314792e-02 -5.27363792e-02 -4.60164174e-02  2.22848989e-02\n",
      "  2.62271296e-02  5.56151988e-03  1.45789236e-02 -2.97145657e-02\n",
      "  3.57042886e-02  2.22533774e-02  3.89617421e-02 -7.92634487e-02\n",
      " -9.01089516e-03  2.19013132e-02 -5.49054425e-03  8.69956426e-03\n",
      "  4.33031246e-02 -2.12631393e-02  1.13291992e-02 -6.33698925e-02\n",
      "  3.63723636e-02  2.67442726e-02 -6.64251819e-02  1.70499552e-02\n",
      " -2.79691126e-02  2.36355886e-03 -1.81952789e-02  1.52955763e-02\n",
      " -8.50433297e-03  1.16647389e-02 -9.75921750e-02 -2.92093456e-02\n",
      " -5.42547703e-02  3.61235105e-02  3.25117111e-02  8.26975610e-03\n",
      " -2.96499085e-04  1.11556267e-02 -3.85188013e-02  2.36161407e-02\n",
      "  9.85921361e-03  5.73998727e-02  4.86061424e-02 -1.37579199e-02\n",
      " -6.19221339e-03  1.11973006e-02 -3.37175131e-02 -1.10515822e-02\n",
      " -7.08333626e-02 -1.01816598e-02 -3.66010703e-02 -1.55560989e-02\n",
      " -2.13110335e-02 -1.02760708e-02 -4.35733646e-02  5.55186495e-02\n",
      " -3.76548246e-02  5.29252477e-02 -3.45224105e-02 -2.43007811e-03\n",
      "  7.25553632e-02  4.45072725e-03  4.71417420e-02 -9.43884347e-03\n",
      " -1.98979080e-02  5.71900122e-02  8.60541388e-02 -5.25057837e-02\n",
      " -1.39549561e-02  1.17372992e-02  1.33974077e-02 -4.73052524e-02\n",
      " -5.41673936e-02  4.62725945e-02 -2.58969981e-02  1.51415411e-02\n",
      "  3.38944830e-02 -3.78261926e-03 -5.76043315e-02 -1.60082486e-02\n",
      "  2.42738742e-02  3.37360799e-02 -1.96820926e-02 -2.53464375e-02\n",
      " -4.75617126e-02 -5.68755083e-02 -2.28194278e-02  3.83187570e-02\n",
      " -1.78331137e-02  1.35964463e-02  7.85997661e-04  9.74011701e-03\n",
      "  3.34298834e-02 -2.60134004e-02 -7.38565903e-03  3.56451236e-02\n",
      " -2.68532448e-02 -7.53624812e-02 -2.66983807e-02 -4.46457420e-33\n",
      " -3.31646726e-02  1.41703570e-02 -3.92909646e-02 -3.46318446e-02\n",
      " -5.88673959e-03 -1.18212355e-02  1.53951468e-02  1.18473414e-02\n",
      "  1.07757142e-02  3.62140238e-02  7.87954219e-03 -2.31845677e-02\n",
      "  1.07623041e-02  1.72346197e-02  9.54178220e-04  2.83640251e-02\n",
      "  2.37419307e-02 -1.48058375e-02  1.24196196e-03  3.52355768e-03\n",
      "  2.33735796e-02  5.58307655e-02  5.38327880e-02 -3.74079235e-02\n",
      " -2.11805683e-02  1.52712033e-04 -7.27788266e-03  5.50556369e-03\n",
      "  3.05823572e-02  4.54633124e-02 -3.35786715e-02  3.16142254e-02\n",
      " -2.56393314e-03  3.96355428e-02 -1.47573715e-02  5.67167327e-02\n",
      " -5.62787578e-02 -5.04600117e-03  3.56154703e-02 -2.76198816e-02\n",
      " -2.32291892e-02 -4.63291854e-02 -3.70919555e-02 -4.23188917e-02\n",
      "  3.70306931e-02  7.88721535e-03  3.85176092e-02  1.74776383e-03\n",
      "  5.62761398e-03  6.18107338e-03 -6.90268278e-02 -9.42962337e-03\n",
      " -7.74675934e-03  1.68349966e-02  1.22767724e-02  2.26406753e-02\n",
      "  1.21008605e-02  1.11743947e-02  1.21539310e-02 -1.16862329e-02\n",
      " -4.41612378e-02  2.30046958e-02  2.20672451e-02 -5.87504357e-02\n",
      " -3.96428369e-02  6.83135390e-02 -3.29948142e-02 -3.66775058e-02\n",
      " -3.53655033e-02  1.76184867e-02  6.95639802e-03  5.92693239e-02\n",
      "  4.12156470e-02  7.98109397e-02 -5.36562735e-03  1.14238728e-02\n",
      " -2.96388473e-02 -1.15411496e-02  2.22812407e-02  7.93183316e-03\n",
      "  2.60356162e-02  1.28212180e-02  1.71345770e-02 -6.90185558e-03\n",
      " -1.07603427e-02  1.35714635e-02 -9.90795437e-04 -6.16075359e-02\n",
      "  4.40514013e-02 -8.26610194e-04 -2.78340783e-02 -1.23619484e-02\n",
      "  1.34629682e-02 -3.85745242e-02  1.08702201e-03  2.18712538e-02\n",
      " -3.32398415e-02  1.84616055e-02 -5.10114804e-03  3.74664739e-02\n",
      " -3.67544265e-03 -2.19246596e-02 -4.96483222e-03 -9.59838089e-03\n",
      "  2.33591273e-02  1.04876524e-02  4.38722298e-02 -1.51424259e-02\n",
      " -6.30309060e-02  8.23260657e-03 -1.09130749e-02 -4.06409390e-02\n",
      " -6.21691085e-02  2.21326388e-02 -2.71434225e-02  4.05539460e-02\n",
      " -8.09448864e-03 -1.76415453e-03  3.01526655e-02 -5.42263268e-03\n",
      " -4.69822213e-02 -1.73768364e-02  4.11631130e-02  3.20634767e-02\n",
      " -2.22943965e-02 -1.58162061e-02 -4.50720750e-02  5.69486618e-02\n",
      "  4.71595563e-02 -5.78058325e-02  1.32475207e-02 -4.71288944e-03\n",
      "  1.66824464e-07  4.81090546e-02  5.03627956e-02  5.45263179e-02\n",
      "  2.07568631e-02 -1.19080152e-02 -6.37493003e-03  5.26367966e-03\n",
      "  7.21949190e-02 -2.21762881e-02  2.20103282e-02 -9.90471570e-04\n",
      " -1.37163941e-02  6.89207157e-03  2.46913154e-02 -1.39462024e-01\n",
      "  2.56982655e-03 -4.64826375e-02 -4.04967591e-02 -6.08555451e-02\n",
      " -1.53213087e-02  1.36129931e-01  9.45034847e-02  4.25741449e-02\n",
      "  4.67131250e-02 -2.30677761e-02 -1.20965820e-02  3.86673398e-02\n",
      "  2.11645057e-03 -2.51473263e-02 -1.15076350e-02 -3.46506238e-02\n",
      " -2.29533575e-02 -6.33848319e-03 -3.05175744e-02 -1.56236542e-02\n",
      "  1.39514096e-02  3.27477261e-04  2.00321386e-03  4.15107328e-03\n",
      " -2.22924985e-02 -3.62589583e-02 -2.36579478e-02 -1.87817235e-02\n",
      " -1.96289383e-02  4.52125780e-02 -8.12568814e-02 -2.14568917e-02\n",
      " -4.41543311e-02 -2.68475618e-02  2.01974250e-02  2.82990397e-03\n",
      " -1.95011422e-02 -3.45330760e-02  2.26913858e-02  3.78325917e-02\n",
      " -1.02543989e-02 -2.19759904e-03 -8.96744579e-02 -4.50031236e-02\n",
      "  8.09701998e-03 -2.05805562e-02 -2.02998724e-02 -2.09922269e-02\n",
      " -1.79404784e-02  5.81897050e-02 -7.63652008e-03  1.50847323e-02\n",
      "  1.78279755e-34  4.86179404e-02  4.22228537e-02  4.71595228e-02\n",
      "  5.89047521e-02  3.99785116e-02 -5.27071543e-02  1.56905279e-02\n",
      " -5.25070238e-04  1.13651920e-02 -6.56410605e-02 -2.20848955e-02]\n",
      "\n",
      "Sentence: Sentences can be embedded one by one or as a list of strings.\n",
      "Embedding: [ 4.31718193e-02 -5.38701862e-02 -3.78044508e-02  4.27235737e-02\n",
      " -2.35408898e-02  3.44860964e-02  2.89586801e-02  1.92815682e-03\n",
      "  2.41733491e-02 -3.17012779e-02  7.32855946e-02  1.25590302e-02\n",
      "  3.64620574e-02 -2.05251630e-02  2.81973705e-02 -6.87328875e-02\n",
      "  4.22231480e-02  9.31746094e-04  3.54035087e-02  1.41787464e-02\n",
      "  7.83994235e-03  2.31178999e-02 -4.84734494e-03  1.07173799e-02\n",
      "  4.39486839e-03  5.47800958e-03 -3.80338840e-02 -3.05488799e-03\n",
      "  5.72227780e-03 -6.78213686e-02 -4.88007590e-02 -1.45032555e-02\n",
      "  6.68012537e-03 -7.17479512e-02  1.64644837e-06  1.07564405e-02\n",
      " -3.60922813e-02 -2.37057246e-02 -5.22791669e-02  3.46110649e-02\n",
      " -5.42175118e-03  1.62611715e-02  1.96564570e-02  2.25395784e-02\n",
      " -2.25997507e-03  4.06341888e-02  8.17157552e-02  2.48179268e-02\n",
      "  5.31884618e-02  7.82714933e-02 -1.91813745e-02 -1.94087084e-02\n",
      " -2.62805130e-02 -2.44083069e-02  5.49405627e-02  1.90319009e-02\n",
      "  1.60811730e-02 -2.68895365e-02 -8.24695174e-03  7.33444616e-02\n",
      "  1.00123342e-02  2.93315928e-02  3.42861470e-03 -2.13270150e-02\n",
      " -1.62442401e-03 -5.56254806e-03 -7.64879733e-02 -5.85450605e-02\n",
      " -2.82272156e-02  7.51843723e-03  7.11225867e-02  1.95453083e-03\n",
      "  5.45929745e-03  3.22320475e-03  5.12800030e-02 -3.54105718e-02\n",
      " -5.03608398e-02  4.70519029e-02  5.15479455e-03  1.52287185e-02\n",
      " -1.06680188e-02  3.16298492e-02 -9.09038167e-03 -4.01327573e-02\n",
      " -4.35236134e-02 -1.94969568e-02  1.65604819e-02 -4.71168943e-02\n",
      " -3.92091796e-02 -3.07756793e-02 -2.94167586e-02 -4.20826823e-02\n",
      "  2.27072742e-03 -2.78329477e-02  1.69421937e-02  7.74501637e-03\n",
      " -5.23742251e-02 -4.50040139e-02  3.83605249e-02 -4.90786731e-02\n",
      "  5.06619066e-02  1.01615358e-02 -1.25021543e-02 -4.64555155e-03\n",
      " -1.54540055e-02  1.58862602e-02  1.18370363e-02 -3.59232686e-02\n",
      " -7.76225477e-02  3.43358256e-02 -2.14709844e-02 -6.86098486e-02\n",
      " -5.46236411e-02  7.83901513e-02 -3.00702173e-02 -3.37550379e-02\n",
      " -4.04998623e-02  4.80515696e-02  9.53903235e-03  2.31399443e-02\n",
      " -8.16115141e-02 -6.51697442e-03  1.54213104e-02  7.04257712e-02\n",
      " -1.25069106e-02 -2.48267055e-02 -1.71328634e-02  6.13110326e-03\n",
      "  5.44412695e-02 -1.40565978e-02 -6.24514557e-03  3.65788005e-02\n",
      "  7.36230686e-02 -6.05681911e-03 -3.61630619e-02 -1.42203958e-03\n",
      "  4.43166159e-02 -3.14513524e-03  3.18767726e-02 -1.30948164e-02\n",
      " -3.69524509e-02 -4.98028332e-03  1.30016892e-03 -2.05213316e-02\n",
      "  2.06277724e-02  5.93870180e-03 -3.07167275e-03 -3.97513285e-02\n",
      "  4.29890007e-02  6.49802908e-02 -6.76022470e-02  5.41655533e-02\n",
      "  1.52562151e-03 -3.72908860e-02 -4.02427092e-02 -2.28772406e-02\n",
      "  1.31769717e-01  4.87872912e-03  1.39470678e-02  4.92435694e-02\n",
      "  2.49219052e-02 -8.76093004e-03 -5.38768107e-03 -2.65595857e-02\n",
      " -1.19766099e-02 -2.32006814e-02 -2.67433859e-02  5.66913700e-03\n",
      "  2.21722275e-02  4.67294008e-02 -5.78487404e-02  8.22120830e-02\n",
      " -3.36834625e-03  8.09647441e-02  1.41423391e-02  1.02393068e-01\n",
      " -5.76832471e-03 -1.15877781e-02  4.90584895e-02  5.87829612e-02\n",
      "  6.50030747e-02  4.74621579e-02 -2.89463960e-02 -1.76587480e-03\n",
      "  3.32561098e-02  2.91198287e-02  6.03811182e-02  3.73491086e-04\n",
      "  1.06576458e-02 -5.96284755e-02 -7.28601664e-02  2.95079947e-02\n",
      "  9.54464916e-03 -2.71542408e-02 -5.63305095e-02  9.66727501e-04\n",
      " -4.77729291e-02  4.67576869e-02  4.87255212e-03 -6.57519549e-02\n",
      " -1.42248496e-02  3.99872884e-02 -1.09797139e-02  7.68941417e-02\n",
      " -4.00004201e-02  2.96826512e-02  2.81303283e-02 -5.55424877e-02\n",
      "  6.31263386e-03  5.00449911e-02  1.89883914e-02  5.38683832e-02\n",
      " -1.95981693e-02  1.08601190e-02  1.64150428e-02  1.44135421e-02\n",
      "  1.71448812e-02  2.17625257e-02 -4.98862676e-02  1.56104947e-02\n",
      "  4.83737327e-03  1.87053606e-02 -3.18543497e-03  2.66863164e-02\n",
      "  5.55552505e-02 -4.88006026e-02 -3.02929282e-02  2.52110399e-02\n",
      "  1.07265087e-02  1.88270453e-02 -1.50687927e-02  3.43832038e-02\n",
      "  4.15124893e-02  1.37788849e-02 -5.54848835e-02  1.43848425e-02\n",
      " -5.88139519e-02 -6.01676628e-02  2.69856490e-02 -5.46129867e-02\n",
      "  8.14634748e-03 -1.17758401e-02  1.57442857e-02  1.43903506e-03\n",
      " -2.64554638e-02 -4.48876582e-02  4.39732410e-02 -1.06194755e-04\n",
      " -2.25906093e-02  3.00296731e-02  1.97440516e-02  7.44078308e-03\n",
      " -1.93789657e-02  8.09797179e-03  4.34859544e-02 -1.08600296e-04\n",
      " -3.77225578e-02  2.67196149e-02 -4.63157669e-02 -1.53401645e-03\n",
      "  8.05312209e-03 -4.30900976e-02 -2.13848837e-02  1.20185213e-02\n",
      "  8.41399748e-03  2.48273090e-03 -3.09566967e-02 -9.05277282e-02\n",
      " -4.76693623e-02  1.22606354e-02 -1.36467144e-02 -2.63654962e-02\n",
      " -7.65552139e-03  8.72378610e-03  2.65725143e-02  8.40057211e-04\n",
      " -5.55928703e-03 -9.29542072e-03  3.19337286e-02  5.94646633e-02\n",
      "  1.83205772e-02 -7.56546855e-02 -5.59388958e-02 -1.20870778e-02\n",
      " -3.16261090e-02  3.62187251e-02  7.53609231e-03 -6.15653843e-02\n",
      " -2.30459068e-02 -3.51668987e-03  1.23332217e-02 -9.67637636e-03\n",
      "  4.96861488e-02 -8.42256770e-02  1.52395917e-02 -1.82445329e-02\n",
      "  7.70462379e-02  9.28717703e-02  4.03724313e-02  1.11732602e-01\n",
      " -1.03270495e-02 -2.54558027e-02  2.13153809e-02 -1.16186810e-03\n",
      "  2.82604550e-03  5.06967083e-02 -3.13697383e-02 -8.14271905e-03\n",
      "  1.38387512e-02  4.66889553e-02  5.09670787e-02  3.77154052e-02\n",
      " -2.94988807e-02  3.60631905e-02 -2.61165691e-03  2.72258127e-04\n",
      " -6.71806708e-02 -6.54026493e-02 -3.43590789e-02  1.91067513e-02\n",
      "  4.13294099e-02 -1.10970577e-02  4.51951697e-02 -5.93565404e-02\n",
      "  1.06963757e-02 -1.82229895e-02 -5.65814339e-02  1.20386770e-02\n",
      "  4.44773808e-02  1.87050141e-02  1.63810086e-02  5.51150665e-02\n",
      " -2.23332252e-02  2.12861821e-02 -1.20339869e-02  3.26752886e-02\n",
      "  1.47004584e-02 -8.16682260e-03  1.12905195e-02 -3.00620627e-02\n",
      " -2.34345775e-02 -2.68646013e-02 -1.28718873e-03 -7.67189562e-02\n",
      "  2.22609052e-03 -5.89476945e-03  2.63103861e-02  2.07130052e-03\n",
      " -6.91151768e-02 -1.43792182e-02  2.68788096e-02 -3.51539850e-02\n",
      " -2.69611757e-02  2.54717027e-03 -6.48881868e-02  3.18727903e-02\n",
      "  1.70126669e-02 -4.54004444e-02 -1.80616304e-02 -1.61115918e-02\n",
      "  5.70773706e-02 -2.78272573e-03 -6.45585358e-02  7.86597952e-02\n",
      "  2.29075216e-02  6.81841606e-03 -9.11738630e-03 -2.27726288e-02\n",
      " -4.76526655e-02  4.88430671e-02 -2.09892020e-02 -2.43693721e-02\n",
      " -5.01206610e-03  6.70253709e-02  6.91368151e-03  2.25842986e-02\n",
      "  2.51125228e-02 -6.92507625e-03  8.59402865e-03  2.38977186e-02\n",
      "  3.29738334e-02 -1.05310582e-01  1.22094685e-02 -1.22263562e-02\n",
      " -5.73768876e-02  1.84311662e-02  2.97158435e-02 -6.09428994e-02\n",
      " -6.55256063e-02  3.55712995e-02  5.64321782e-03  3.34645738e-03\n",
      " -3.59686762e-02 -8.83417204e-03 -6.97894841e-02  6.89779073e-02\n",
      " -4.88213124e-03  2.23995019e-02 -3.16053554e-02 -7.41183432e-03\n",
      "  3.19351070e-02 -5.18788509e-02  2.11601499e-02 -5.03340401e-02\n",
      "  9.10576154e-03  2.13354323e-02  1.66838020e-02  3.49020213e-02\n",
      " -6.38499707e-02 -6.75625866e-03 -1.27405310e-02 -4.63366471e-02\n",
      " -1.14779770e-02  2.08778344e-02  2.44822130e-02  3.66460346e-03\n",
      " -2.86095333e-03  2.29390450e-02  2.13746261e-02 -3.48900966e-02\n",
      " -3.00387964e-02  4.78870273e-02  5.83370775e-02 -9.70496144e-03\n",
      "  1.38234589e-02 -3.27485688e-02 -8.11501290e-04  9.54227522e-03\n",
      "  1.20401485e-02  1.97230317e-02 -4.74863133e-04 -1.39226038e-02\n",
      " -5.21070361e-02 -1.75592452e-02 -5.41698523e-02 -1.17970034e-02\n",
      " -1.71030592e-02 -3.50195132e-02  3.38661373e-02 -6.76587075e-02\n",
      " -2.27606799e-02  1.95606817e-02  5.50249182e-02  1.22028887e-02\n",
      " -1.75167248e-03  7.22441915e-03  1.16349943e-02 -1.61907859e-02\n",
      " -3.37754898e-02  3.22626941e-02 -2.03813817e-02 -2.33859271e-02\n",
      " -1.29991928e-02 -1.66799258e-02  1.03070885e-02 -1.46030253e-02\n",
      " -7.79070482e-02 -8.25812146e-02 -3.38809863e-02  3.81114595e-02\n",
      "  7.86006637e-03  2.41455045e-02 -2.75714882e-02  1.30866952e-02\n",
      " -7.88593199e-03  1.78651102e-02  5.37323095e-02 -3.01823616e-02\n",
      "  1.69455390e-02  1.19571807e-02  3.52569536e-04  4.90209162e-02\n",
      " -8.57210346e-03  1.71269733e-03  4.83874837e-03 -4.10081223e-02\n",
      " -4.68120985e-02 -2.32559652e-03 -5.16776480e-02  3.10030449e-02\n",
      "  1.60961617e-02 -1.00803478e-02 -3.72483139e-03 -3.53388153e-02\n",
      "  2.95961443e-02  2.89097149e-02 -7.59911686e-02 -5.02980836e-02\n",
      " -2.11783666e-02  3.20462137e-02 -3.84538509e-02  2.45103110e-02\n",
      " -2.04188060e-02  6.02107821e-03 -9.81936697e-03  3.74777764e-02\n",
      "  3.40838991e-02  1.28864441e-02  5.67342751e-02 -8.09703767e-02\n",
      " -8.93608201e-03  1.33352634e-02 -2.51565967e-02  2.58417078e-03\n",
      " -6.51803017e-02  1.34399943e-02 -2.04682462e-02  6.53377734e-03\n",
      "  4.56973491e-03  1.99271273e-02 -6.07340261e-02  1.40691502e-02\n",
      " -5.75334132e-02  9.79801919e-03  3.55393551e-02 -2.45283470e-02\n",
      " -4.73312475e-03 -2.77493019e-02  2.34282743e-02 -8.76351478e-05\n",
      "  7.30441138e-03  1.42028835e-02  4.92807180e-02 -3.16540450e-02\n",
      " -1.34901870e-02  3.08487769e-02  2.80402005e-02 -4.33068871e-02\n",
      " -4.42283973e-02  3.80739197e-02  9.48078305e-05 -4.34896313e-02\n",
      "  1.43868010e-02  2.44328100e-03 -4.84073348e-02  1.08955530e-02\n",
      " -9.87484679e-03  4.59295362e-02  3.96379195e-02 -2.60117278e-02\n",
      "  2.48134509e-02 -5.37149496e-02  5.62824830e-02  8.81359819e-03\n",
      "  5.25076725e-02 -1.47371171e-02 -1.74381137e-02  3.45084183e-02\n",
      "  3.75523455e-02 -4.70167398e-02 -1.94911230e-02  3.82632054e-02\n",
      " -5.67595847e-02 -1.78613677e-03  2.33404394e-02 -5.88216234e-33\n",
      " -4.87188213e-02 -2.76265331e-02 -3.38240489e-02  2.66188327e-02\n",
      " -3.39276679e-02 -8.49191286e-03 -1.91250239e-02  3.00252084e-02\n",
      "  3.40782031e-02  5.11157326e-02 -1.92479938e-02  2.85642501e-02\n",
      "  3.66040282e-02  1.68858543e-02  4.77258191e-02  1.23801949e-02\n",
      "  2.14844178e-02  4.93638741e-04  1.21274088e-02 -5.82144111e-02\n",
      "  1.62954517e-02 -7.14259967e-03  4.80091721e-02  2.51190439e-02\n",
      "  4.60097678e-02 -2.29840446e-02 -2.05696337e-02 -3.22232442e-03\n",
      "  4.00091745e-02  3.52310613e-02 -3.43153998e-02  2.75630318e-03\n",
      " -1.25138909e-02  1.97686236e-02  5.53489337e-03  1.03744589e-01\n",
      "  5.77610172e-03 -5.65426648e-02  4.19558808e-02 -3.78830209e-02\n",
      " -3.93443108e-02 -6.24310002e-02 -2.24398193e-03 -5.46548888e-02\n",
      "  4.56134379e-02 -5.69245312e-03  3.38916928e-02 -1.44447722e-02\n",
      "  2.72107590e-03  1.11192046e-02 -5.00660874e-02 -1.61127280e-02\n",
      "  1.72824331e-03  6.88878298e-02  1.16493050e-02  2.83170994e-02\n",
      "  6.97192084e-03  2.68372390e-02 -7.72086158e-03  2.16828156e-02\n",
      "  1.15182567e-02  8.72832164e-02 -6.27272809e-03 -6.44473583e-02\n",
      " -1.58233587e-02  4.03268225e-02 -1.69728417e-02 -1.61188785e-02\n",
      " -3.75576578e-02  7.02938363e-02 -3.30486484e-02  4.66323793e-02\n",
      "  1.18027823e-02  6.51075244e-02 -1.16979443e-02 -8.28344468e-03\n",
      " -5.46904989e-02 -2.00226773e-02  8.42688954e-04 -8.19525495e-03\n",
      "  2.08356827e-02  1.37454560e-02 -1.29925762e-03 -3.94575298e-02\n",
      " -2.00184621e-02 -1.53721534e-02  1.17271915e-02 -4.40111384e-02\n",
      "  5.39267659e-02 -2.33010873e-02 -2.24211290e-02 -3.65213840e-03\n",
      "  2.92213447e-02  7.56438915e-03 -2.90923100e-02  4.01517898e-02\n",
      " -2.00853311e-02 -1.79863477e-03 -1.26236109e-02  2.51076911e-02\n",
      " -4.69285399e-02 -3.08554638e-02 -3.63343686e-04  6.01787725e-03\n",
      "  3.97509150e-02  1.38547895e-02  2.49774568e-02  1.76976323e-02\n",
      " -9.31572989e-02 -9.83688794e-03  8.44924431e-03 -1.95391141e-02\n",
      " -3.26569416e-02  5.13739092e-03  5.80932433e-03  2.08537206e-02\n",
      " -5.97831607e-03  5.86810336e-02 -1.49496477e-02 -5.72965331e-02\n",
      " -5.98235102e-03  1.95203244e-03  2.72977189e-03  6.06994890e-03\n",
      " -2.00525280e-02 -1.31688165e-02 -4.06229161e-02  5.68997338e-02\n",
      "  4.44968976e-02 -1.24308197e-02  1.96967851e-02  3.80979329e-02\n",
      "  2.30237632e-07  1.10574979e-02  4.79513071e-02  6.18298426e-02\n",
      "  4.40278500e-02  6.17663702e-03  2.58289743e-03  3.38913798e-02\n",
      " -5.32939099e-03 -2.59283409e-02 -1.26143890e-02  2.46495344e-02\n",
      " -1.68772857e-03  1.17901445e-03  2.40443218e-02 -9.77309421e-02\n",
      "  1.97367184e-02 -5.52920513e-02 -6.17424622e-02 -4.87151667e-02\n",
      "  1.11090520e-03  1.18732050e-01  8.13258365e-02  3.32449116e-02\n",
      "  4.38327044e-02 -2.49559321e-02 -3.59626599e-02  1.66319404e-02\n",
      "  5.93765685e-03 -1.43972216e-02  4.46708919e-03 -6.01986311e-02\n",
      " -5.65911531e-02 -8.21538921e-03  5.83059667e-03 -1.69482119e-02\n",
      "  9.58633795e-03  1.46733588e-02  5.05845807e-02  3.06891426e-02\n",
      "  6.60468638e-02 -2.56551728e-02 -2.78858226e-02 -3.19173820e-02\n",
      " -3.39236520e-02  1.49903093e-02 -3.03336028e-02 -6.06493000e-03\n",
      " -4.81772656e-03  1.72137003e-02 -8.23370460e-03  1.55547718e-02\n",
      "  2.69106701e-02  5.44309942e-03 -1.06899524e-02 -7.82140996e-03\n",
      " -4.44506928e-02  2.55874135e-02 -5.74760661e-02 -2.05443110e-02\n",
      " -3.07849888e-02 -1.57854930e-02 -7.07536051e-03 -4.21312414e-02\n",
      "  3.79934236e-02  6.27765357e-02 -7.67793274e-03 -3.18353474e-02\n",
      "  1.99277746e-34  1.04834093e-02 -3.39326560e-02  3.93821299e-02\n",
      "  5.53065650e-02  9.42169689e-03  1.09728258e-02 -4.91939336e-02\n",
      "  2.95024160e-02 -8.85374099e-03 -5.96248657e-02 -2.37825699e-02]\n",
      "\n",
      "Sentence: Embeddings are one of the most powerful concepts in machine learning!\n",
      "Embedding: [-2.98611615e-02 -1.37522090e-02 -4.75402176e-02  2.72126738e-02\n",
      "  3.40053886e-02  3.16466093e-02  4.26964164e-02  3.29799554e-03\n",
      "  4.35718149e-02  2.53836531e-02  3.02528758e-02  3.21130976e-02\n",
      " -3.99912931e-02  1.28761912e-02  6.70219660e-02 -7.92899951e-02\n",
      "  4.68772240e-02  2.40267050e-02 -2.07997710e-02 -1.07433284e-02\n",
      " -1.19410604e-02 -5.39291315e-02  4.21055295e-02  2.23588385e-02\n",
      " -2.98949685e-02  8.35979078e-03  1.58385150e-02 -4.80236448e-02\n",
      "  1.88440620e-03 -1.67521387e-02 -2.15628538e-02 -3.88488360e-02\n",
      "  3.06274295e-02  4.20525968e-02  1.69483371e-06 -1.86929014e-02\n",
      " -1.24558546e-02  1.32128904e-02 -4.89039570e-02  1.34745976e-02\n",
      "  2.28873324e-02  8.81785806e-03  8.64930078e-03 -2.00950000e-02\n",
      " -3.15217748e-02 -2.53433287e-02  7.57318512e-02  3.62447016e-02\n",
      "  1.25290258e-02  3.09695136e-02  4.50759567e-03 -3.50042433e-02\n",
      " -4.42457036e-04 -9.76647157e-03  6.04545549e-02  4.03472222e-02\n",
      "  1.10734832e-02  6.56198896e-03 -5.84597327e-03  3.79785383e-03\n",
      " -4.46914807e-02  1.76405106e-02  2.45916825e-02 -3.60042253e-03\n",
      "  1.02473363e-01  3.73758785e-02  6.13311958e-03 -2.24676803e-02\n",
      "  1.46482522e-02  5.00536561e-02 -2.29907259e-02  1.12924809e-02\n",
      " -3.10552251e-02 -1.49508938e-02 -2.53131590e-03  3.20945159e-02\n",
      " -4.67056148e-02 -4.85886745e-02  2.98306178e-02  6.44215718e-02\n",
      " -3.12613174e-02  3.57407257e-02  4.16526757e-02 -5.52517548e-02\n",
      " -8.74624681e-03 -2.18630042e-02 -1.12744272e-02 -2.14436240e-02\n",
      " -1.32823642e-02 -2.04865988e-02 -1.00576291e-02  3.54763865e-02\n",
      " -7.47610582e-03 -3.70188318e-02  5.77893220e-02 -2.18169112e-02\n",
      "  4.36223811e-03  2.04380434e-02  3.36814784e-02 -4.92800996e-02\n",
      "  4.82793339e-02 -1.81002531e-03 -1.05118677e-02  4.13323231e-02\n",
      " -6.79834038e-02  1.75715946e-02 -4.43412475e-02  9.90841165e-03\n",
      " -3.81809063e-02  1.10827768e-02 -5.07280082e-02 -2.17451118e-02\n",
      " -1.03836292e-02  4.60332856e-02  1.55862542e-02 -4.21366692e-02\n",
      " -2.72146296e-02  3.22818942e-02 -4.24739793e-02  2.71207206e-02\n",
      " -7.41061717e-02  4.20107581e-02  2.02438347e-02  7.31811300e-02\n",
      " -8.97695404e-03 -2.31160428e-02 -3.93559337e-02 -1.46008758e-02\n",
      " -3.30910310e-02  1.12239504e-02  2.58571608e-03 -4.36851615e-03\n",
      "  1.85855366e-02  2.69934721e-02 -1.67215262e-02  3.69569734e-02\n",
      "  4.44489196e-02 -2.21723653e-02  6.72961446e-03  1.22935493e-02\n",
      "  1.71758719e-02 -2.36478099e-03  3.72263342e-02 -2.22870428e-02\n",
      "  2.94603277e-02 -2.33691521e-02  5.38469292e-03 -3.06581948e-02\n",
      " -2.38920078e-02 -2.63614226e-02 -2.01788712e-02  1.11245610e-01\n",
      " -1.99836083e-02 -3.54030766e-02  3.84143740e-02  2.53069550e-02\n",
      "  1.99551564e-02  5.53518161e-02 -1.99332908e-02 -2.16719159e-03\n",
      "  4.91092876e-02 -4.03530635e-02 -1.16977133e-02 -5.33113144e-02\n",
      "  8.29587784e-03 -5.08251674e-02 -2.65503973e-02 -1.53242880e-02\n",
      "  5.78816188e-03  2.46578455e-03 -3.44449654e-02 -1.85128290e-03\n",
      " -3.95730548e-02 -2.71690749e-02  4.93568443e-02  8.38368908e-02\n",
      "  5.43492176e-02  8.22261423e-02  1.23894550e-02 -4.79798531e-03\n",
      "  7.77383510e-04  2.98486706e-02 -1.85583923e-02  5.98795451e-02\n",
      " -6.82795746e-03  9.78120137e-04  2.85485629e-02 -7.64621003e-03\n",
      " -1.86620243e-02 -2.69287620e-02 -2.90332660e-02 -1.37871904e-02\n",
      " -2.57597747e-03 -2.20173635e-02 -1.70821529e-02 -3.81842740e-02\n",
      "  2.21505575e-02 -3.59234065e-02 -1.19439848e-02 -3.18307616e-02\n",
      " -4.80801053e-02  9.77636036e-03 -1.04860205e-03  4.15370874e-02\n",
      " -1.10974386e-02 -4.72830534e-02  1.90984756e-02 -5.31177334e-02\n",
      "  2.11325325e-02 -2.53069284e-03  5.61054908e-02 -1.33795785e-02\n",
      " -5.95863350e-03 -1.20308287e-02  4.63929772e-02 -2.81908978e-02\n",
      "  2.25355364e-02 -2.50471290e-03 -3.52452807e-02  2.55495682e-02\n",
      "  9.10396688e-03  3.25214816e-03  2.55972496e-03 -1.25624510e-02\n",
      " -3.51496525e-02 -4.28946577e-02 -2.32333806e-03  2.41021216e-02\n",
      " -5.16839186e-03  1.68740358e-02  5.52645605e-03  2.36792006e-02\n",
      "  5.65164499e-02 -3.47869098e-02 -6.34518042e-02 -7.45626027e-03\n",
      " -1.78448465e-02  5.35897501e-02  2.67291758e-02 -8.74199644e-02\n",
      "  1.04196360e-02 -4.13941889e-04 -3.04447510e-03  9.14244819e-03\n",
      "  2.91530192e-02 -5.81831373e-02  6.83463141e-02 -4.08618338e-02\n",
      " -9.09787323e-03 -3.40770334e-02  3.52411456e-02 -1.02628255e-02\n",
      " -5.72466524e-04 -2.73451488e-03  1.59635805e-02  4.49064514e-03\n",
      " -2.09051650e-02  3.02770045e-02  2.46119164e-02 -1.44068217e-02\n",
      "  1.73269827e-02  1.99038861e-03  4.23051901e-02 -2.39176489e-02\n",
      " -3.25547233e-02 -1.45940054e-02  3.95101048e-02 -6.04650192e-02\n",
      " -3.02065630e-02  1.67189669e-02 -2.26816870e-02 -2.61954647e-02\n",
      " -5.51319532e-02  1.44908438e-02 -1.99246276e-02  3.99747258e-03\n",
      "  3.12610157e-02 -4.90727648e-02 -9.49762587e-04  5.39497249e-02\n",
      " -9.10082553e-03 -2.69485917e-02 -3.63158733e-02 -1.38436779e-02\n",
      " -4.45622243e-02  5.49359098e-02  2.17597815e-03  2.23441934e-03\n",
      " -5.23013668e-03 -1.47894118e-02  3.60592194e-02  1.45263411e-02\n",
      "  8.39192793e-03 -6.10360578e-02 -7.89953209e-03 -2.98294774e-03\n",
      "  3.56567348e-03  8.33992064e-02 -2.61215270e-02  8.06722119e-02\n",
      "  3.63051519e-03  1.69974845e-02  2.58604214e-02  1.09442824e-03\n",
      " -4.57063317e-02  5.55678681e-02  2.00643297e-02  4.76660840e-02\n",
      " -4.91053089e-02 -1.86081417e-02  3.34404930e-02 -2.57310402e-02\n",
      " -3.16365249e-03  7.21444264e-02 -1.61519460e-02 -1.33933090e-02\n",
      " -6.06294237e-02 -2.82187071e-02 -8.91928840e-03 -2.71171238e-03\n",
      "  8.04919284e-03 -4.95209545e-02  7.89434537e-02  2.76427977e-02\n",
      " -5.42582897e-03 -3.06726829e-03 -4.11827080e-02  1.39171779e-02\n",
      "  3.04253157e-02  1.02856401e-02  1.06679136e-02 -5.56554385e-02\n",
      " -1.75083298e-02  2.03868803e-02  8.43314081e-03  3.82470898e-02\n",
      " -3.89099903e-02 -1.61303412e-02  3.18059921e-02 -7.32969940e-02\n",
      " -1.76502373e-02 -4.79874052e-02 -5.55042140e-02 -5.00750076e-03\n",
      "  4.46798978e-04  3.57332937e-02 -8.24674149e-04 -3.34324315e-02\n",
      " -3.32416743e-02 -2.46460270e-02  2.15332285e-02  3.90860531e-03\n",
      "  2.53471453e-02  6.02994114e-03 -7.81607628e-03  1.23765925e-02\n",
      " -1.71039272e-02  2.68102791e-02  2.83670239e-03 -1.27643198e-02\n",
      "  1.00510873e-01  1.03580691e-02 -3.55142914e-02  1.56616364e-02\n",
      " -9.85949561e-02  4.58441749e-02 -3.15230899e-02 -2.35781278e-02\n",
      " -2.78350711e-02 -7.75875378e-05 -2.82363389e-02 -1.92918591e-02\n",
      "  1.87389944e-02  5.71941249e-02  2.56912094e-02 -3.20030376e-02\n",
      "  1.99074261e-02 -3.15819904e-02 -4.02062275e-02  5.77630661e-02\n",
      "  1.72974002e-02 -5.37014343e-02 -1.25325732e-02 -1.45484423e-02\n",
      " -5.76175004e-02  1.09727690e-02 -2.04728488e-02  2.85541043e-02\n",
      " -5.04399762e-02  4.36991155e-02  1.75711047e-02 -1.02344044e-02\n",
      " -9.69772041e-02 -2.99995132e-02 -2.86679287e-02  2.24936623e-02\n",
      " -1.68121178e-02 -1.43673755e-02 -8.79590865e-03 -1.69043746e-02\n",
      "  2.41558235e-02 -6.53192624e-02 -4.10799943e-02 -2.34058686e-02\n",
      " -6.76065087e-02 -1.55690713e-02  3.62358317e-02  7.83160031e-02\n",
      " -4.97517176e-02 -7.08547980e-02 -5.01179025e-02 -8.56435159e-04\n",
      "  5.44897327e-03  4.34699422e-03  9.88052860e-02 -2.16415636e-02\n",
      " -1.87750850e-02  1.15070017e-02  2.63996273e-02  1.65235698e-02\n",
      " -2.24057846e-02 -4.31826822e-02  1.31803945e-01 -2.97034755e-02\n",
      "  2.65934225e-02 -1.38888676e-02 -1.67003851e-02  3.44146229e-02\n",
      " -8.94356798e-03  6.16001263e-02 -3.42303254e-02  2.46419152e-03\n",
      " -8.14090855e-03  5.80325760e-02  5.24208322e-02 -1.53281540e-02\n",
      "  4.01382819e-02  1.51407821e-02 -3.01468698e-03 -4.97021489e-02\n",
      " -4.24302649e-03  5.77288419e-02  3.17873694e-02  4.74007875e-02\n",
      "  2.95218136e-02 -1.50122950e-02 -2.47945730e-02 -7.11502284e-02\n",
      "  2.06847545e-02  3.11487522e-02 -5.86067792e-03  1.62786935e-02\n",
      " -3.93682383e-02  5.46505600e-02  3.26595046e-02 -1.87021531e-02\n",
      " -9.79863331e-02  4.33768472e-03 -5.58157302e-02 -1.34620974e-02\n",
      "  2.88453996e-02  1.58748161e-02 -3.32564898e-02  1.44415814e-03\n",
      " -5.51108010e-02  8.24674368e-02  2.38846000e-02 -2.04837732e-02\n",
      " -4.78586787e-03  3.78722884e-02 -4.87562940e-02  3.44646871e-02\n",
      "  1.10358084e-02  1.12450747e-02  1.33262491e-02 -3.46375667e-02\n",
      " -6.92220926e-02  7.30126025e-03 -6.57012314e-03  1.73203330e-02\n",
      "  5.23057114e-03  4.48132232e-02  3.89853194e-02 -1.99274216e-02\n",
      " -1.80920698e-02  3.25937532e-02 -2.02026237e-02  4.86206700e-04\n",
      " -8.88755545e-03 -1.91348363e-02  2.50685718e-02  4.74020317e-02\n",
      "  2.18658079e-03 -1.69988275e-02  3.62671576e-02  3.46244965e-03\n",
      "  4.21938486e-03  8.04172531e-02  3.10627613e-02 -1.04941835e-03\n",
      " -3.55466641e-02  4.34836932e-02 -3.06218714e-02 -3.03192288e-02\n",
      " -4.13175076e-02 -1.05257835e-02 -2.35242844e-02 -1.86771844e-02\n",
      "  4.42935573e-03  5.45056127e-02 -6.05017617e-02  2.48421840e-02\n",
      " -3.36966217e-02 -4.54169065e-02 -2.63173338e-02  6.98052673e-03\n",
      "  6.92871660e-02 -2.04491280e-02 -1.96813494e-02 -9.72562283e-03\n",
      " -1.21564772e-02  7.89341982e-03  1.84745819e-03 -6.93650916e-02\n",
      "  2.43357103e-02  4.00609225e-02  3.44013125e-02 -2.84281913e-02\n",
      " -1.09431241e-02  1.38742812e-02 -4.40585287e-03  1.19345612e-03\n",
      " -8.81164819e-02  1.15930764e-02 -2.56351605e-02  5.57525903e-02\n",
      "  1.26946136e-01  5.39566018e-02 -1.41436392e-02  1.27196210e-02\n",
      " -1.32236034e-02 -5.94484396e-02  2.86704693e-02  2.57284883e-02\n",
      " -8.33775196e-03  8.17429216e-04  5.93050849e-03  3.29109989e-02\n",
      "  4.12751958e-02 -5.77958021e-03 -1.71124320e-02  1.06227808e-02\n",
      " -2.19601393e-02 -4.97207195e-02  2.53765434e-02 -5.60257579e-33\n",
      " -1.35397352e-02 -3.77959087e-02 -2.67923623e-03 -3.69689486e-04\n",
      " -1.98267996e-02  5.47052221e-03  6.02684729e-03  1.93068981e-02\n",
      "  3.87984910e-03  2.97698658e-02 -1.88228786e-02  2.20034621e-03\n",
      "  8.17020424e-03  1.61965508e-02  3.17528620e-02 -6.83420664e-03\n",
      "  2.19252091e-02  4.37734532e-04  2.96859164e-02 -2.62557324e-02\n",
      "  6.49381056e-03  3.56025174e-02  1.58609450e-03 -4.76583838e-02\n",
      " -5.26238643e-02  3.78274024e-02  3.54341641e-02 -3.10347937e-02\n",
      "  7.96400756e-03  5.48469201e-02 -3.56443301e-02  9.10133403e-03\n",
      " -9.45984386e-03 -4.63287197e-02 -1.63906608e-02  6.32453188e-02\n",
      " -1.38588622e-02 -5.95724732e-02 -1.57991052e-02  2.01887432e-02\n",
      " -1.98293459e-02 -3.49211507e-02  2.27938127e-02 -5.91621660e-02\n",
      "  4.18854430e-02  1.20744819e-03  5.19158654e-02 -1.88435949e-02\n",
      " -3.12101711e-02  2.34932993e-02 -7.41029829e-02 -2.76645325e-04\n",
      " -1.51720373e-02  6.11714087e-02  1.25065133e-01 -1.28459297e-02\n",
      " -1.12671442e-02  1.51749223e-03 -8.09153542e-02  1.12689175e-02\n",
      " -1.97574161e-02  2.74268202e-02  9.40990541e-03 -9.58757848e-03\n",
      "  2.54850890e-02  6.81658909e-02 -1.83452927e-02 -1.00963950e-01\n",
      " -9.45247803e-03 -5.27006062e-03  1.98684093e-02  9.80847478e-02\n",
      "  3.15633118e-02  5.30422926e-02  3.75123024e-02 -6.64209053e-02\n",
      " -5.92880435e-02 -1.57073718e-02  1.76609475e-02 -5.81073873e-02\n",
      "  2.23230850e-02  1.29869804e-02 -3.30261216e-02  9.96865099e-04\n",
      " -9.87089425e-03 -3.12955193e-02  2.28525070e-03 -4.91250232e-02\n",
      "  1.47693492e-02 -1.83367580e-02 -4.16305251e-02  3.76897268e-02\n",
      "  3.35410200e-02 -7.97111541e-02  4.01300378e-02  1.59071442e-02\n",
      "  5.06089302e-03  4.28808592e-02  2.29760259e-02 -4.13350984e-02\n",
      " -3.10503226e-02 -5.26404902e-02 -4.95405085e-02 -2.94256508e-02\n",
      "  5.94924279e-02 -2.59803087e-02  3.02497428e-02  8.80410802e-03\n",
      " -4.84467186e-02 -2.00851355e-02  9.82172880e-03 -7.89193735e-02\n",
      "  4.52884007e-03 -9.34895221e-03  9.23312176e-03 -3.17362249e-02\n",
      "  2.10833047e-02  6.37123501e-03  3.36347744e-02  3.83613594e-02\n",
      " -4.55528051e-02  1.08117843e-03 -9.83321294e-03  7.70189054e-03\n",
      " -2.87617501e-02 -1.74959432e-02 -4.27811267e-03  2.81287301e-02\n",
      "  4.97339182e-02 -7.45570809e-02 -1.07008554e-02 -7.66055938e-03\n",
      "  2.33968819e-07  1.52483070e-02  8.39613974e-02  3.67242955e-02\n",
      " -3.69249247e-02  3.64752337e-02  4.26422060e-02 -4.39824676e-03\n",
      "  1.78133752e-02 -2.67076921e-02 -7.13898800e-03  5.59975952e-02\n",
      "  3.13965939e-02  2.13439390e-03  3.90370674e-02 -8.78528729e-02\n",
      " -2.21659914e-02 -2.47735735e-02 -1.18190618e-02 -7.89707340e-03\n",
      " -2.08857376e-02  4.30556312e-02  1.07643515e-01  4.40618806e-02\n",
      "  1.47963315e-02  2.44862903e-02 -3.86268087e-02  1.80743653e-02\n",
      " -1.47838157e-03  7.74167255e-02 -4.19565663e-02 -3.80529054e-02\n",
      "  3.61258015e-02  1.59038266e-03  1.95323452e-02 -2.00080238e-02\n",
      "  4.22538482e-02  3.06111630e-02 -3.53699736e-03  5.93108824e-03\n",
      " -2.23223511e-02 -2.07131281e-02 -3.62916989e-03  1.74653921e-02\n",
      " -4.08758484e-02  5.91594912e-02 -5.89099042e-02 -3.96754332e-02\n",
      " -3.33528817e-02  1.02162044e-02  6.97289826e-03  7.70389810e-02\n",
      " -1.86911635e-02 -1.82568394e-02 -2.42318958e-02 -3.40701244e-03\n",
      " -3.60554941e-02  4.33389544e-02 -3.48602720e-02  5.27768284e-02\n",
      "  2.89709978e-02 -4.98462878e-02 -1.94749124e-02  1.16398185e-02\n",
      " -3.04614920e-02  8.04638043e-02  6.56248182e-02 -2.84533035e-02\n",
      "  1.81615278e-34 -4.19155834e-03 -2.57882401e-02  5.17319962e-02\n",
      "  4.94420715e-02  1.32476697e-02 -4.21994030e-02 -1.12458607e-02\n",
      " -2.61520464e-02  5.51130548e-02  2.20024977e-02 -2.51170527e-02]\n",
      "\n",
      "Sentence: Learn to use embeddings well and you'll be well on your way to being an AI engineer.\n",
      "Embedding: [-2.20730864e-02  2.08950471e-02 -6.03006035e-02  8.43949523e-03\n",
      "  4.37650681e-02  1.55070676e-02  4.99907322e-02 -3.03232297e-02\n",
      "  4.94784340e-02  2.35511437e-02  3.29350382e-02  1.53877158e-02\n",
      " -6.68355227e-02  1.11002877e-01  6.92676753e-02 -2.31889300e-02\n",
      "  3.79103236e-02 -4.94147558e-03 -1.57800727e-02 -3.45476270e-02\n",
      " -2.65052989e-02 -2.47879587e-02 -1.86141413e-02  3.00361682e-02\n",
      " -2.81186681e-02 -8.75141192e-03 -3.30770528e-03 -2.06116699e-02\n",
      "  1.03315702e-02 -1.51483351e-02 -3.48331034e-02 -2.63248049e-02\n",
      "  2.06907578e-02  3.79109383e-02  1.81912856e-06 -2.44291243e-03\n",
      " -1.80562644e-03  5.61762089e-03 -2.79870126e-02  1.54703241e-02\n",
      "  3.06457151e-02  3.72601748e-02 -1.55611429e-02  2.54414342e-02\n",
      " -6.42072260e-02  3.16353068e-02  6.63442612e-02  3.80970463e-02\n",
      "  5.57845198e-02  5.31660616e-02 -9.69295111e-03 -3.61424387e-02\n",
      "  3.72435227e-02 -4.67827870e-03  5.14576025e-02  1.00057460e-02\n",
      "  4.90291463e-03  1.41562968e-02  4.95100059e-02  3.32950056e-03\n",
      " -3.21100689e-02  4.42387499e-02  3.27415764e-02 -7.90621527e-03\n",
      "  1.07809775e-01  7.32944310e-02  3.36702615e-02 -4.28345762e-02\n",
      "  1.05966358e-02  2.05654185e-02 -2.02670135e-02  1.04964469e-02\n",
      " -1.97615474e-02 -2.89188429e-05 -2.61862166e-02 -1.85174141e-02\n",
      " -3.44269387e-02 -4.08620723e-02  2.32571904e-02  2.14195773e-02\n",
      "  1.31321242e-02 -3.27211358e-02 -1.91425923e-02 -2.86572203e-02\n",
      " -1.16859255e-02  1.21910730e-02  1.05248615e-02 -3.39584760e-02\n",
      "  3.08910967e-03 -4.44888994e-02  2.65104771e-02  1.09536666e-02\n",
      "  2.51450688e-02 -6.48832927e-03  4.54359781e-03 -2.02784855e-02\n",
      " -1.03215948e-02  2.06589755e-02 -1.65313650e-02 -2.45612282e-02\n",
      "  5.47549762e-02  2.68261526e-02  2.95510087e-02  3.86754908e-02\n",
      " -7.76720569e-02  3.80056016e-02 -2.98364386e-02  7.96886086e-02\n",
      " -3.00942827e-02  7.57843256e-03 -6.89826980e-02 -2.92667281e-02\n",
      " -2.35580411e-02  3.48198861e-02  2.52938643e-02 -4.53817174e-02\n",
      " -1.57939140e-02  4.39031273e-02 -4.04336043e-02  8.32529087e-03\n",
      " -2.84665115e-02  4.94933464e-02  2.41277460e-02  3.02192606e-02\n",
      " -4.99590412e-02 -5.94533011e-02 -3.70176062e-02  1.30330315e-02\n",
      " -3.36469263e-02  3.45589891e-02 -1.44523047e-02  2.57640537e-02\n",
      "  4.61187167e-03  2.21551694e-02 -4.93460381e-03  9.66004878e-02\n",
      " -2.72446196e-03  5.65336784e-04 -3.24248672e-02  1.31681534e-02\n",
      "  4.41607237e-02 -7.03056995e-03  6.84260875e-02 -2.28166766e-02\n",
      " -2.81035481e-03 -4.23883162e-02 -1.33632086e-02 -5.96738532e-02\n",
      " -6.96127070e-03 -2.31900662e-02 -3.78851220e-02  9.80186611e-02\n",
      " -2.21728757e-02 -2.30062809e-02  3.22814807e-02  8.21805280e-03\n",
      " -7.04117026e-03  4.84079681e-02  4.23291363e-02 -2.59713479e-03\n",
      "  1.20539466e-04  1.67414434e-02  2.91197915e-02 -1.28740808e-02\n",
      " -2.41077840e-02 -3.29320692e-02 -3.50295776e-03 -3.19322050e-02\n",
      " -2.64171846e-02  2.30404045e-02  1.11637209e-02 -9.95994639e-03\n",
      " -1.75901204e-02 -2.00275937e-03  1.21594863e-02  4.67823520e-02\n",
      "  5.20882308e-02  7.21171945e-02  1.94978192e-02  1.15072522e-02\n",
      "  5.94160706e-03 -1.47834113e-02 -2.87724100e-02  6.72666728e-02\n",
      " -1.68758649e-02  5.25876926e-03 -3.39739248e-02  5.24596274e-02\n",
      " -2.59793028e-02 -4.41379957e-02  1.47447095e-03 -1.06599238e-02\n",
      " -1.51859475e-02 -1.55879231e-03  1.81504581e-02 -4.85411063e-02\n",
      "  3.67902778e-03 -6.59313649e-02 -1.49418581e-02 -3.23529877e-02\n",
      " -2.79949103e-02  1.71856787e-02 -7.87080731e-03  4.65692393e-02\n",
      "  1.47123523e-02 -7.40438998e-02 -6.52104393e-02 -5.22734933e-02\n",
      " -1.82343647e-02  5.20859398e-02  3.06304563e-02 -2.36037616e-02\n",
      "  2.42384579e-02 -1.83940288e-02 -4.83012386e-03 -2.13386305e-02\n",
      "  1.56584159e-02  9.87342838e-03 -4.25561778e-02  6.00461010e-03\n",
      " -3.14499554e-03  4.51518316e-03 -1.52778858e-03  1.13731371e-02\n",
      " -6.96354210e-02 -3.37258279e-02  1.33406920e-02  4.87286644e-03\n",
      " -7.81487674e-03  4.78049517e-02 -1.59711801e-02  3.14606503e-02\n",
      "  5.15920669e-02 -4.05122116e-02 -5.06460704e-02  9.99933574e-03\n",
      " -2.00729854e-02  4.21552621e-02  3.03183198e-02 -1.00431219e-01\n",
      " -4.12020199e-02  3.43990736e-02  3.29209454e-02  1.07407698e-03\n",
      "  3.70962359e-02 -6.94237500e-02  6.52393252e-02  8.31663143e-03\n",
      "  1.68036129e-02 -2.60706060e-02  8.14502407e-03 -1.48009313e-02\n",
      " -2.65670624e-02  3.29321921e-02 -7.37514952e-03  7.23975291e-03\n",
      " -2.69330274e-02  1.71755292e-02 -2.28083245e-02 -4.75340243e-03\n",
      "  2.88569070e-02  1.30791450e-04  5.44129126e-02 -1.43378889e-02\n",
      "  1.89891774e-02 -1.32732140e-02  4.01178077e-02 -7.29275271e-02\n",
      " -2.41210684e-02  3.16217355e-02 -1.68014225e-02  8.47541261e-03\n",
      " -5.23940846e-02 -1.43883014e-02 -1.46156596e-02  6.39908854e-03\n",
      "  2.15113536e-02 -5.18960617e-02 -4.30576317e-02  2.34075673e-02\n",
      "  2.30274023e-03 -2.48434190e-02 -4.38243560e-02 -2.16570273e-02\n",
      " -6.91595525e-02  1.76770221e-02  2.12066788e-02 -2.20294539e-02\n",
      " -1.06772678e-02  9.57421958e-03  2.21988838e-02  5.51471114e-02\n",
      "  1.03683081e-02 -8.14824402e-02 -7.94707052e-03 -1.85866635e-02\n",
      "  1.20494720e-02  7.51403049e-02 -1.41215837e-02  8.83924663e-02\n",
      "  3.12628709e-02  8.12258013e-03 -2.29444299e-02  3.96010987e-02\n",
      " -2.00168062e-02  9.16027725e-02 -2.06839107e-02  5.84990941e-02\n",
      " -4.32368629e-02 -4.74742986e-03 -9.51888226e-03  5.42947697e-03\n",
      "  1.19160388e-04  6.15376383e-02 -1.68788224e-03 -4.66320626e-02\n",
      " -2.01405492e-02  1.32405879e-02  9.70683340e-03  2.73847990e-02\n",
      "  3.06639709e-02  6.71583228e-03  8.71220902e-02 -1.97371375e-03\n",
      "  8.18298385e-03  5.44355717e-03 -5.76205887e-02  1.34820594e-02\n",
      "  5.06297732e-03 -2.10569166e-02  1.25937099e-02 -5.49784256e-03\n",
      " -1.44645479e-02 -2.92567108e-02  5.53298555e-02 -2.60098986e-02\n",
      " -2.82455003e-03 -2.30901819e-02  8.89708847e-03 -2.61565372e-02\n",
      "  9.08628688e-04 -6.16203696e-02 -7.56419599e-02 -1.05931554e-02\n",
      " -1.19563900e-02  6.71458542e-02 -1.96234863e-02 -5.00934124e-02\n",
      " -3.91229056e-02 -3.07007711e-02  7.18906596e-02  9.29245446e-03\n",
      " -6.34386064e-03  7.87001627e-04 -1.36484047e-02  2.87188776e-02\n",
      "  4.01224978e-02  1.28036933e-02  1.77381355e-02 -4.75977408e-03\n",
      "  5.47173247e-02  1.10808085e-03 -2.25790460e-02 -2.80285184e-03\n",
      " -1.13696031e-01  2.55904533e-02  4.00434597e-04 -4.39811759e-02\n",
      "  1.36319203e-02 -1.54137351e-02 -4.99015450e-02 -2.32889708e-02\n",
      " -1.62988110e-03  3.95835489e-02  1.89040732e-02 -3.02703492e-02\n",
      "  2.71438044e-02  1.05672900e-03 -4.21069525e-02  3.71961035e-02\n",
      "  3.54258679e-02 -6.98274747e-02 -2.20937524e-02 -4.01496515e-02\n",
      " -1.90164354e-02 -2.69835312e-02 -1.51213249e-02  3.33365500e-02\n",
      " -9.74889770e-02  1.73102319e-02  6.21018326e-03 -2.59427750e-03\n",
      " -1.10152945e-01 -6.10186681e-02 -1.36549706e-02 -1.35035478e-02\n",
      " -6.72573447e-02 -4.05122433e-03 -6.64986344e-03  3.86565342e-03\n",
      "  9.43471678e-03 -3.86636928e-02 -1.93592664e-02  1.34933842e-02\n",
      " -4.58106697e-02  6.06737025e-02  6.06380291e-02  4.85596843e-02\n",
      " -4.56088446e-02 -5.71936779e-02 -1.55094704e-02  3.40963081e-02\n",
      "  9.48158791e-04 -9.94347688e-03  2.84657758e-02 -3.29024270e-02\n",
      " -2.83211097e-02  3.19907703e-02  2.61298660e-02 -2.74054911e-02\n",
      " -1.36353606e-02  7.47712981e-03  1.19430304e-01 -4.45806980e-02\n",
      "  1.07671069e-02 -8.69424194e-02 -2.19550878e-02  1.83874723e-02\n",
      " -1.06521323e-02 -1.89243034e-02 -3.06513719e-02 -3.04701831e-02\n",
      " -3.22214626e-02  4.12151478e-02  8.95753969e-03 -2.73180082e-02\n",
      "  9.39993095e-03 -9.57135810e-04 -1.94010008e-02 -4.92623448e-02\n",
      " -9.18887183e-03  4.66894582e-02  5.41892983e-02  2.21609380e-02\n",
      " -2.86351703e-02  5.20295575e-02  2.47588903e-02 -7.14268833e-02\n",
      " -1.26206568e-02  7.35519687e-03  2.13784520e-02  2.93514188e-02\n",
      " -2.57651322e-02  5.20562790e-02 -2.74891946e-02 -3.10242847e-02\n",
      " -9.02879536e-02  6.10371567e-02 -5.22609800e-02  2.13111639e-02\n",
      "  4.41734977e-02  3.23371030e-02  1.75648071e-02 -2.39520241e-02\n",
      " -2.69709472e-02  5.11278063e-02  2.69065481e-02 -4.51932624e-02\n",
      "  2.52656615e-03  2.44934056e-02 -2.89541539e-02  2.79993024e-02\n",
      " -1.36022624e-02 -4.32368815e-02  1.85830258e-02  7.63609569e-05\n",
      "  2.43516359e-03 -3.73320491e-03 -1.72279738e-02  1.01292571e-02\n",
      "  1.98437385e-02 -2.60018334e-02 -3.40176350e-03  1.09125394e-02\n",
      " -4.16363589e-02  3.37031744e-02 -2.81635430e-02  1.79126170e-02\n",
      " -4.53095101e-02 -1.09819639e-02 -2.20824126e-03  1.99103113e-02\n",
      "  3.56371887e-02 -3.11799534e-02  3.78751829e-02 -1.41409133e-02\n",
      " -2.16906853e-02  2.73019634e-02  3.69817950e-03  6.35388270e-02\n",
      "  1.22669041e-02 -6.02274528e-03 -7.60759227e-03 -1.86565276e-02\n",
      " -5.64718246e-03 -2.20048241e-03 -1.31825218e-02  1.67724416e-02\n",
      " -3.77264768e-02  2.97894832e-02 -5.01569808e-02  4.89087850e-02\n",
      " -6.07444607e-02 -8.39418769e-02 -5.09001613e-02  1.81767922e-02\n",
      "  6.66732565e-02 -3.30038881e-03 -2.82398984e-03 -5.35406880e-02\n",
      "  3.90341543e-02  2.19852924e-02  3.13555561e-02 -3.36527377e-02\n",
      "  1.96913369e-02  1.67883597e-02  5.04002981e-02  3.08058644e-03\n",
      " -7.24763901e-04  4.42907251e-02 -4.12960164e-03  4.29328717e-02\n",
      " -6.62552118e-02  1.16053037e-03 -2.81716548e-02  1.56886149e-02\n",
      "  9.78133455e-02  5.53594828e-02 -1.39379054e-02  2.12307014e-02\n",
      " -1.30956145e-02 -6.82028085e-02 -8.09032528e-04  4.99291942e-02\n",
      " -2.69265454e-02 -2.97803804e-02  3.84462141e-02  1.97354015e-02\n",
      "  3.37088592e-02  1.65873636e-02  5.77314617e-03 -3.04897595e-02\n",
      " -1.52511867e-02 -3.56159471e-02 -8.69219657e-03 -5.42296833e-33\n",
      "  3.24369385e-03 -3.46329845e-02  3.58932987e-02  1.83771141e-02\n",
      " -2.17505097e-02 -3.26411836e-02  2.88396142e-03  1.50463954e-02\n",
      " -1.75258995e-03 -1.99418999e-02 -6.10350724e-03  2.23847255e-02\n",
      " -8.78938939e-04  2.48685032e-02  3.39736007e-02  2.75592878e-02\n",
      "  3.37792188e-02  3.98565121e-02  2.55545750e-02  1.83042418e-02\n",
      " -2.92878523e-02  5.18084597e-03  8.37833271e-04 -3.66560705e-02\n",
      " -3.46733034e-02  3.82687151e-02  5.50822308e-03 -4.35187817e-02\n",
      "  2.44077519e-02  3.54167782e-02 -2.13442650e-02  2.86623556e-02\n",
      " -2.65407434e-04  3.73409986e-02 -8.68166331e-03  3.04787536e-03\n",
      " -2.71682180e-02 -3.85088585e-02 -6.12388141e-02 -2.00842042e-03\n",
      " -1.22080306e-02 -8.67198259e-02  3.75361112e-03 -1.77707374e-02\n",
      "  8.32483824e-03 -1.69167239e-02  7.02404231e-02  3.32234018e-02\n",
      "  4.34313044e-02  1.47017175e-02 -1.25546947e-01  1.50866406e-02\n",
      " -5.43164499e-02 -1.79148815e-03  4.99601141e-02 -1.53786307e-02\n",
      "  3.32683213e-02 -3.07709053e-02 -1.83896516e-02  9.45800543e-03\n",
      " -4.60291356e-02 -2.03870120e-03  2.62428354e-02 -5.00788689e-02\n",
      "  2.01836191e-02  6.08983077e-02 -2.01180503e-02 -2.60053817e-02\n",
      "  1.05925333e-02 -3.31153423e-02  1.62595548e-02  7.77862594e-02\n",
      " -1.90732081e-03 -5.62886661e-03  1.43716279e-02 -4.06833254e-02\n",
      " -5.14971167e-02  1.66213344e-04 -3.33052385e-03  1.44688794e-02\n",
      "  4.24890488e-04  3.04453317e-02 -1.83636490e-02  1.51192502e-03\n",
      "  2.99861450e-02 -3.68002057e-02  8.35623592e-03 -3.31025571e-02\n",
      "  2.66911425e-02  5.47828246e-03 -1.80524122e-02  2.42577828e-02\n",
      "  5.72708482e-03 -5.93372174e-02  1.04358412e-01 -9.87923797e-03\n",
      " -1.36106042e-02  5.79998977e-02  2.50108428e-02  2.89337169e-02\n",
      " -3.20520885e-02 -3.40233222e-02 -3.41698751e-02 -2.76982095e-02\n",
      "  6.47003055e-02  1.50798000e-02 -1.61925107e-02  3.03266272e-02\n",
      " -2.67187972e-02 -3.67774479e-02 -2.27845348e-02 -5.36433980e-02\n",
      "  1.90499891e-02 -3.42503153e-02  1.32688116e-02 -5.41317556e-03\n",
      "  7.49740982e-03 -7.36935297e-04 -3.08569372e-02  3.82288434e-02\n",
      " -2.08311137e-02 -3.43154818e-02  5.60239842e-03  1.44999176e-02\n",
      " -3.76364030e-02 -5.11783026e-02 -3.51075046e-02  1.71867795e-02\n",
      "  1.50721567e-02 -9.62026566e-02 -1.53544731e-02  1.58376358e-02\n",
      "  2.42940928e-07 -5.88801224e-03  7.68796578e-02  5.86063452e-02\n",
      "  2.21232940e-02 -2.36690864e-02  5.25273830e-02  1.48661695e-02\n",
      "  7.34175742e-03 -4.98924823e-03  4.37414236e-02 -1.28331883e-02\n",
      "  3.37342173e-02 -1.10814963e-02 -1.33937830e-02 -7.80064240e-02\n",
      " -1.36330929e-02  1.94749273e-02  1.91744382e-03 -3.00251953e-02\n",
      "  1.02735707e-04  9.54532623e-02  1.19654015e-01  3.73372473e-02\n",
      "  4.25130967e-03  2.05130205e-02 -3.85415107e-02 -1.90614350e-02\n",
      "  5.88792898e-02  6.81264475e-02 -3.12595479e-02 -6.50440231e-02\n",
      "  2.48043798e-02  3.90115863e-04  7.54762217e-02 -3.46075594e-02\n",
      "  1.32949529e-02  4.14005592e-02  3.07568815e-02  5.50352642e-03\n",
      " -1.53088255e-03  2.75993589e-02  6.46027969e-03  1.05398400e-02\n",
      " -3.09298635e-02  4.60232347e-02 -3.64920311e-02 -1.39539894e-02\n",
      " -3.53721119e-02  7.97801826e-04  1.40632791e-02  1.80258621e-02\n",
      " -1.43368840e-02  2.19216174e-03 -3.96873280e-02 -1.17282066e-02\n",
      " -4.45220061e-02  8.05771165e-03 -4.04861979e-02  3.56148519e-02\n",
      "  5.12852967e-02 -6.64038584e-02 -5.32595031e-02  8.92898254e-03\n",
      "  1.56423878e-02  1.02110982e-01  8.10763519e-03 -4.03858954e-03\n",
      "  2.02352628e-34 -1.38293970e-02 -1.17623871e-02  1.51005751e-02\n",
      "  8.25896189e-02  2.39228606e-02 -1.10377921e-02  3.65661038e-03\n",
      " -7.44783366e-03  2.94555184e-02  3.53000802e-03 -6.10421598e-02]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Requires !pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\", \n",
    "                                      device=\"cpu\") # choose the device to load the model to (note: GPU will often be *much* faster than CPU)\n",
    "\n",
    "# Create a list of sentences to turn into numbers\n",
    "sentences = [\n",
    "    \"The Sentences Transformers library provides an easy and open-source way to create embeddings.\",\n",
    "    \"Sentences can be embedded one by one or as a list of strings.\",\n",
    "    \"Embeddings are one of the most powerful concepts in machine learning!\",\n",
    "    \"Learn to use embeddings well and you'll be well on your way to being an AI engineer.\"\n",
    "]\n",
    "\n",
    "# Sentences are encoded/embedded by calling model.encode()\n",
    "embeddings = embedding_model.encode(sentences)\n",
    "embeddings_dict = dict(zip(sentences, embeddings))\n",
    "\n",
    "# See the embeddings\n",
    "for sentence, embedding in embeddings_dict.items():\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eabe492f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk token count: 0.75 | Text: 253\n",
      "Chunk token count: 15.5 | Text: From another point of view, the use of a deep architecture 555\n",
      "Chunk token count: 15.75 | Text: At training iteration t, the next search direction dt takes 313\n",
      "Chunk token count: 2.25 | Text: 3 404 753\n",
      "Chunk token count: 20.5 | Text: won the ImageNet object recognition challenge, but convolutional networks 2012 371\n"
     ]
    }
   ],
   "source": [
    "# Show random chunks with under 30 tokens in length\n",
    "min_token_length = 30\n",
    "for row in df[df[\"chunk_token_count\"] <= min_token_length].sample(5).iterrows():\n",
    "    print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_chunk\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "abf86cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': -14,\n",
       "  'sentence_chunk': 'Contents Website vii Acknowledgments viii Notation xi 1 Introduction 1 1.1 Who Should Read This Book? . . . . . . . . . . . . . . . . . . . .8 1.2 Historical Trends in Deep Learning . . . . . . . . . . . . . . . . .11 I Applied Math and Machine Learning Basics 29 2 Linear Algebra 31 2.1 Scalars, Vectors, Matrices and Tensors . . . . . . . . . . . . . . .31 2.2 Multiplying Matrices and Vectors . . . . . . . . . . . . . . . . . .34 2.3 Identity and Inverse Matrices . . . . . . . . . . . . . . . . . . . .36 2.4 Linear Dependence and Span . . . . . . . . . . . . . . . . . . . .37 2.5 Norms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .39 2.6 Special Kinds of Matrices and Vectors . . . . . . . . . . . . . . .40 2.7 Eigendecomposition . . . . . . . . . . . . . . . . . . . . . . . . . .42 2.8 Singular Value Decomposition . . . . . . . . . . . . . . . . . . . .',\n",
       "  'chunk_char_count': 884,\n",
       "  'chunk_word_count': 274,\n",
       "  'chunk_token_count': 221.0},\n",
       " {'page_number': -14,\n",
       "  'sentence_chunk': '44 2.9 The Moore-Penrose Pseudoinverse . . . . . . . . . . . . . . . . . .45 2.10 The Trace Operator . . . . . . . . . . . . . . . . . . . . . . . . .46 2.11 The Determinant . . . . . . . . . . . . . . . . . . . . . . . . . . .47 2.12 Example: Principal Components Analysis . . . . . . . . . . . . .48 3 Probability and Information Theory 53 3.1 Why Probability? . . . . . . . . . . . . . . . . . . . . . . . . . . .54 i',\n",
       "  'chunk_char_count': 420,\n",
       "  'chunk_word_count': 137,\n",
       "  'chunk_token_count': 105.0}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_chunks_over_min_token_len = df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient=\"records\")\n",
    "pages_and_chunks_over_min_token_len[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ed84cd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1874/1874 [22:50<00:00,  1.37it/s]\n"
     ]
    }
   ],
   "source": [
    "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "    item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5653612a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "768\n",
      "[-0.01161679 -0.01041864 -0.02972839  0.03680343 -0.02879737]\n"
     ]
    }
   ],
   "source": [
    "print(type(item[\"embedding\"]))        # should be <class 'list'> or <class 'numpy.ndarray'>\n",
    "print(len(item[\"embedding\"]))         # e.g., 384, 512, 768, etc.\n",
    "print(item[\"embedding\"][:5])          # show first few values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c0b96bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\n",
    "    {\n",
    "        \"sentence_chunk\": item[\"sentence_chunk\"],\n",
    "        **{f\"dim_{i}\": float(x) for i, x in enumerate(item[\"embedding\"])}\n",
    "    }\n",
    "    for item in pages_and_chunks_over_min_token_len\n",
    "])\n",
    "\n",
    "df.to_csv(\"embeddings_flat.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a579bbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>dim_0</th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_758</th>\n",
       "      <th>dim_759</th>\n",
       "      <th>dim_760</th>\n",
       "      <th>dim_761</th>\n",
       "      <th>dim_762</th>\n",
       "      <th>dim_763</th>\n",
       "      <th>dim_764</th>\n",
       "      <th>dim_765</th>\n",
       "      <th>dim_766</th>\n",
       "      <th>dim_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contents Website vii Acknowledgments viii Nota...</td>\n",
       "      <td>-0.040271</td>\n",
       "      <td>0.013905</td>\n",
       "      <td>-0.021256</td>\n",
       "      <td>0.041426</td>\n",
       "      <td>-0.021738</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.054794</td>\n",
       "      <td>-0.003756</td>\n",
       "      <td>0.003455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028978</td>\n",
       "      <td>0.006534</td>\n",
       "      <td>0.036656</td>\n",
       "      <td>-0.058340</td>\n",
       "      <td>-0.048954</td>\n",
       "      <td>-0.069978</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>-0.000420</td>\n",
       "      <td>-0.028307</td>\n",
       "      <td>-0.002465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44 2.9 The Moore-Penrose Pseudoinverse . . . ....</td>\n",
       "      <td>-0.031741</td>\n",
       "      <td>-0.037186</td>\n",
       "      <td>-0.031555</td>\n",
       "      <td>0.007193</td>\n",
       "      <td>-0.020357</td>\n",
       "      <td>0.024212</td>\n",
       "      <td>0.009975</td>\n",
       "      <td>-0.011623</td>\n",
       "      <td>-0.016394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057023</td>\n",
       "      <td>0.020886</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>-0.040777</td>\n",
       "      <td>-0.039249</td>\n",
       "      <td>-0.020921</td>\n",
       "      <td>-0.046177</td>\n",
       "      <td>-0.009167</td>\n",
       "      <td>-0.061047</td>\n",
       "      <td>0.039575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CONTENTS 3.2 Random Variables . . . . . . . . ...</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>-0.020099</td>\n",
       "      <td>-0.010779</td>\n",
       "      <td>-0.036296</td>\n",
       "      <td>-0.046839</td>\n",
       "      <td>-0.006059</td>\n",
       "      <td>0.064030</td>\n",
       "      <td>-0.028023</td>\n",
       "      <td>-0.026936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025948</td>\n",
       "      <td>-0.050867</td>\n",
       "      <td>-0.004814</td>\n",
       "      <td>-0.006382</td>\n",
       "      <td>-0.028602</td>\n",
       "      <td>-0.052971</td>\n",
       "      <td>-0.008787</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.017470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70 3.12 Technical Details of Continuous Variab...</td>\n",
       "      <td>-0.022244</td>\n",
       "      <td>-0.011066</td>\n",
       "      <td>-0.001443</td>\n",
       "      <td>0.019685</td>\n",
       "      <td>-0.026603</td>\n",
       "      <td>-0.034205</td>\n",
       "      <td>0.038988</td>\n",
       "      <td>0.034638</td>\n",
       "      <td>-0.003044</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004564</td>\n",
       "      <td>-0.019053</td>\n",
       "      <td>0.034722</td>\n",
       "      <td>-0.055960</td>\n",
       "      <td>-0.013404</td>\n",
       "      <td>0.014567</td>\n",
       "      <td>-0.001038</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>-0.011777</td>\n",
       "      <td>0.036516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110 5.3 Hyperparameters and Validation Sets . ...</td>\n",
       "      <td>-0.017849</td>\n",
       "      <td>0.026254</td>\n",
       "      <td>-0.003629</td>\n",
       "      <td>0.010114</td>\n",
       "      <td>-0.012865</td>\n",
       "      <td>-0.024139</td>\n",
       "      <td>0.036304</td>\n",
       "      <td>-0.054298</td>\n",
       "      <td>0.014574</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006059</td>\n",
       "      <td>-0.003951</td>\n",
       "      <td>-0.021149</td>\n",
       "      <td>-0.058968</td>\n",
       "      <td>0.004840</td>\n",
       "      <td>-0.042809</td>\n",
       "      <td>-0.017105</td>\n",
       "      <td>-0.011151</td>\n",
       "      <td>-0.017171</td>\n",
       "      <td>-0.020745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      sentence_chunk     dim_0     dim_1  \\\n",
       "0  Contents Website vii Acknowledgments viii Nota... -0.040271  0.013905   \n",
       "1  44 2.9 The Moore-Penrose Pseudoinverse . . . .... -0.031741 -0.037186   \n",
       "2  CONTENTS 3.2 Random Variables . . . . . . . . ...  0.001216 -0.020099   \n",
       "3  70 3.12 Technical Details of Continuous Variab... -0.022244 -0.011066   \n",
       "4  110 5.3 Hyperparameters and Validation Sets . ... -0.017849  0.026254   \n",
       "\n",
       "      dim_2     dim_3     dim_4     dim_5     dim_6     dim_7     dim_8  ...  \\\n",
       "0 -0.021256  0.041426 -0.021738  0.001527  0.054794 -0.003756  0.003455  ...   \n",
       "1 -0.031555  0.007193 -0.020357  0.024212  0.009975 -0.011623 -0.016394  ...   \n",
       "2 -0.010779 -0.036296 -0.046839 -0.006059  0.064030 -0.028023 -0.026936  ...   \n",
       "3 -0.001443  0.019685 -0.026603 -0.034205  0.038988  0.034638 -0.003044  ...   \n",
       "4 -0.003629  0.010114 -0.012865 -0.024139  0.036304 -0.054298  0.014574  ...   \n",
       "\n",
       "    dim_758   dim_759   dim_760   dim_761   dim_762   dim_763   dim_764  \\\n",
       "0  0.028978  0.006534  0.036656 -0.058340 -0.048954 -0.069978  0.000119   \n",
       "1  0.057023  0.020886  0.001551 -0.040777 -0.039249 -0.020921 -0.046177   \n",
       "2  0.025948 -0.050867 -0.004814 -0.006382 -0.028602 -0.052971 -0.008787   \n",
       "3 -0.004564 -0.019053  0.034722 -0.055960 -0.013404  0.014567 -0.001038   \n",
       "4 -0.006059 -0.003951 -0.021149 -0.058968  0.004840 -0.042809 -0.017105   \n",
       "\n",
       "    dim_765   dim_766   dim_767  \n",
       "0 -0.000420 -0.028307 -0.002465  \n",
       "1 -0.009167 -0.061047  0.039575  \n",
       "2  0.001743  0.002443  0.017470  \n",
       "3  0.004248 -0.011777  0.036516  \n",
       "4 -0.011151 -0.017171 -0.020745  \n",
       "\n",
       "[5 rows x 769 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2d22d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings to file\n",
    "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks_over_min_token_len)\n",
    "embeddings_df_save_path = \"assets/text_chunks_and_embeddings_df.csv\"\n",
    "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c95c7db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-14</td>\n",
       "      <td>Contents Website vii Acknowledgments viii Nota...</td>\n",
       "      <td>884</td>\n",
       "      <td>274</td>\n",
       "      <td>221.00</td>\n",
       "      <td>[-4.02709916e-02  1.39047820e-02 -2.12559048e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-14</td>\n",
       "      <td>44 2.9 The Moore-Penrose Pseudoinverse . . . ....</td>\n",
       "      <td>420</td>\n",
       "      <td>137</td>\n",
       "      <td>105.00</td>\n",
       "      <td>[-3.17406543e-02 -3.71864699e-02 -3.15545760e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-13</td>\n",
       "      <td>CONTENTS 3.2 Random Variables . . . . . . . . ...</td>\n",
       "      <td>756</td>\n",
       "      <td>240</td>\n",
       "      <td>189.00</td>\n",
       "      <td>[ 1.21580879e-03 -2.00990736e-02 -1.07791517e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-13</td>\n",
       "      <td>70 3.12 Technical Details of Continuous Variab...</td>\n",
       "      <td>807</td>\n",
       "      <td>257</td>\n",
       "      <td>201.75</td>\n",
       "      <td>[-2.22441740e-02 -1.10664023e-02 -1.44321460e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-13</td>\n",
       "      <td>110 5.3 Hyperparameters and Validation Sets . ...</td>\n",
       "      <td>827</td>\n",
       "      <td>246</td>\n",
       "      <td>206.75</td>\n",
       "      <td>[-1.78492293e-02  2.62535345e-02 -3.62942228e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                     sentence_chunk  \\\n",
       "0          -14  Contents Website vii Acknowledgments viii Nota...   \n",
       "1          -14  44 2.9 The Moore-Penrose Pseudoinverse . . . ....   \n",
       "2          -13  CONTENTS 3.2 Random Variables . . . . . . . . ...   \n",
       "3          -13  70 3.12 Technical Details of Continuous Variab...   \n",
       "4          -13  110 5.3 Hyperparameters and Validation Sets . ...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  \\\n",
       "0               884               274             221.00   \n",
       "1               420               137             105.00   \n",
       "2               756               240             189.00   \n",
       "3               807               257             201.75   \n",
       "4               827               246             206.75   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-4.02709916e-02  1.39047820e-02 -2.12559048e-...  \n",
       "1  [-3.17406543e-02 -3.71864699e-02 -3.15545760e-...  \n",
       "2  [ 1.21580879e-03 -2.00990736e-02 -1.07791517e-...  \n",
       "3  [-2.22441740e-02 -1.10664023e-02 -1.44321460e-...  \n",
       "4  [-1.78492293e-02  2.62535345e-02 -3.62942228e-...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Import saved file and view\n",
    "text_chunks_and_embedding_df_load = pd.read_csv(embeddings_df_save_path)\n",
    "text_chunks_and_embedding_df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dce4cc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1874, 768])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "device =  \"cpu\"\n",
    "\n",
    "# Import texts and embedding df\n",
    "text_chunks_and_embedding_df = pd.read_csv(\"assets/text_chunks_and_embeddings_df.csv\")\n",
    "\n",
    "# Convert embedding column back to np.array (it got converted to string when it got saved to CSV)\n",
    "text_chunks_and_embedding_df[\"embedding\"] = text_chunks_and_embedding_df[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \"))\n",
    "\n",
    "# Convert texts and embedding df to list of dicts\n",
    "pages_and_chunks = text_chunks_and_embedding_df.to_dict(orient=\"records\")\n",
    "\n",
    "# Convert embeddings to torch tensor and send to device (note: NumPy arrays are float64, torch tensors are float32 by default)\n",
    "embeddings = torch.tensor(np.array(text_chunks_and_embedding_df[\"embedding\"].tolist()), dtype=torch.float32).to(device)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "991d5326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-14</td>\n",
       "      <td>Contents Website vii Acknowledgments viii Nota...</td>\n",
       "      <td>884</td>\n",
       "      <td>274</td>\n",
       "      <td>221.00</td>\n",
       "      <td>[-0.0402709916, 0.013904782, -0.0212559048, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-14</td>\n",
       "      <td>44 2.9 The Moore-Penrose Pseudoinverse . . . ....</td>\n",
       "      <td>420</td>\n",
       "      <td>137</td>\n",
       "      <td>105.00</td>\n",
       "      <td>[-0.0317406543, -0.0371864699, -0.031554576, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-13</td>\n",
       "      <td>CONTENTS 3.2 Random Variables . . . . . . . . ...</td>\n",
       "      <td>756</td>\n",
       "      <td>240</td>\n",
       "      <td>189.00</td>\n",
       "      <td>[0.00121580879, -0.0200990736, -0.0107791517, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-13</td>\n",
       "      <td>70 3.12 Technical Details of Continuous Variab...</td>\n",
       "      <td>807</td>\n",
       "      <td>257</td>\n",
       "      <td>201.75</td>\n",
       "      <td>[-0.022244174, -0.0110664023, -0.0014432146, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-13</td>\n",
       "      <td>110 5.3 Hyperparameters and Validation Sets . ...</td>\n",
       "      <td>827</td>\n",
       "      <td>246</td>\n",
       "      <td>206.75</td>\n",
       "      <td>[-0.0178492293, 0.0262535345, -0.00362942228, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                     sentence_chunk  \\\n",
       "0          -14  Contents Website vii Acknowledgments viii Nota...   \n",
       "1          -14  44 2.9 The Moore-Penrose Pseudoinverse . . . ....   \n",
       "2          -13  CONTENTS 3.2 Random Variables . . . . . . . . ...   \n",
       "3          -13  70 3.12 Technical Details of Continuous Variab...   \n",
       "4          -13  110 5.3 Hyperparameters and Validation Sets . ...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  \\\n",
       "0               884               274             221.00   \n",
       "1               420               137             105.00   \n",
       "2               756               240             189.00   \n",
       "3               807               257             201.75   \n",
       "4               827               246             206.75   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.0402709916, 0.013904782, -0.0212559048, 0....  \n",
       "1  [-0.0317406543, -0.0371864699, -0.031554576, 0...  \n",
       "2  [0.00121580879, -0.0200990736, -0.0107791517, ...  \n",
       "3  [-0.022244174, -0.0110664023, -0.0014432146, 0...  \n",
       "4  [-0.0178492293, 0.0262535345, -0.00362942228, ...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks_and_embedding_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "909dde72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.0271e-02,  1.3905e-02, -2.1256e-02,  4.1426e-02, -2.1738e-02,\n",
       "         1.5266e-03,  5.4794e-02, -3.7556e-03,  3.4545e-03, -8.9366e-03,\n",
       "         8.2205e-03, -1.3111e-02,  2.4085e-02,  2.3415e-02,  1.9467e-02,\n",
       "        -4.5688e-02, -1.6615e-02,  1.7007e-02,  1.0802e-02, -5.3992e-02,\n",
       "         7.1947e-03, -3.6319e-02, -1.1533e-03,  7.1632e-03, -5.5167e-02,\n",
       "         8.2339e-04,  1.9330e-02, -2.0470e-02,  1.2855e-02,  5.5406e-02,\n",
       "         9.8052e-03,  4.0950e-02,  5.9935e-02, -1.6186e-02,  1.8019e-06,\n",
       "        -7.5615e-03, -7.2378e-04, -4.0358e-02,  7.9174e-02,  5.1595e-02,\n",
       "        -6.1176e-03, -5.3496e-03,  3.6026e-03, -3.5802e-02, -3.4927e-02,\n",
       "        -6.8273e-03, -4.4217e-02,  3.1314e-02,  4.0591e-02,  2.7293e-02,\n",
       "        -1.0609e-02, -1.3389e-02,  5.5221e-03, -2.8958e-02,  1.6316e-02,\n",
       "        -6.6412e-02,  1.1399e-02, -4.2833e-02, -4.4757e-02, -5.4450e-02,\n",
       "        -5.8498e-03,  5.8170e-02,  8.1549e-03,  1.9927e-02,  6.9836e-02,\n",
       "         4.3452e-02,  2.8802e-02,  3.5914e-03,  4.5694e-03,  7.6567e-02,\n",
       "        -1.8146e-02,  1.7739e-03,  3.7220e-02,  7.3603e-03,  1.7231e-02,\n",
       "         3.2931e-02, -3.2114e-02, -1.7390e-02,  4.1045e-02,  1.0362e-02,\n",
       "        -4.2002e-02,  2.4113e-02,  5.5418e-03, -1.2461e-02, -7.4081e-02,\n",
       "         7.1966e-02,  3.6020e-02,  2.5760e-02, -3.6462e-02, -1.0915e-02,\n",
       "        -2.2381e-02,  1.4794e-02,  3.4402e-02,  1.1299e-02, -4.2053e-02,\n",
       "        -5.6241e-02, -2.4290e-02, -1.2088e-01, -1.1305e-02, -4.4176e-02,\n",
       "         5.8755e-02, -2.5253e-02, -1.2631e-02,  2.8539e-02, -3.5647e-02,\n",
       "         1.2049e-02, -5.7709e-02,  4.2268e-02, -1.6295e-02,  2.4352e-02,\n",
       "         3.6461e-02,  1.8493e-02, -1.5276e-02,  4.2553e-02,  1.9979e-02,\n",
       "         2.5248e-02, -5.0765e-02, -9.8187e-03, -5.6729e-02, -6.9971e-03,\n",
       "        -5.6749e-02,  4.7374e-02,  2.9283e-02, -2.6577e-02,  2.8231e-02,\n",
       "         4.8610e-02, -2.2714e-02,  5.9123e-02, -4.6077e-02,  1.8663e-02,\n",
       "        -3.9975e-05,  1.7578e-02,  2.6822e-02,  1.2123e-02,  3.3863e-02,\n",
       "         5.1244e-02,  1.7006e-02,  8.1160e-03, -3.2639e-02,  2.3975e-02,\n",
       "        -8.8247e-03, -9.2776e-02,  1.3516e-03, -5.4254e-02,  2.3904e-02,\n",
       "         1.3823e-02,  1.2608e-04, -3.9916e-02, -3.3439e-03, -3.0798e-02,\n",
       "        -2.6194e-02,  7.0402e-02,  3.0509e-02, -1.2353e-02,  8.6060e-02,\n",
       "        -1.7916e-02,  3.0735e-02,  2.4442e-02,  3.5832e-02,  6.3308e-03,\n",
       "         1.9013e-02, -2.5528e-02,  2.8953e-02, -6.8745e-03,  2.9187e-02,\n",
       "        -3.4006e-02, -6.1470e-02, -5.9428e-02,  1.5193e-02, -5.0798e-02,\n",
       "        -5.3447e-02,  5.3847e-02, -4.2982e-03, -2.0845e-02,  3.7690e-02,\n",
       "         3.2411e-02, -8.7175e-03,  6.0038e-02,  4.0295e-02, -3.1214e-03,\n",
       "         3.8632e-03,  5.1602e-02,  3.3681e-02,  3.0467e-02, -4.4585e-03,\n",
       "        -5.5535e-02, -1.7026e-02,  3.2554e-02, -2.9431e-02, -5.0688e-02,\n",
       "         3.8319e-02, -4.4910e-02,  9.4307e-03, -2.3700e-02,  1.0200e-01,\n",
       "        -7.3880e-02, -4.2120e-02, -2.2424e-02,  1.2367e-02, -6.3478e-02,\n",
       "        -1.4826e-02, -8.0070e-03,  3.6258e-02, -6.6399e-02, -7.1678e-03,\n",
       "        -5.7306e-02, -1.5393e-02, -1.1257e-02, -2.0340e-02, -6.7343e-02,\n",
       "        -6.6664e-03, -2.1138e-02,  2.6561e-02, -3.5910e-02,  9.1884e-03,\n",
       "         3.2599e-02,  2.9828e-02, -3.2297e-02, -4.8010e-02,  8.5928e-04,\n",
       "         7.4100e-04,  3.4559e-02,  2.1637e-03, -1.1336e-02, -2.7983e-02,\n",
       "         3.3974e-02,  5.5725e-02,  3.9822e-02,  1.3454e-02,  6.3828e-02,\n",
       "         2.1654e-02, -5.2620e-02,  5.6058e-02, -6.7051e-02, -6.3028e-02,\n",
       "         3.8898e-03,  1.4555e-04,  2.9620e-02,  9.8315e-03, -9.2808e-02,\n",
       "        -3.1001e-03,  4.1016e-02, -3.4543e-03, -5.7608e-02,  8.0406e-02,\n",
       "         2.1894e-02, -3.9654e-02, -4.4064e-02, -6.8009e-03, -4.6431e-02,\n",
       "         3.9710e-02, -3.2774e-02,  5.9316e-02, -1.9936e-02,  4.4795e-02,\n",
       "         9.2011e-03, -2.0069e-02,  3.7821e-02, -1.9185e-02, -3.3008e-02,\n",
       "         1.0833e-03, -3.8537e-02, -2.1858e-02,  1.2550e-02,  1.3205e-02,\n",
       "         6.1307e-02,  2.6163e-02,  2.0888e-03, -2.4571e-03, -3.6312e-02,\n",
       "        -1.4072e-02, -2.7147e-02, -8.5273e-03,  5.0372e-02, -2.6018e-02,\n",
       "        -2.7347e-02,  3.3502e-02,  1.3543e-03, -8.3087e-02,  3.7975e-02,\n",
       "         3.6645e-03, -5.0347e-03,  2.1386e-02, -1.5028e-02,  4.0937e-04,\n",
       "         3.9006e-02,  1.6115e-02, -9.9640e-03, -6.0846e-03,  5.2047e-02,\n",
       "        -1.4438e-02,  4.3703e-02, -5.9320e-02, -2.8895e-02, -9.6970e-03,\n",
       "        -3.6668e-02,  1.2132e-03,  7.4864e-02,  6.7105e-03,  4.5353e-02,\n",
       "         4.1186e-02,  9.7184e-02,  9.2186e-03,  1.9143e-02, -1.6964e-02,\n",
       "         3.3894e-02, -1.8607e-03,  2.9836e-03, -9.0824e-03,  1.5597e-02,\n",
       "         1.0308e-02, -2.3816e-02, -7.4877e-03, -4.6195e-02, -5.5116e-03,\n",
       "        -3.2208e-02, -2.7327e-02, -8.4818e-03,  1.6452e-02,  1.3957e-02,\n",
       "         2.2578e-02, -2.0359e-02,  3.5624e-02,  3.1465e-02,  5.6489e-03,\n",
       "        -2.7560e-03, -6.8454e-02, -1.1963e-02, -7.0989e-02,  5.8282e-03,\n",
       "        -1.4338e-02, -7.4659e-02, -2.6804e-02,  1.2092e-02,  5.2488e-03,\n",
       "         2.1840e-02, -2.9032e-02,  1.3555e-02, -6.7594e-03,  1.9762e-02,\n",
       "         8.1504e-03, -5.2435e-02, -3.4651e-02,  2.7346e-02,  4.9021e-02,\n",
       "        -4.7889e-02, -1.7227e-02, -5.7039e-02,  2.2588e-02, -2.5649e-02,\n",
       "        -3.4320e-03,  5.2766e-02,  1.0410e-02,  2.9113e-02, -5.2508e-03,\n",
       "         1.0644e-01, -1.9111e-02, -2.0969e-02, -3.7355e-02, -1.9332e-03,\n",
       "         3.9862e-02,  1.9069e-02,  3.5339e-02,  3.1885e-02, -8.2500e-02,\n",
       "         2.3291e-02,  2.2087e-02,  2.2214e-02,  2.1318e-02, -8.4257e-03,\n",
       "        -3.1514e-02,  3.7685e-03,  1.9462e-02,  6.4791e-03, -5.7212e-03,\n",
       "        -8.0602e-02, -1.3520e-02,  4.4062e-02, -3.0775e-02,  1.6905e-02,\n",
       "         7.9293e-03, -7.5727e-04,  4.6532e-02, -1.6029e-02, -1.5513e-02,\n",
       "         2.5835e-02, -3.4569e-02,  1.4046e-02, -3.1933e-02, -3.1354e-03,\n",
       "        -7.3030e-03, -1.7859e-02, -7.0435e-02, -1.7429e-02,  1.3975e-03,\n",
       "        -5.1853e-02, -2.5799e-03, -3.8193e-02, -3.7508e-03, -2.0982e-02,\n",
       "         3.3238e-02,  9.7365e-03, -3.7931e-02,  3.2625e-03, -4.8575e-02,\n",
       "        -2.5045e-03,  7.7723e-03,  4.1421e-02, -7.0632e-02, -3.8464e-02,\n",
       "        -1.1182e-02,  1.2170e-02, -3.8919e-02, -3.9455e-02,  1.2829e-02,\n",
       "         3.0279e-02, -1.3232e-02, -2.7474e-02,  7.7274e-02, -2.7010e-02,\n",
       "         3.4605e-02, -3.2291e-02,  6.7591e-02, -2.9082e-02, -3.3691e-02,\n",
       "         8.9051e-03, -3.6301e-02, -9.2806e-03,  2.1046e-02, -1.4001e-02,\n",
       "        -7.3162e-02, -1.8337e-02,  2.0479e-02,  6.2332e-02, -2.0225e-02,\n",
       "        -2.1120e-02, -1.2893e-03, -1.7547e-02, -2.2824e-02, -4.4212e-02,\n",
       "         2.4311e-02,  1.6895e-02,  8.6107e-02, -1.5665e-02,  1.3584e-02,\n",
       "         5.9487e-03, -3.7698e-02, -4.1565e-02,  5.5986e-03,  4.2712e-02,\n",
       "         1.8090e-02,  1.6763e-02,  2.2895e-02,  4.0256e-02, -4.6387e-03,\n",
       "        -3.1302e-02, -5.1287e-02, -7.8548e-02, -5.9692e-02, -1.4433e-02,\n",
       "        -1.3337e-02,  1.9648e-02, -3.7509e-03, -8.3723e-03, -5.7618e-02,\n",
       "         1.5699e-02,  1.3202e-02,  2.7894e-02,  3.9882e-02,  4.9314e-02,\n",
       "        -3.6118e-02, -3.5185e-02,  2.8965e-02,  1.0576e-03,  5.5616e-02,\n",
       "        -1.4985e-03, -4.7033e-02, -2.3916e-02, -1.9298e-02,  9.6844e-03,\n",
       "         2.4077e-02,  7.3394e-02,  3.1156e-02, -2.8791e-02, -4.6649e-02,\n",
       "         4.6195e-02,  5.5695e-03, -9.6009e-03, -3.1012e-02, -1.0489e-02,\n",
       "        -1.0562e-02,  6.3612e-02, -4.1227e-02,  3.2548e-02,  6.7783e-02,\n",
       "         2.7035e-03, -7.0834e-02, -1.2374e-04, -2.1535e-02,  3.2292e-02,\n",
       "        -2.9998e-02,  2.9493e-02, -4.0442e-03,  5.5931e-02,  4.7947e-02,\n",
       "         6.6131e-03, -1.4154e-02,  1.4131e-02,  1.0484e-02,  3.1045e-02,\n",
       "        -2.5072e-02, -1.5945e-02, -2.6281e-02, -3.9359e-03,  4.4547e-03,\n",
       "         1.8987e-03,  4.3300e-02, -7.4744e-03,  3.2807e-02, -6.5632e-03,\n",
       "         1.5387e-02, -5.4624e-02,  4.8808e-02,  1.7485e-03,  2.3557e-02,\n",
       "         2.2200e-02, -4.2893e-02, -1.2154e-02,  8.2053e-02,  3.9361e-02,\n",
       "         2.7958e-03, -5.2514e-03, -4.9627e-02, -2.9840e-02, -2.7768e-02,\n",
       "         2.4304e-02,  3.7878e-02, -1.0470e-02, -2.8191e-02,  2.7906e-02,\n",
       "        -5.4647e-02, -3.5671e-02,  3.9408e-02, -1.1703e-02,  7.0067e-02,\n",
       "        -2.1504e-02,  1.0147e-02,  2.6769e-02, -1.7629e-02,  3.9997e-02,\n",
       "         1.7249e-02, -1.9352e-02, -1.7341e-02, -7.3054e-02, -1.1541e-02,\n",
       "        -5.8193e-33, -6.8862e-03, -1.6939e-02, -6.3783e-02,  5.5735e-03,\n",
       "        -1.2354e-02, -1.7210e-02,  2.8501e-02,  3.0011e-03, -1.4401e-03,\n",
       "         1.1744e-02, -3.3194e-02,  4.7805e-02,  7.9897e-03,  1.2789e-02,\n",
       "         9.2728e-03, -1.8695e-02, -1.6325e-02, -2.3881e-02,  3.5916e-02,\n",
       "         1.8631e-02,  4.5149e-02,  7.2282e-02,  1.6218e-02, -7.6696e-02,\n",
       "        -1.1891e-02, -4.0121e-02, -5.2746e-02, -4.7471e-03, -5.3024e-02,\n",
       "        -3.1790e-02, -3.6628e-02, -7.5267e-03,  5.4981e-02,  2.7813e-02,\n",
       "         4.0839e-02, -3.1816e-02, -3.0344e-02, -2.5693e-02, -4.2196e-02,\n",
       "         5.2588e-03, -9.6632e-02, -8.3009e-03,  7.5362e-02, -4.0875e-03,\n",
       "        -9.1397e-02, -1.5493e-02,  5.3083e-02,  2.3391e-02,  2.8589e-02,\n",
       "        -3.5364e-02, -1.9254e-02,  5.5612e-03, -5.1698e-02, -6.8952e-03,\n",
       "         1.9021e-02, -2.5355e-02, -7.5580e-03,  3.1991e-02, -3.0060e-02,\n",
       "         4.5588e-02,  1.1671e-02,  2.6413e-02,  3.0328e-02,  4.7934e-03,\n",
       "        -3.7419e-02,  5.2088e-02,  5.6939e-02, -4.5641e-02,  2.0832e-02,\n",
       "        -4.5458e-02,  4.4375e-02,  5.3358e-02,  4.8393e-02,  2.8198e-02,\n",
       "         5.9794e-02, -5.4135e-02, -1.1296e-01,  4.1462e-02, -1.1672e-02,\n",
       "         5.4937e-03, -2.1842e-02, -1.1412e-02, -1.9337e-03, -1.2059e-02,\n",
       "         1.4725e-02, -6.6614e-02, -1.2973e-02,  1.5243e-02, -2.8760e-02,\n",
       "         1.2940e-02, -3.8068e-02,  3.0518e-02, -2.3640e-02, -5.4920e-02,\n",
       "         4.9740e-02,  1.7371e-02,  8.2466e-03,  5.3954e-02,  4.9764e-02,\n",
       "        -2.6642e-02,  3.9496e-02, -5.6225e-03, -7.2132e-03, -1.3713e-02,\n",
       "         3.2974e-02, -1.5340e-02,  2.8883e-02,  6.7802e-02,  3.0667e-02,\n",
       "        -2.0678e-02, -9.6011e-03, -4.4718e-02,  1.0476e-02,  4.3411e-02,\n",
       "         4.7735e-02, -1.4069e-02, -9.9990e-03,  8.1939e-02, -1.5176e-02,\n",
       "         5.3174e-02, -4.5279e-02,  2.3058e-03,  1.1695e-02,  2.6054e-02,\n",
       "        -1.6552e-02, -2.5705e-02, -1.4613e-02, -8.0929e-03,  2.0268e-02,\n",
       "        -4.1308e-02, -1.6170e-02, -3.0776e-02,  2.5377e-07, -3.5878e-02,\n",
       "         1.6204e-02, -9.9918e-03, -4.8650e-02,  8.5915e-03,  4.4361e-02,\n",
       "        -7.4840e-02,  8.6524e-02, -6.4205e-02,  8.9288e-03,  3.4629e-03,\n",
       "        -1.9877e-02,  3.5819e-03, -3.6078e-02,  1.7813e-02,  4.0684e-03,\n",
       "         3.3381e-03,  2.9938e-02, -1.9228e-02,  2.0224e-02,  6.5796e-03,\n",
       "         1.2343e-02,  2.4237e-02, -2.9043e-02,  2.6992e-02,  5.0122e-02,\n",
       "         3.0385e-02,  4.5181e-03,  1.8205e-02, -9.0678e-03,  5.0139e-02,\n",
       "        -2.5300e-02, -1.3112e-02,  3.2874e-02, -5.2215e-03,  6.8957e-02,\n",
       "         6.2850e-02,  3.8940e-02, -1.0503e-02,  1.7988e-02, -1.0862e-02,\n",
       "         4.1235e-02, -4.9247e-03,  2.0638e-02,  8.5269e-02,  5.7919e-02,\n",
       "        -3.5898e-02, -2.4064e-02, -2.7270e-02,  7.0998e-02,  5.9181e-02,\n",
       "         1.7828e-02,  3.0970e-02,  2.9967e-02, -5.0339e-02,  2.6496e-03,\n",
       "         1.9859e-02, -6.8886e-02,  7.9037e-02,  2.7967e-02, -3.4054e-02,\n",
       "        -7.7724e-04,  3.8492e-02,  5.4956e-03,  7.6438e-02, -1.3680e-02,\n",
       "        -2.3799e-03,  2.4483e-34, -5.1473e-02,  2.8978e-02,  6.5338e-03,\n",
       "         3.6656e-02, -5.8340e-02, -4.8954e-02, -6.9978e-02,  1.1945e-04,\n",
       "        -4.2018e-04, -2.8307e-02, -2.4647e-03])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "efc852d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer \n",
    "\n",
    "model = SentenceTransformer('all-mpnet-base-v2' , device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6d2026f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function to print wrapped text \n",
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888671cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "embedding_model = SentenceTransformer('all-mpnet-base-v2', device=device)\n",
    "def retrieve_relevant_resources(query: str,\n",
    "                                embeddings: torch.tensor,\n",
    "                                model: SentenceTransformer=embedding_model,\n",
    "                                n_resources_to_return: int=5,\n",
    "                                print_time: bool=True):\n",
    "    \"\"\"\n",
    "    Embeds a query with model and returns top k scores and indices from embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    # Embed the query\n",
    "    query_embedding = model.encode(query, \n",
    "                                   convert_to_tensor=True) \n",
    "\n",
    "    # Get dot product scores on embeddings\n",
    "    start_time = timer()\n",
    "    dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
    "    end_time = timer()\n",
    "\n",
    "    if print_time:\n",
    "        print(f\"[INFO] Time taken to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
    "\n",
    "    scores, indices = torch.topk(input=dot_scores, \n",
    "                                 k=n_resources_to_return)\n",
    "\n",
    "    return scores, indices\n",
    "\n",
    "def print_top_results_and_scores(query: str,\n",
    "                                 embeddings: torch.tensor,\n",
    "                                 pages_and_chunks: list[dict]=pages_and_chunks,\n",
    "                                 n_resources_to_return: int=5): \n",
    "    \"\"\"\n",
    "    Takes a query, retrieves most relevant resources and prints them out in descending order.\n",
    "\n",
    "    Note: Requires pages_and_chunks to be formatted in a specific way (see above for reference).\n",
    "    \"\"\"\n",
    "    \n",
    "    scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                                  embeddings=embeddings,\n",
    "                                                  n_resources_to_return=n_resources_to_return)\n",
    "    \n",
    "    print(f\"Query: {query}\\n\")\n",
    "    print(\"Results:\")\n",
    "    # Loop through zipped together scores and indicies\n",
    "    for score, index in zip(scores, indices):\n",
    "        print(f\"Score: {score:.4f}\")\n",
    "        # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
    "        print_wrapped(pages_and_chunks[index][\"sentence_chunk\"])\n",
    "        # Print the page number too so we can reference the textbook further and check the results\n",
    "        print(f\"Page number: {pages_and_chunks[index]['page_number']}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "844528d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time taken to get scores on 1874 embeddings: 0.00052 seconds.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is deep learning?\"\n",
    "\n",
    "scores , indices = retrieve_relevant_resources(query=query,\n",
    "                                                  embeddings=embeddings,\n",
    "                                                  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5bc757ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time taken to get scores on 1874 embeddings: 0.00071 seconds.\n",
      "Query: What is deep learning?\n",
      "\n",
      "Results:\n",
      "Score: 0.7849\n",
      "Speciﬁcally, it is a type of machine learning, a technique that allows computer\n",
      "systems to improve with experience and data. According to the authors of this\n",
      "book, machine learning is the only viable approach to building AI systems that\n",
      "can operate in complicated, real-world environments. Deep learning is a\n",
      "particular kind of machine learning that achieves great power and ﬂexibility by\n",
      "learning to represent the world as a nested hierarchy of concepts, with each\n",
      "concept deﬁned in relation to simpler concepts, and more abstract\n",
      "representations computed in terms of less abstract ones. Figure illustrates the\n",
      "relationship between these diﬀerent 1.4 AI disciplines. Figure gives a high-\n",
      "level schematic of how each works.1.5 1.1 Who Should Read This Book?This book\n",
      "can be useful for a variety of readers, but we wrote it with two main target\n",
      "audiences in mind. One of these target audiences is university students\n",
      "(undergraduate or graduate) learning about machine learning, including those who\n",
      "are beginning a career in deep learning and artiﬁcial intelligence research. The\n",
      "other target audience is software engineers who do not have a machine learning\n",
      "or statistics background, but want to rapidly acquire one and begin using deep\n",
      "learning in their product or platform. Deep learning has already proven useful\n",
      "in 8\n",
      "Page number: 7\n",
      "\n",
      "\n",
      "Score: 0.6688\n",
      "As a result, one of the names that deep learning has gone by is artiﬁcial neural\n",
      "networks (ANNs). The corresponding perspective on deep learning models is that\n",
      "they are engineered systems inspired by the biological brain (whether the human\n",
      "brain or the brain of another animal). While the kinds of neural networks used\n",
      "for machine learning have sometimes been used to understand brain function ( ,\n",
      "), they are Hinton and Shallice 1991 generally not designed to be realistic\n",
      "models of biological function. The neural perspective on deep learning is\n",
      "motivated by two main ideas. One idea is that the brain provides a proof by\n",
      "example that intelligent behavior is possible, and a conceptually\n",
      "straightforward path to building intelligence is to reverse engineer the\n",
      "computational principles behind the brain and duplicate its functionality.\n",
      "Another perspective is that it would be deeply interesting to understand the\n",
      "brain and the principles that underlie human intelligence, so machine learning\n",
      "models that shed light on these basic scientiﬁc questions are useful apart from\n",
      "their ability to solve engineering applications. The modern term “deep learning”\n",
      "goes beyond the neuroscientiﬁc perspective on the current breed of machine\n",
      "learning models. It appeals to a more general principle of learning multiple\n",
      "levels of composition, which can be applied in machine learning frameworks that\n",
      "are not necessarily neurally inspired.13\n",
      "Page number: 12\n",
      "\n",
      "\n",
      "Score: 0.6641\n",
      "CHAPTER 1. INTRODUCTION 1.2.1 The Many Names and Changing Fortunes of Neural\n",
      "Net- works We expect that many readers of this book have heard of deep learning\n",
      "as an exciting new technology, and are surprised to see a mention of “history”\n",
      "in a book about an emerging ﬁeld. In fact, deep learning dates back to the\n",
      "1940s. Deep learning only appears to be new, because it was relatively unpopular\n",
      "for several years preceding its current popularity, and because it has gone\n",
      "through many diﬀerent names, and has only recently become called “deep\n",
      "learning.”The ﬁeld has been rebranded many times, reﬂecting the inﬂuence of\n",
      "diﬀerent researchers and diﬀerent perspectives. A comprehensive history of deep\n",
      "learning is beyond the scope of this textbook. However, some basic context is\n",
      "useful for understanding deep learning. Broadly speaking, there have been three\n",
      "waves of development of deep learning: deep learning known as cybernetics in the\n",
      "1940s–1960s, deep learning known as connectionism in the 1980s–1990s, and the\n",
      "current resurgence under the name deep learning beginning in 2006. This is\n",
      "quantitatively illustrated in ﬁgure .1.7 Some of the earliest learning\n",
      "algorithms we recognize today were intended to be computational models of\n",
      "biological learning, i.e. models of how learning happens or could happen in the\n",
      "brain.\n",
      "Page number: 12\n",
      "\n",
      "\n",
      "Score: 0.6327\n",
      "CHAPTER 1. INTRODUCTION of the ﬂowchart of the computations needed to compute\n",
      "the representation of each concept may be much deeper than the graph of the\n",
      "concepts themselves. This is because the system’s understanding of the simpler\n",
      "concepts can be reﬁned given information about the more complex concepts. For\n",
      "example, an AI system observing an image of a face with one eye in shadow may\n",
      "initially only see one eye. After detecting that a face is present, it can then\n",
      "infer that a second eye is probably present as well. In this case, the graph of\n",
      "concepts only includes two layers—a layer for eyes and a layer for faces—but the\n",
      "graph of computations includes 2n layers if we reﬁne our estimate of each\n",
      "concept given the other times.n Because it is not always clear which of these\n",
      "two views—the depth of the computational graph, or the depth of the\n",
      "probabilistic modeling graph—is most relevant, and because diﬀerent people\n",
      "choose diﬀerent sets of smallest elements from which to construct their graphs,\n",
      "there is no single correct value for the depth of an architecture, just as there\n",
      "is no single correct value for the length of a computer program. Nor is there a\n",
      "consensus about how much depth a model requires to qualify as “deep.”However,\n",
      "deep learning can safely be regarded as the study of models that either involve\n",
      "a greater amount of composition of learned functions or learned concepts than\n",
      "traditional machine learning does. To summarize, deep learning, the subject of\n",
      "this book, is an approach to AI.\n",
      "Page number: 7\n",
      "\n",
      "\n",
      "Score: 0.6195\n",
      "We can think of each application of a diﬀerent mathematical function as\n",
      "providing a new representation of the input. The idea of learning the right\n",
      "representation for the data provides one perspec- tive on deep learning. Another\n",
      "perspective on deep learning is that depth allows the computer to learn a multi-\n",
      "step computer program. Each layer of the representation can be thought of as the\n",
      "state of the computer’s memory after executing another set of instructions in\n",
      "parallel. Networks with greater depth can execute more instructions in sequence.\n",
      "Sequential instructions oﬀer great power because later 5\n",
      "Page number: 4\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_results_and_scores(query=query,\n",
    "                             embeddings=embeddings,\n",
    "                             pages_and_chunks=pages_and_chunks,\n",
    "                             ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aa82d968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU memory: 4 GB\n"
     ]
    }
   ],
   "source": [
    "# Get GPU available memory\n",
    "import torch\n",
    "gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory\n",
    "gpu_memory_gb = round(gpu_memory_bytes / (2**30))\n",
    "print(f\"Available GPU memory: {gpu_memory_gb} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e71bf078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 MB allocated\n",
      "0.0 MB reserved\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() \n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "print(torch.cuda.memory_allocated() / 1e6, \"MB allocated\")\n",
    "print(torch.cuda.memory_reserved() / 1e6, \"MB reserved\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "24ad3e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using attention implementation: sdpa\n",
      "[INFO] Loading model TinyLlama/TinyLlama-1.1B-Chat-v1.0 on CPU\n",
      "[INFO] Model loaded successfully on CPU!\n",
      "Hello, how are you?\n",
      "\n",
      "2. \"Good morning, how are you?\"\n",
      "\n",
      "3. \"How are you?\"\n",
      "\n",
      "4. \"How are you doing?\"\n",
      "\n",
      "5. \"How are you feeling?\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from transformers.utils import is_flash_attn_2_available\n",
    "\n",
    "use_quantization = True\n",
    "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",    # IMPORTANT for CPU quantization!\n",
    ")\n",
    "\n",
    "attn_impl = \"flash_attention_2\" if (is_flash_attn_2_available() and torch.cuda.is_available() and torch.cuda.get_device_capability(0)[0] >= 8) else \"sdpa\"\n",
    "print(f\"[INFO] Using attention implementation: {attn_impl}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "print(f\"[INFO] Loading model {model_id} on CPU\")\n",
    "\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=quant_config if use_quantization else None,\n",
    "    device_map={\"\": \"cpu\"},      # force CPU load\n",
    "    low_cpu_mem_usage=True,\n",
    "    attn_implementation=attn_impl,\n",
    ")\n",
    "\n",
    "print(\"[INFO] Model loaded successfully on CPU!\")\n",
    "\n",
    "# Example inference\n",
    "input_text = \"Hello, how are you?\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")  # inputs on CPU by default\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = llm_model.generate(**inputs, max_length=50)\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "99ff10c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_formatter(query: str, \n",
    "                     context_items: list[dict]) -> str:\n",
    "    \"\"\"\n",
    "    Augments query with text-based context from context_items.\n",
    "    \"\"\"\n",
    "    # Join context items into one dotted paragraph\n",
    "    context = \"- \" + \"\\n- \".join([item[\"sentence_chunk\"] for item in context_items])\n",
    "\n",
    "    # Create a base prompt with examples to help the model\n",
    "    # Note: this is very customizable, I've chosen to use 3 examples of the answer style we'd like.\n",
    "    # We could also write this in a txt file and import it in if we wanted.\n",
    "    base_prompt = \"\"\"Based on the following context items, please answer the query.\n",
    "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
    "Don't return the thinking, only return the answer.\n",
    "Make sure your answers are as explanatory as possible.\n",
    "Use the following examples as reference for the ideal answer style.\n",
    "\\nExample 1:\n",
    "Query: What are the fat-soluble vitamins?\n",
    "Answer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\n",
    "\\nExample 2:\n",
    "Query: What are the causes of type 2 diabetes?\n",
    "Answer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\n",
    "\\nExample 3:\n",
    "Query: What is the importance of hydration for physical performance?\n",
    "Answer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\n",
    "\\nNow use the following context items to answer the user query:\n",
    "{context}\n",
    "\\nRelevant passages: <extract relevant passages from the context here>\n",
    "User query: {query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    # Update base prompt with context items and query   \n",
    "    base_prompt = base_prompt.format(context=context, query=query)\n",
    "\n",
    "    # Create prompt template for instruction-tuned model\n",
    "    dialogue_template = [\n",
    "        {\"role\": \"user\",\n",
    "        \"content\": base_prompt}\n",
    "    ]\n",
    "\n",
    "    # Apply the chat template\n",
    "    prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "                                          tokenize=False,\n",
    "                                          add_generation_prompt=True)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "322ee92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is deep learning?\n",
      "[INFO] Time taken to get scores on 1874 embeddings: 0.00044 seconds.\n",
      "<|user|>\n",
      "Based on the following context items, please answer the query.\n",
      "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
      "Don't return the thinking, only return the answer.\n",
      "Make sure your answers are as explanatory as possible.\n",
      "Use the following examples as reference for the ideal answer style.\n",
      "\n",
      "Example 1:\n",
      "Query: What are the fat-soluble vitamins?\n",
      "Answer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\n",
      "\n",
      "Example 2:\n",
      "Query: What are the causes of type 2 diabetes?\n",
      "Answer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\n",
      "\n",
      "Example 3:\n",
      "Query: What is the importance of hydration for physical performance?\n",
      "Answer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\n",
      "\n",
      "Now use the following context items to answer the user query:\n",
      "- Speciﬁcally, it is a type of machine learning, a technique that allows computer systems to improve with experience and data. According to the authors of this book, machine learning is the only viable approach to building AI systems that can operate in complicated, real-world environments. Deep learning is a particular kind of machine learning that achieves great power and ﬂexibility by learning to represent the world as a nested hierarchy of concepts, with each concept deﬁned in relation to simpler concepts, and more abstract representations computed in terms of less abstract ones. Figure illustrates the relationship between these diﬀerent 1.4 AI disciplines. Figure gives a high-level schematic of how each works.1.5 1.1 Who Should Read This Book?This book can be useful for a variety of readers, but we wrote it with two main target audiences in mind. One of these target audiences is university students (undergraduate or graduate) learning about machine learning, including those who are beginning a career in deep learning and artiﬁcial intelligence research. The other target audience is software engineers who do not have a machine learning or statistics background, but want to rapidly acquire one and begin using deep learning in their product or platform. Deep learning has already proven useful in 8\n",
      "- As a result, one of the names that deep learning has gone by is artiﬁcial neural networks (ANNs). The corresponding perspective on deep learning models is that they are engineered systems inspired by the biological brain (whether the human brain or the brain of another animal). While the kinds of neural networks used for machine learning have sometimes been used to understand brain function ( , ), they are Hinton and Shallice 1991 generally not designed to be realistic models of biological function. The neural perspective on deep learning is motivated by two main ideas. One idea is that the brain provides a proof by example that intelligent behavior is possible, and a conceptually straightforward path to building intelligence is to reverse engineer the computational principles behind the brain and duplicate its functionality. Another perspective is that it would be deeply interesting to understand the brain and the principles that underlie human intelligence, so machine learning models that shed light on these basic scientiﬁc questions are useful apart from their ability to solve engineering applications. The modern term “deep learning” goes beyond the neuroscientiﬁc perspective on the current breed of machine learning models. It appeals to a more general principle of learning multiple levels of composition, which can be applied in machine learning frameworks that are not necessarily neurally inspired.13\n",
      "- CHAPTER 1. INTRODUCTION 1.2.1 The Many Names and Changing Fortunes of Neural Net- works We expect that many readers of this book have heard of deep learning as an exciting new technology, and are surprised to see a mention of “history” in a book about an emerging ﬁeld. In fact, deep learning dates back to the 1940s. Deep learning only appears to be new, because it was relatively unpopular for several years preceding its current popularity, and because it has gone through many diﬀerent names, and has only recently become called “deep learning.”The ﬁeld has been rebranded many times, reﬂecting the inﬂuence of diﬀerent researchers and diﬀerent perspectives. A comprehensive history of deep learning is beyond the scope of this textbook. However, some basic context is useful for understanding deep learning. Broadly speaking, there have been three waves of development of deep learning: deep learning known as cybernetics in the 1940s–1960s, deep learning known as connectionism in the 1980s–1990s, and the current resurgence under the name deep learning beginning in 2006. This is quantitatively illustrated in ﬁgure .1.7 Some of the earliest learning algorithms we recognize today were intended to be computational models of biological learning, i.e. models of how learning happens or could happen in the brain.\n",
      "- CHAPTER 1. INTRODUCTION of the ﬂowchart of the computations needed to compute the representation of each concept may be much deeper than the graph of the concepts themselves. This is because the system’s understanding of the simpler concepts can be reﬁned given information about the more complex concepts. For example, an AI system observing an image of a face with one eye in shadow may initially only see one eye. After detecting that a face is present, it can then infer that a second eye is probably present as well. In this case, the graph of concepts only includes two layers—a layer for eyes and a layer for faces—but the graph of computations includes 2n layers if we reﬁne our estimate of each concept given the other times.n Because it is not always clear which of these two views—the depth of the computational graph, or the depth of the probabilistic modeling graph—is most relevant, and because diﬀerent people choose diﬀerent sets of smallest elements from which to construct their graphs, there is no single correct value for the depth of an architecture, just as there is no single correct value for the length of a computer program. Nor is there a consensus about how much depth a model requires to qualify as “deep.”However, deep learning can safely be regarded as the study of models that either involve a greater amount of composition of learned functions or learned concepts than traditional machine learning does. To summarize, deep learning, the subject of this book, is an approach to AI.\n",
      "- We can think of each application of a diﬀerent mathematical function as providing a new representation of the input. The idea of learning the right representation for the data provides one perspec- tive on deep learning. Another perspective on deep learning is that depth allows the computer to learn a multi-step computer program. Each layer of the representation can be thought of as the state of the computer’s memory after executing another set of instructions in parallel. Networks with greater depth can execute more instructions in sequence. Sequential instructions oﬀer great power because later 5\n",
      "\n",
      "Relevant passages: <extract relevant passages from the context here>\n",
      "User query: What is deep learning?\n",
      "Answer:</s>\n",
      "<|assistant|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Get relevant resources\n",
    "scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                              embeddings=embeddings)\n",
    "    \n",
    "# Create a list of context items\n",
    "context_items = [pages_and_chunks[i] for i in indices]\n",
    "\n",
    "# Format prompt with context items\n",
    "prompt = prompt_formatter(query=query,\n",
    "                          context_items=context_items)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d4541964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35min 34s, sys: 33min 45s, total: 1h 9min 20s\n",
      "Wall time: 22min 41s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[125]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43minput_ids = tokenizer(prompt, return_tensors=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m).to(device)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m# Generate an output of tokens\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43moutputs = llm_model.generate(**input_ids,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                             temperature=0.7, # lower temperature = more deterministic outputs, higher temperature = more creative outputs\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                             do_sample=True, # whether or not to use sampling, see https://huyenchip.com/2024/01/16/sampling.html for more\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                             max_new_tokens=256) # how many new tokens to generate from prompt \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m# Turn the output tokens into text\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43moutput_text = tokenizer.decode(outputs[0])\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mprint(f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mQuery: \u001b[39;49m\u001b[38;5;132;43;01m{query}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mprint(f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRAG answer:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43moutput_text.replace(prompt, \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m)}\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2565\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2563\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2564\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2565\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2568\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2569\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/IPython/core/magics/execution.py:1470\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1468\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m interrupt_occured:\n\u001b[32m   1469\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exit_on_interrupt \u001b[38;5;129;01mand\u001b[39;00m captured_exception:\n\u001b[32m-> \u001b[39m\u001b[32m1470\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m captured_exception\n\u001b[32m   1471\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1472\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/IPython/core/magics/execution.py:1434\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1432\u001b[39m st = clock2()\n\u001b[32m   1433\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1434\u001b[39m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1435\u001b[39m     out = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1436\u001b[39m     \u001b[38;5;66;03m# multi-line %%time case\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:4\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:2623\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2615\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2616\u001b[39m         input_ids=input_ids,\n\u001b[32m   2617\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2618\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2619\u001b[39m         **model_kwargs,\n\u001b[32m   2620\u001b[39m     )\n\u001b[32m   2622\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2623\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2624\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2628\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2630\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2633\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2634\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2635\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2636\u001b[39m         input_ids=input_ids,\n\u001b[32m   2637\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2638\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2639\u001b[39m         **model_kwargs,\n\u001b[32m   2640\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3607\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3605\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3606\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3607\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3609\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3610\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3611\u001b[39m     outputs,\n\u001b[32m   3612\u001b[39m     model_kwargs,\n\u001b[32m   3613\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3614\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:943\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    940\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    944\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    945\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:552\u001b[39m, in \u001b[36mLlamaForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    547\u001b[39m output_hidden_states = (\n\u001b[32m    548\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m    549\u001b[39m )\n\u001b[32m    551\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    565\u001b[39m hidden_states = outputs.last_hidden_state\n\u001b[32m    566\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:943\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    940\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    944\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    945\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:440\u001b[39m, in \u001b[36mLlamaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    437\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    438\u001b[39m     all_hidden_states += (hidden_states,)\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    452\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/transformers/modeling_layers.py:83\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m         logger.warning(message)\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:306\u001b[39m, in \u001b[36mLlamaDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    304\u001b[39m residual = hidden_states\n\u001b[32m    305\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.post_attention_layernorm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    307\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    309\u001b[39m outputs = (hidden_states,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:151\u001b[39m, in \u001b[36mLlamaMLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     down_proj = \u001b[38;5;28mself\u001b[39m.down_proj(\u001b[38;5;28mself\u001b[39m.act_fn(\u001b[38;5;28mself\u001b[39m.gate_proj(x)) * \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/bitsandbytes/nn/modules.py:490\u001b[39m, in \u001b[36mLinear4bit.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    486\u001b[39m     x = x.to(\u001b[38;5;28mself\u001b[39m.compute_dtype)\n\u001b[32m    488\u001b[39m bias = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias.to(\u001b[38;5;28mself\u001b[39m.compute_dtype)\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbnb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul_4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m.\u001b[49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m.to(inp_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:388\u001b[39m, in \u001b[36mmatmul_4bit\u001b[39m\u001b[34m(A, B, quant_state, out, bias)\u001b[39m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m MatMul4Bit.apply(A, B, out, bias, quant_state)\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m     out = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgemv_4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    390\u001b[39m         out += bias\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/bitsandbytes/functional.py:1724\u001b[39m, in \u001b[36mgemv_4bit\u001b[39m\u001b[34m(A, B, out, transposed_A, transposed_B, state)\u001b[39m\n\u001b[32m   1713\u001b[39m     torch.ops.bitsandbytes.gemv_4bit.out(\n\u001b[32m   1714\u001b[39m         A,\n\u001b[32m   1715\u001b[39m         B,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1720\u001b[39m         out=out,\n\u001b[32m   1721\u001b[39m     )\n\u001b[32m   1722\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m-> \u001b[39m\u001b[32m1724\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbitsandbytes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgemv_4bit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1725\u001b[39m \u001b[43m    \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1728\u001b[39m \u001b[43m    \u001b[49m\u001b[43mabsmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mblocksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1731\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/torch/_ops.py:756\u001b[39m, in \u001b[36mOpOverload.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m756\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/torch/_compile.py:51\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive)\n\u001b[32m     49\u001b[39m     fn.__dynamo_disable = disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:838\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    836\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m838\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    840\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/torch/library.py:719\u001b[39m, in \u001b[36m_impl.<locals>.register_.<locals>.func_no_dynamo\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    717\u001b[39m \u001b[38;5;129m@torch\u001b[39m._disable_dynamo\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunc_no_dynamo\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/bitsandbytes/backends/cpu/ops.py:176\u001b[39m, in \u001b[36m_\u001b[39m\u001b[34m(A, B, shapeB, absmax, code, blocksize)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;129m@register_kernel\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mbitsandbytes::gemv_4bit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_\u001b[39m(\n\u001b[32m    166\u001b[39m     A: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    173\u001b[39m     \u001b[38;5;66;03m# TODO: We need to determine whether `code` is NF4, FP4, or other.\u001b[39;00m\n\u001b[32m    174\u001b[39m     \u001b[38;5;66;03m# Right now we assume NF4, as this is the only one supported on CPU.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     B_dq = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbitsandbytes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdequantize_4bit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mabsmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnf4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshapeB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mA\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# User called gemv with B.t(), so we need to transpose it back.\u001b[39;00m\n\u001b[32m    186\u001b[39m     \u001b[38;5;66;03m# if B.shape[0] == 1:\u001b[39;00m\n\u001b[32m    187\u001b[39m     \u001b[38;5;66;03m#    B_dq = B_dq.t()\u001b[39;00m\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.nn.functional.linear(\n\u001b[32m    190\u001b[39m         A,\n\u001b[32m    191\u001b[39m         B_dq,\n\u001b[32m    192\u001b[39m         bias=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    193\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/torch/_ops.py:756\u001b[39m, in \u001b[36mOpOverload.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m756\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/torch/_compile.py:51\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive)\n\u001b[32m     49\u001b[39m     fn.__dynamo_disable = disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:838\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    836\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m838\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    840\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/torch/library.py:719\u001b[39m, in \u001b[36m_impl.<locals>.register_.<locals>.func_no_dynamo\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    717\u001b[39m \u001b[38;5;129m@torch\u001b[39m._disable_dynamo\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunc_no_dynamo\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/bitsandbytes/backends/cpu/ops.py:159\u001b[39m, in \u001b[36m_\u001b[39m\u001b[34m(A, absmax, blocksize, quant_type, shape, dtype)\u001b[39m\n\u001b[32m    156\u001b[39m blocks = _NF4_QUANT_TABLE[blocks] * absmax[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    158\u001b[39m \u001b[38;5;66;03m# Reshape to original shape\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m blocks = \u001b[43mblocks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m blocks.to(dtype)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generate an output of tokens\n",
    "outputs = llm_model.generate(**input_ids,\n",
    "                             temperature=0.7, # lower temperature = more deterministic outputs, higher temperature = more creative outputs\n",
    "                             do_sample=True, # whether or not to use sampling, see https://huyenchip.com/2024/01/16/sampling.html for more\n",
    "                             max_new_tokens=256) # how many new tokens to generate from prompt \n",
    "\n",
    "# Turn the output tokens into text\n",
    "output_text = tokenizer.decode(outputs[0])\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"RAG answer:\\n{output_text.replace(prompt, '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d347a27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query, \n",
    "        temperature=0.7,\n",
    "        max_new_tokens=512,\n",
    "        format_answer_text=True, \n",
    "        return_answer_only=True):\n",
    "    \"\"\"\n",
    "    Takes a query, finds relevant resources/context and generates an answer to the query based on the relevant resources.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get just the scores and indices of top related results\n",
    "    scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                                  embeddings=embeddings)\n",
    "    \n",
    "    # Create a list of context items\n",
    "    context_items = [pages_and_chunks[i] for i in indices]\n",
    "\n",
    "    # Add score to context item\n",
    "    for i, item in enumerate(context_items):\n",
    "        item[\"score\"] = scores[i].cpu() # return score back to CPU \n",
    "        \n",
    "    # Format the prompt with context items\n",
    "    prompt = prompt_formatter(query=query,\n",
    "                              context_items=context_items)\n",
    "    \n",
    "    # Tokenize the prompt\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate an output of tokens\n",
    "    outputs = llm_model.generate(**input_ids,\n",
    "                                 temperature=temperature,\n",
    "                                 do_sample=True,\n",
    "                                 max_new_tokens=max_new_tokens)\n",
    "    \n",
    "    # Turn the output tokens into text\n",
    "    output_text = tokenizer.decode(outputs[0])\n",
    "\n",
    "    if format_answer_text:\n",
    "        # Replace special tokens and unnecessary help message\n",
    "        output_text = output_text.replace(prompt, \"\").replace(\"<bos>\", \"\").replace(\"<eos>\", \"\").replace(\"Sure, here is the answer to the user query:\\n\\n\", \"\")\n",
    "\n",
    "    # Only return the answer without the context items\n",
    "    if return_answer_only:\n",
    "        return output_text\n",
    "    \n",
    "    return output_text, context_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb969ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is deep learning?\n",
      "[INFO] Time taken to get scores on 1874 embeddings: 0.00062 seconds.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[124]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mQuery: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Answer query with context and return context \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m answer, context_items = \u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mreturn_answer_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAnswer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m print_wrapped(answer)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[123]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mask\u001b[39m\u001b[34m(query, temperature, max_new_tokens, format_answer_text, return_answer_only)\u001b[39m\n\u001b[32m     22\u001b[39m prompt = prompt_formatter(query=query,\n\u001b[32m     23\u001b[39m                           context_items=context_items)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Tokenize the prompt\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m input_ids = \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Generate an output of tokens\u001b[39;00m\n\u001b[32m     29\u001b[39m outputs = llm_model.generate(**input_ids,\n\u001b[32m     30\u001b[39m                              temperature=temperature,\n\u001b[32m     31\u001b[39m                              do_sample=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     32\u001b[39m                              max_new_tokens=max_new_tokens)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SILVA.AI/Projects/Hands_on_LLM/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:811\u001b[39m, in \u001b[36mBatchEncoding.to\u001b[39m\u001b[34m(self, device, non_blocking)\u001b[39m\n\u001b[32m    806\u001b[39m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[32m    807\u001b[39m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[32m    808\u001b[39m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[32m    809\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[32m    810\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = {\n\u001b[32m--> \u001b[39m\u001b[32m811\u001b[39m         k: \u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, torch.Tensor) \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[32m    812\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.data.items()\n\u001b[32m    813\u001b[39m     }\n\u001b[32m    814\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    815\u001b[39m     logger.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. This is not supported.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Answer query with context and return context \n",
    "answer, context_items = ask(query=query, \n",
    "                            temperature=0.7,\n",
    "                            max_new_tokens=512,\n",
    "                            return_answer_only=False)\n",
    "\n",
    "print(f\"Answer:\\n\")\n",
    "print_wrapped(answer)\n",
    "print(f\"Context items:\")\n",
    "context_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46bb017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hands-on-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
